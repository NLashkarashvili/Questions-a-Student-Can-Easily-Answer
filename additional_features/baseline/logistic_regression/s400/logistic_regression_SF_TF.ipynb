{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:39:34.283895Z",
     "iopub.status.busy": "2021-08-08T17:39:34.283187Z",
     "iopub.status.idle": "2021-08-08T17:39:40.883100Z",
     "shell.execute_reply": "2021-08-08T17:39:40.882281Z",
     "shell.execute_reply.started": "2021-08-06T21:05:15.103244Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.642332,
     "end_time": "2021-08-08T17:39:40.883271",
     "exception": false,
     "start_time": "2021-08-08T17:39:34.240939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:46:20.346040Z",
     "iopub.status.busy": "2021-08-08T17:46:20.345323Z",
     "iopub.status.idle": "2021-08-08T17:46:20.347734Z",
     "shell.execute_reply": "2021-08-08T17:46:20.347240Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.04112Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.368669,
     "end_time": "2021-08-08T17:46:20.347888",
     "exception": false,
     "start_time": "2021-08-08T17:46:19.979219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 400\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:46:21.074507Z",
     "iopub.status.busy": "2021-08-08T17:46:21.073857Z",
     "iopub.status.idle": "2021-08-08T17:46:21.076847Z",
     "shell.execute_reply": "2021-08-08T17:46:21.076294Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.049329Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.368039,
     "end_time": "2021-08-08T17:46:21.076991",
     "exception": false,
     "start_time": "2021-08-08T17:46:20.708952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 39\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:46:25.912275Z",
     "iopub.status.busy": "2021-08-08T17:46:25.911532Z",
     "iopub.status.idle": "2021-08-08T17:51:06.649535Z",
     "shell.execute_reply": "2021-08-08T17:51:06.648656Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.318071Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 281.10566,
     "end_time": "2021-08-08T17:51:06.649901",
     "exception": false,
     "start_time": "2021-08-08T17:46:25.544241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 191ms/step - loss: 0.6039 - masked_acc: 0.5198 - masked_auc: 0.5440 - val_loss: 0.4833 - val_masked_acc: 0.6988 - val_masked_auc: 0.6914\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 127ms/step - loss: 0.4551 - masked_acc: 0.7131 - masked_auc: 0.7201 - val_loss: 0.4620 - val_masked_acc: 0.7336 - val_masked_auc: 0.7545\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4422 - masked_acc: 0.7382 - masked_auc: 0.7629 - val_loss: 0.4587 - val_masked_acc: 0.7458 - val_masked_auc: 0.7756\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4368 - masked_acc: 0.7478 - masked_auc: 0.7796 - val_loss: 0.4551 - val_masked_acc: 0.7521 - val_masked_auc: 0.7869\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4360 - masked_acc: 0.7532 - masked_auc: 0.7892 - val_loss: 0.4559 - val_masked_acc: 0.7560 - val_masked_auc: 0.7938\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4344 - masked_acc: 0.7568 - masked_auc: 0.7954 - val_loss: 0.4564 - val_masked_acc: 0.7586 - val_masked_auc: 0.7983\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.4320 - masked_acc: 0.7592 - masked_auc: 0.7996 - val_loss: 0.4554 - val_masked_acc: 0.7605 - val_masked_auc: 0.8015\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4296 - masked_acc: 0.7610 - masked_auc: 0.8024 - val_loss: 0.4554 - val_masked_acc: 0.7619 - val_masked_auc: 0.8038\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.4351 - masked_acc: 0.7621 - masked_auc: 0.8044 - val_loss: 0.4553 - val_masked_acc: 0.7630 - val_masked_auc: 0.8057\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4384 - masked_acc: 0.7632 - masked_auc: 0.8061 - val_loss: 0.4554 - val_masked_acc: 0.7639 - val_masked_auc: 0.8071\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4414 - masked_acc: 0.7639 - masked_auc: 0.8075 - val_loss: 0.4554 - val_masked_acc: 0.7646 - val_masked_auc: 0.8083\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4340 - masked_acc: 0.7647 - masked_auc: 0.8087 - val_loss: 0.4554 - val_masked_acc: 0.7652 - val_masked_auc: 0.8093\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.4350 - masked_acc: 0.7653 - masked_auc: 0.8096 - val_loss: 0.4550 - val_masked_acc: 0.7657 - val_masked_auc: 0.8101\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4341 - masked_acc: 0.7658 - masked_auc: 0.8104 - val_loss: 0.4562 - val_masked_acc: 0.7662 - val_masked_auc: 0.8108\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.4345 - masked_acc: 0.7663 - masked_auc: 0.8111 - val_loss: 0.4548 - val_masked_acc: 0.7666 - val_masked_auc: 0.8114\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4368 - masked_acc: 0.7666 - masked_auc: 0.8116 - val_loss: 0.4553 - val_masked_acc: 0.7669 - val_masked_auc: 0.8120\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4296 - masked_acc: 0.7670 - masked_auc: 0.8122 - val_loss: 0.4549 - val_masked_acc: 0.7672 - val_masked_auc: 0.8125\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4353 - masked_acc: 0.7673 - masked_auc: 0.8127 - val_loss: 0.4540 - val_masked_acc: 0.7675 - val_masked_auc: 0.8129\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4365 - masked_acc: 0.7675 - masked_auc: 0.8130 - val_loss: 0.4552 - val_masked_acc: 0.7677 - val_masked_auc: 0.8133\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4365 - masked_acc: 0.7678 - masked_auc: 0.8135 - val_loss: 0.4560 - val_masked_acc: 0.7680 - val_masked_auc: 0.8137\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4428 - masked_acc: 0.7679 - masked_auc: 0.8137 - val_loss: 0.4552 - val_masked_acc: 0.7681 - val_masked_auc: 0.8140\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 131ms/step - loss: 0.4285 - masked_acc: 0.7683 - masked_auc: 0.8141 - val_loss: 0.4568 - val_masked_acc: 0.7683 - val_masked_auc: 0.8142\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4338 - masked_acc: 0.7684 - masked_auc: 0.8142 - val_loss: 0.4544 - val_masked_acc: 0.7685 - val_masked_auc: 0.8145\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4306 - masked_acc: 0.7685 - masked_auc: 0.8145 - val_loss: 0.4547 - val_masked_acc: 0.7686 - val_masked_auc: 0.8147\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4402 - masked_acc: 0.7686 - masked_auc: 0.8148 - val_loss: 0.4558 - val_masked_acc: 0.7688 - val_masked_auc: 0.8149\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4337 - masked_acc: 0.7688 - masked_auc: 0.8150 - val_loss: 0.4556 - val_masked_acc: 0.7689 - val_masked_auc: 0.8151\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.4337 - masked_acc: 0.7690 - masked_auc: 0.8152 - val_loss: 0.4550 - val_masked_acc: 0.7690 - val_masked_auc: 0.8153\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.4287 - masked_acc: 0.7691 - masked_auc: 0.8154 - val_loss: 0.4562 - val_masked_acc: 0.7691 - val_masked_auc: 0.8155\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4340 - masked_acc: 0.7694 - masked_auc: 0.8158\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4327 - masked_acc: 0.7693 - masked_auc: 0.8158\n",
      "Test:  [0.432661771774292, 0.7693144679069519, 0.8157638311386108]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 157ms/step - loss: 0.5756 - masked_acc: 0.6323 - masked_auc: 0.5391 - val_loss: 0.4829 - val_masked_acc: 0.7185 - val_masked_auc: 0.6968\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4496 - masked_acc: 0.7285 - masked_auc: 0.7243 - val_loss: 0.4601 - val_masked_acc: 0.7442 - val_masked_auc: 0.7589\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4480 - masked_acc: 0.7465 - masked_auc: 0.7657 - val_loss: 0.4553 - val_masked_acc: 0.7528 - val_masked_auc: 0.7797\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4323 - masked_acc: 0.7545 - masked_auc: 0.7836 - val_loss: 0.4551 - val_masked_acc: 0.7574 - val_masked_auc: 0.7904\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4351 - masked_acc: 0.7581 - masked_auc: 0.7927 - val_loss: 0.4557 - val_masked_acc: 0.7603 - val_masked_auc: 0.7966\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4310 - masked_acc: 0.7609 - masked_auc: 0.7981 - val_loss: 0.4556 - val_masked_acc: 0.7621 - val_masked_auc: 0.8008\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4451 - masked_acc: 0.7622 - masked_auc: 0.8014 - val_loss: 0.4559 - val_masked_acc: 0.7634 - val_masked_auc: 0.8036\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4346 - masked_acc: 0.7637 - masked_auc: 0.8044 - val_loss: 0.4547 - val_masked_acc: 0.7646 - val_masked_auc: 0.8058\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4322 - masked_acc: 0.7648 - masked_auc: 0.8064 - val_loss: 0.4552 - val_masked_acc: 0.7653 - val_masked_auc: 0.8075\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4333 - masked_acc: 0.7655 - masked_auc: 0.8079 - val_loss: 0.4552 - val_masked_acc: 0.7660 - val_masked_auc: 0.8088\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4438 - masked_acc: 0.7659 - masked_auc: 0.8090 - val_loss: 0.4585 - val_masked_acc: 0.7665 - val_masked_auc: 0.8098\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4353 - masked_acc: 0.7666 - masked_auc: 0.8101 - val_loss: 0.4548 - val_masked_acc: 0.7669 - val_masked_auc: 0.8107\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4392 - masked_acc: 0.7670 - masked_auc: 0.8109 - val_loss: 0.4549 - val_masked_acc: 0.7673 - val_masked_auc: 0.8114\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4313 - masked_acc: 0.7675 - masked_auc: 0.8116 - val_loss: 0.4562 - val_masked_acc: 0.7677 - val_masked_auc: 0.8120\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4401 - masked_acc: 0.7677 - masked_auc: 0.8122 - val_loss: 0.4551 - val_masked_acc: 0.7680 - val_masked_auc: 0.8126\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4328 - masked_acc: 0.7680 - masked_auc: 0.8128 - val_loss: 0.4543 - val_masked_acc: 0.7682 - val_masked_auc: 0.8131\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4407 - masked_acc: 0.7682 - masked_auc: 0.8133 - val_loss: 0.4562 - val_masked_acc: 0.7685 - val_masked_auc: 0.8136\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.4397 - masked_acc: 0.7684 - masked_auc: 0.8136 - val_loss: 0.4586 - val_masked_acc: 0.7686 - val_masked_auc: 0.8140\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.4379 - masked_acc: 0.7686 - masked_auc: 0.8140 - val_loss: 0.4556 - val_masked_acc: 0.7688 - val_masked_auc: 0.8143\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4389 - masked_acc: 0.7688 - masked_auc: 0.8144 - val_loss: 0.4572 - val_masked_acc: 0.7690 - val_masked_auc: 0.8146\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4345 - masked_acc: 0.7690 - masked_auc: 0.8147 - val_loss: 0.4559 - val_masked_acc: 0.7691 - val_masked_auc: 0.8149\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4345 - masked_acc: 0.7691 - masked_auc: 0.8149 - val_loss: 0.4550 - val_masked_acc: 0.7692 - val_masked_auc: 0.8152\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4306 - masked_acc: 0.7693 - masked_auc: 0.8153 - val_loss: 0.4545 - val_masked_acc: 0.7693 - val_masked_auc: 0.8154\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4278 - masked_acc: 0.7694 - masked_auc: 0.8155 - val_loss: 0.4539 - val_masked_acc: 0.7695 - val_masked_auc: 0.8156\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4350 - masked_acc: 0.7695 - masked_auc: 0.8157 - val_loss: 0.4567 - val_masked_acc: 0.7696 - val_masked_auc: 0.8158\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4359 - masked_acc: 0.7696 - masked_auc: 0.8159 - val_loss: 0.4548 - val_masked_acc: 0.7697 - val_masked_auc: 0.8160\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4417 - masked_acc: 0.7696 - masked_auc: 0.8160 - val_loss: 0.4550 - val_masked_acc: 0.7697 - val_masked_auc: 0.8162\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4347 - masked_acc: 0.7698 - masked_auc: 0.8162 - val_loss: 0.4561 - val_masked_acc: 0.7698 - val_masked_auc: 0.8164\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4321 - masked_acc: 0.7698 - masked_auc: 0.8164 - val_loss: 0.4559 - val_masked_acc: 0.7699 - val_masked_auc: 0.8165\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4360 - masked_acc: 0.7699 - masked_auc: 0.8166 - val_loss: 0.4554 - val_masked_acc: 0.7700 - val_masked_auc: 0.8166\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4325 - masked_acc: 0.7700 - masked_auc: 0.8167 - val_loss: 0.4558 - val_masked_acc: 0.7700 - val_masked_auc: 0.8168\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4410 - masked_acc: 0.7700 - masked_auc: 0.8167 - val_loss: 0.4554 - val_masked_acc: 0.7701 - val_masked_auc: 0.8169\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4367 - masked_acc: 0.7700 - masked_auc: 0.8169 - val_loss: 0.4540 - val_masked_acc: 0.7702 - val_masked_auc: 0.8170\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4374 - masked_acc: 0.7701 - masked_auc: 0.8170 - val_loss: 0.4554 - val_masked_acc: 0.7702 - val_masked_auc: 0.8171\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4348 - masked_acc: 0.7704 - masked_auc: 0.8173\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4246 - masked_acc: 0.7703 - masked_auc: 0.8172\n",
      "Test:  [0.4246164858341217, 0.7703022360801697, 0.8172337412834167]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 155ms/step - loss: 0.5671 - masked_acc: 0.6277 - masked_auc: 0.5656 - val_loss: 0.4681 - val_masked_acc: 0.7208 - val_masked_auc: 0.7158\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4545 - masked_acc: 0.7306 - masked_auc: 0.7382 - val_loss: 0.4488 - val_masked_acc: 0.7458 - val_masked_auc: 0.7683\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4378 - masked_acc: 0.7486 - masked_auc: 0.7751 - val_loss: 0.4475 - val_masked_acc: 0.7543 - val_masked_auc: 0.7860\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 130ms/step - loss: 0.4363 - masked_acc: 0.7557 - masked_auc: 0.7890 - val_loss: 0.4452 - val_masked_acc: 0.7588 - val_masked_auc: 0.7951\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4395 - masked_acc: 0.7593 - masked_auc: 0.7967 - val_loss: 0.4455 - val_masked_acc: 0.7617 - val_masked_auc: 0.8004\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4367 - masked_acc: 0.7621 - masked_auc: 0.8015 - val_loss: 0.4491 - val_masked_acc: 0.7634 - val_masked_auc: 0.8037\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.4396 - masked_acc: 0.7637 - masked_auc: 0.8045 - val_loss: 0.4447 - val_masked_acc: 0.7647 - val_masked_auc: 0.8062\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.4424 - masked_acc: 0.7647 - masked_auc: 0.8066 - val_loss: 0.4449 - val_masked_acc: 0.7658 - val_masked_auc: 0.8082\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4386 - masked_acc: 0.7659 - masked_auc: 0.8085 - val_loss: 0.4450 - val_masked_acc: 0.7667 - val_masked_auc: 0.8096\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4370 - masked_acc: 0.7668 - masked_auc: 0.8100 - val_loss: 0.4460 - val_masked_acc: 0.7673 - val_masked_auc: 0.8108\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4361 - masked_acc: 0.7674 - masked_auc: 0.8110 - val_loss: 0.4449 - val_masked_acc: 0.7679 - val_masked_auc: 0.8118\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4383 - masked_acc: 0.7679 - masked_auc: 0.8119 - val_loss: 0.4468 - val_masked_acc: 0.7683 - val_masked_auc: 0.8125\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4344 - masked_acc: 0.7683 - masked_auc: 0.8126 - val_loss: 0.4448 - val_masked_acc: 0.7687 - val_masked_auc: 0.8131\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4418 - masked_acc: 0.7686 - masked_auc: 0.8133 - val_loss: 0.4447 - val_masked_acc: 0.7690 - val_masked_auc: 0.8137\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4336 - masked_acc: 0.7691 - masked_auc: 0.8139 - val_loss: 0.4459 - val_masked_acc: 0.7693 - val_masked_auc: 0.8142\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4373 - masked_acc: 0.7693 - masked_auc: 0.8143 - val_loss: 0.4458 - val_masked_acc: 0.7695 - val_masked_auc: 0.8147\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4362 - masked_acc: 0.7695 - masked_auc: 0.8147 - val_loss: 0.4457 - val_masked_acc: 0.7698 - val_masked_auc: 0.8151\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4358 - masked_acc: 0.7697 - masked_auc: 0.8151 - val_loss: 0.4453 - val_masked_acc: 0.7700 - val_masked_auc: 0.8154\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 130ms/step - loss: 0.4349 - masked_acc: 0.7700 - masked_auc: 0.8155 - val_loss: 0.4474 - val_masked_acc: 0.7701 - val_masked_auc: 0.8157\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4398 - masked_acc: 0.7701 - masked_auc: 0.8157 - val_loss: 0.4458 - val_masked_acc: 0.7703 - val_masked_auc: 0.8160\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4323 - masked_acc: 0.7703 - masked_auc: 0.8161 - val_loss: 0.4461 - val_masked_acc: 0.7704 - val_masked_auc: 0.8162\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4400 - masked_acc: 0.7704 - masked_auc: 0.8162 - val_loss: 0.4458 - val_masked_acc: 0.7706 - val_masked_auc: 0.8165\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4344 - masked_acc: 0.7706 - masked_auc: 0.8165 - val_loss: 0.4448 - val_masked_acc: 0.7707 - val_masked_auc: 0.8167\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4380 - masked_acc: 0.7707 - masked_auc: 0.8167 - val_loss: 0.4450 - val_masked_acc: 0.7708 - val_masked_auc: 0.8169\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4366 - masked_acc: 0.7710 - masked_auc: 0.8171\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4291 - masked_acc: 0.7709 - masked_auc: 0.8171\n",
      "Test:  [0.42911872267723083, 0.7708556652069092, 0.8170729875564575]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 151ms/step - loss: 0.5842 - masked_acc: 0.6074 - masked_auc: 0.5376 - val_loss: 0.4874 - val_masked_acc: 0.7160 - val_masked_auc: 0.6990\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4494 - masked_acc: 0.7266 - masked_auc: 0.7268 - val_loss: 0.4712 - val_masked_acc: 0.7429 - val_masked_auc: 0.7597\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4407 - masked_acc: 0.7457 - masked_auc: 0.7674 - val_loss: 0.4679 - val_masked_acc: 0.7522 - val_masked_auc: 0.7800\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4382 - masked_acc: 0.7534 - masked_auc: 0.7837 - val_loss: 0.4649 - val_masked_acc: 0.7568 - val_masked_auc: 0.7900\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4317 - masked_acc: 0.7577 - masked_auc: 0.7922 - val_loss: 0.4643 - val_masked_acc: 0.7598 - val_masked_auc: 0.7962\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4342 - masked_acc: 0.7604 - masked_auc: 0.7975 - val_loss: 0.4664 - val_masked_acc: 0.7618 - val_masked_auc: 0.8002\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4368 - masked_acc: 0.7620 - masked_auc: 0.8011 - val_loss: 0.4636 - val_masked_acc: 0.7631 - val_masked_auc: 0.8030\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4308 - masked_acc: 0.7636 - masked_auc: 0.8039 - val_loss: 0.4631 - val_masked_acc: 0.7642 - val_masked_auc: 0.8051\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 3s 199ms/step - loss: 0.4362 - masked_acc: 0.7644 - masked_auc: 0.8055 - val_loss: 0.4640 - val_masked_acc: 0.7650 - val_masked_auc: 0.8068\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 4s 275ms/step - loss: 0.4338 - masked_acc: 0.7652 - masked_auc: 0.8071 - val_loss: 0.4622 - val_masked_acc: 0.7657 - val_masked_auc: 0.8081\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 4s 315ms/step - loss: 0.4381 - masked_acc: 0.7658 - masked_auc: 0.8083 - val_loss: 0.4640 - val_masked_acc: 0.7663 - val_masked_auc: 0.8091\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.4311 - masked_acc: 0.7664 - masked_auc: 0.8094 - val_loss: 0.4630 - val_masked_acc: 0.7667 - val_masked_auc: 0.8100\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 4s 305ms/step - loss: 0.4357 - masked_acc: 0.7668 - masked_auc: 0.8103 - val_loss: 0.4639 - val_masked_acc: 0.7672 - val_masked_auc: 0.8108\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 4s 287ms/step - loss: 0.4398 - masked_acc: 0.7671 - masked_auc: 0.8109 - val_loss: 0.4645 - val_masked_acc: 0.7675 - val_masked_auc: 0.8114\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 3s 205ms/step - loss: 0.4357 - masked_acc: 0.7675 - masked_auc: 0.8116 - val_loss: 0.4635 - val_masked_acc: 0.7678 - val_masked_auc: 0.8120\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.4373 - masked_acc: 0.7679 - masked_auc: 0.8120 - val_loss: 0.4626 - val_masked_acc: 0.7681 - val_masked_auc: 0.8124\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 124ms/step - loss: 0.4361 - masked_acc: 0.7681 - masked_auc: 0.8125 - val_loss: 0.4632 - val_masked_acc: 0.7684 - val_masked_auc: 0.8129\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.4356 - masked_acc: 0.7684 - masked_auc: 0.8131 - val_loss: 0.4628 - val_masked_acc: 0.7686 - val_masked_auc: 0.8133\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 132ms/step - loss: 0.4407 - masked_acc: 0.7685 - masked_auc: 0.8133 - val_loss: 0.4634 - val_masked_acc: 0.7688 - val_masked_auc: 0.8137\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.4357 - masked_acc: 0.7688 - masked_auc: 0.8137 - val_loss: 0.4634 - val_masked_acc: 0.7690 - val_masked_auc: 0.8140\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.4349 - masked_acc: 0.7693 - masked_auc: 0.8143\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4204 - masked_acc: 0.7693 - masked_auc: 0.8144\n",
      "Test:  [0.4203777611255646, 0.7692746520042419, 0.814405083656311]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 158ms/step - loss: 0.5739 - masked_acc: 0.6160 - masked_auc: 0.5428 - val_loss: 0.4468 - val_masked_acc: 0.7212 - val_masked_auc: 0.7109\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4504 - masked_acc: 0.7315 - masked_auc: 0.7350 - val_loss: 0.4322 - val_masked_acc: 0.7466 - val_masked_auc: 0.7653\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4375 - masked_acc: 0.7496 - masked_auc: 0.7729 - val_loss: 0.4281 - val_masked_acc: 0.7553 - val_masked_auc: 0.7846\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.4391 - masked_acc: 0.7565 - masked_auc: 0.7881 - val_loss: 0.4274 - val_masked_acc: 0.7598 - val_masked_auc: 0.7942\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4372 - masked_acc: 0.7607 - masked_auc: 0.7962 - val_loss: 0.4271 - val_masked_acc: 0.7626 - val_masked_auc: 0.7998\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.4274 - masked_acc: 0.7633 - masked_auc: 0.8013 - val_loss: 0.4276 - val_masked_acc: 0.7645 - val_masked_auc: 0.8035\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 125ms/step - loss: 0.4397 - masked_acc: 0.7647 - masked_auc: 0.8043 - val_loss: 0.4267 - val_masked_acc: 0.7659 - val_masked_auc: 0.8061\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 0.4360 - masked_acc: 0.7661 - masked_auc: 0.8067 - val_loss: 0.4279 - val_masked_acc: 0.7669 - val_masked_auc: 0.8081\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.4363 - masked_acc: 0.7670 - masked_auc: 0.8086 - val_loss: 0.4267 - val_masked_acc: 0.7678 - val_masked_auc: 0.8096\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.4377 - masked_acc: 0.7679 - masked_auc: 0.8100 - val_loss: 0.4262 - val_masked_acc: 0.7684 - val_masked_auc: 0.8108\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.4394 - masked_acc: 0.7684 - masked_auc: 0.8111 - val_loss: 0.4275 - val_masked_acc: 0.7689 - val_masked_auc: 0.8118\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4362 - masked_acc: 0.7689 - masked_auc: 0.8120 - val_loss: 0.4272 - val_masked_acc: 0.7693 - val_masked_auc: 0.8126\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4407 - masked_acc: 0.7693 - masked_auc: 0.8127 - val_loss: 0.4274 - val_masked_acc: 0.7697 - val_masked_auc: 0.8132\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4410 - masked_acc: 0.7696 - masked_auc: 0.8133 - val_loss: 0.4271 - val_masked_acc: 0.7700 - val_masked_auc: 0.8138\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.4303 - masked_acc: 0.7702 - masked_auc: 0.8141 - val_loss: 0.4277 - val_masked_acc: 0.7703 - val_masked_auc: 0.8143\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.4393 - masked_acc: 0.7702 - masked_auc: 0.8143 - val_loss: 0.4264 - val_masked_acc: 0.7705 - val_masked_auc: 0.8147\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.4381 - masked_acc: 0.7705 - masked_auc: 0.8148 - val_loss: 0.4261 - val_masked_acc: 0.7707 - val_masked_auc: 0.8151\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.4421 - masked_acc: 0.7707 - masked_auc: 0.8152 - val_loss: 0.4267 - val_masked_acc: 0.7709 - val_masked_auc: 0.8155\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.4366 - masked_acc: 0.7709 - masked_auc: 0.8155 - val_loss: 0.4267 - val_masked_acc: 0.7711 - val_masked_auc: 0.8158\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.4359 - masked_acc: 0.7711 - masked_auc: 0.8159 - val_loss: 0.4284 - val_masked_acc: 0.7713 - val_masked_auc: 0.8161\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.4374 - masked_acc: 0.7712 - masked_auc: 0.8162 - val_loss: 0.4265 - val_masked_acc: 0.7714 - val_masked_auc: 0.8164\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4352 - masked_acc: 0.7714 - masked_auc: 0.8164 - val_loss: 0.4271 - val_masked_acc: 0.7716 - val_masked_auc: 0.8166\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.4357 - masked_acc: 0.7715 - masked_auc: 0.8167 - val_loss: 0.4265 - val_masked_acc: 0.7717 - val_masked_auc: 0.8169\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.4378 - masked_acc: 0.7717 - masked_auc: 0.8169 - val_loss: 0.4267 - val_masked_acc: 0.7718 - val_masked_auc: 0.8171\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.4415 - masked_acc: 0.7717 - masked_auc: 0.8171 - val_loss: 0.4277 - val_masked_acc: 0.7719 - val_masked_auc: 0.8173\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.4375 - masked_acc: 0.7719 - masked_auc: 0.8173 - val_loss: 0.4269 - val_masked_acc: 0.7720 - val_masked_auc: 0.8174\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 2s 129ms/step - loss: 0.4352 - masked_acc: 0.7720 - masked_auc: 0.8175 - val_loss: 0.4271 - val_masked_acc: 0.7721 - val_masked_auc: 0.8176\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4352 - masked_acc: 0.7723 - masked_auc: 0.8178\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4543 - masked_acc: 0.7721 - masked_auc: 0.8178\n",
      "Test:  [0.45434609055519104, 0.7721037864685059, 0.8178081512451172]\n"
     ]
    }
   ],
   "source": [
    "# 5 fold cross validation with LSTM-based model\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "    \n",
    "    output = tf.concat([embedding_chap, embedding_sub_chap, embedding_ques, dense_features], axis = 2)\n",
    "\n",
    "    pred = Dense(1, input_shape = (None, 4*EMBEDDING_DIM), activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='logistic_regression'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:51:08.736166Z",
     "iopub.status.busy": "2021-08-08T17:51:08.735502Z",
     "iopub.status.idle": "2021-08-08T17:51:08.745042Z",
     "shell.execute_reply": "2021-08-08T17:51:08.744529Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.771838Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 1.054696,
     "end_time": "2021-08-08T17:51:08.745186",
     "exception": false,
     "start_time": "2021-08-08T17:51:07.690490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.43222416639328004 +/- 0.01181041006083645\n",
      "test avg acc:  0.7703701615333557 +/- 0.0010545532951167036\n",
      "test avg auc:  0.8164567589759827 +/- 0.0012246812515663559\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:51:10.852990Z",
     "iopub.status.busy": "2021-08-08T17:51:10.852027Z",
     "iopub.status.idle": "2021-08-08T17:51:10.861484Z",
     "shell.execute_reply": "2021-08-08T17:51:10.862038Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.782922Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 1.074611,
     "end_time": "2021-08-08T17:51:10.862210",
     "exception": false,
     "start_time": "2021-08-08T17:51:09.787599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.43511608242988586 +/- 0.0008435815838008256\n",
      "train avg acc:  0.7704720735549927 +/- 0.0011106196748008322\n",
      "train avg auc:  0.8164590001106262 +/- 0.0012846862230395833\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 708.279646,
   "end_time": "2021-08-08T17:51:14.729041",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-08T17:39:26.449395",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
