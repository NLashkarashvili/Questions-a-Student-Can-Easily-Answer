{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T17:53:59.695557Z",
     "iopub.status.busy": "2021-08-08T17:53:59.694332Z",
     "iopub.status.idle": "2021-08-08T17:54:06.029102Z",
     "shell.execute_reply": "2021-08-08T17:54:06.028049Z",
     "shell.execute_reply.started": "2021-08-06T21:05:15.103244Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.366772,
     "end_time": "2021-08-08T17:54:06.029281",
     "exception": false,
     "start_time": "2021-08-08T17:53:59.662509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T18:00:28.000917Z",
     "iopub.status.busy": "2021-08-08T18:00:28.000153Z",
     "iopub.status.idle": "2021-08-08T18:00:28.004379Z",
     "shell.execute_reply": "2021-08-08T18:00:28.004860Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.04112Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.36364,
     "end_time": "2021-08-08T18:00:28.005034",
     "exception": false,
     "start_time": "2021-08-08T18:00:27.641394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 400\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T18:00:28.723260Z",
     "iopub.status.busy": "2021-08-08T18:00:28.722611Z",
     "iopub.status.idle": "2021-08-08T18:00:28.725080Z",
     "shell.execute_reply": "2021-08-08T18:00:28.724468Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.049329Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.36214,
     "end_time": "2021-08-08T18:00:28.725215",
     "exception": false,
     "start_time": "2021-08-08T18:00:28.363075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 2\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T18:00:30.165297Z",
     "iopub.status.busy": "2021-08-08T18:00:30.164623Z",
     "iopub.status.idle": "2021-08-08T18:00:31.293766Z",
     "shell.execute_reply": "2021-08-08T18:00:31.293230Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.074094Z"
    },
    "id": "mY3Thp6d0NaT",
    "papermill": {
     "duration": 1.487414,
     "end_time": "2021-08-08T18:00:31.293949",
     "exception": false,
     "start_time": "2021-08-08T18:00:29.806535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create dataset class\n",
    "#to prepare it for train, valid, and test sets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SPACE_DATASET(Dataset):\n",
    "    def __init__(self, data, maxlength = 400):\n",
    "        super(SPACE_DATASET, self).__init__()\n",
    "        self.maxlength = maxlength\n",
    "        self.data = data\n",
    "        self.users = list()\n",
    "        for user in data.index:\n",
    "            self.users.append(user)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        user = self.users[ix]\n",
    "        user = user\n",
    "        target, term, ch_label, sub_ch_label, ques_name, features = self.data[user]\n",
    "        \n",
    "        #0s should be used as padding values\n",
    "        ori_target = target.values \n",
    "        term = term.values\n",
    "        ch_label = ch_label.values + 1\n",
    "        sub_ch_label = sub_ch_label.values +1\n",
    "        ques_name = ques_name.values + 1\n",
    "        \n",
    "        n = len(ch_label)\n",
    "\n",
    "        # one hot for term\n",
    "        term_encode = [0]*7\n",
    "        term_encode[term[0]] = 1\n",
    "        shifted_target= []\n",
    "\n",
    "        \n",
    "        # get  user interaction informations in the previous MAXLEN interactions\n",
    "        if n > self.maxlength:\n",
    "          ch_label = ch_label[-self.maxlength:]\n",
    "          sub_ch_label = sub_ch_label[-self.maxlength:]\n",
    "          ques_name = ques_name[-self.maxlength:]\n",
    "          features = features[-self.maxlength:]\n",
    "          target = ori_target[-self.maxlength:]\n",
    "          shifted_target = ori_target[ (-self.maxlength - 1) :-1]\n",
    "        else:\n",
    "          ch_label = [0]*(self.maxlength - n)+list(ch_label[:])\n",
    "          sub_ch_label = [0]*(self.maxlength - n)+list(sub_ch_label[:])\n",
    "          ques_name = [0]*(self.maxlength - n)+list(ques_name[:])\n",
    "          features = [[0]*len(features[0])]*(self.maxlength  - n)+list(features[:])\n",
    "          target = [-1]*(self.maxlength - n) + list(ori_target[:])\n",
    "          shifted_target = [2]*(self.maxlength + 1 - n) + list(ori_target[:-1])\n",
    "\n",
    "        new_features = []\n",
    "        count = 0\n",
    "        for f in features:\n",
    "          temp = list(f)\n",
    "#           temp.extend(term_encode)\n",
    "          #temp.append(shifted_target[count]) #uncomment this line for include previous response feature\n",
    "          new_features.append(temp)\n",
    "          count += 1\n",
    "        features = new_features\n",
    "        return ch_label,sub_ch_label,ques_name,features, shifted_target, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T18:00:32.012381Z",
     "iopub.status.busy": "2021-08-08T18:00:32.011626Z",
     "iopub.status.idle": "2021-08-08T18:00:32.015842Z",
     "shell.execute_reply": "2021-08-08T18:00:32.015134Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.310275Z"
    },
    "papermill": {
     "duration": 0.366532,
     "end_time": "2021-08-08T18:00:32.015989",
     "exception": false,
     "start_time": "2021-08-08T18:00:31.649457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUB_CHAPTER_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xc90-aLzxat",
    "papermill": {
     "duration": 0.356272,
     "end_time": "2021-08-08T18:00:32.730579",
     "exception": false,
     "start_time": "2021-08-08T18:00:32.374307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## KFOLD - GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T18:00:33.488470Z",
     "iopub.status.busy": "2021-08-08T18:00:33.486532Z",
     "iopub.status.idle": "2021-08-08T18:03:43.528053Z",
     "shell.execute_reply": "2021-08-08T18:03:43.527380Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.318071Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 190.404719,
     "end_time": "2021-08-08T18:03:43.528203",
     "exception": false,
     "start_time": "2021-08-08T18:00:33.123484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 181ms/step - loss: 0.5894 - masked_acc: 0.5927 - masked_auc: 0.5665 - val_loss: 0.4578 - val_masked_acc: 0.7198 - val_masked_auc: 0.6933\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4658 - masked_acc: 0.7292 - masked_auc: 0.7164 - val_loss: 0.4431 - val_masked_acc: 0.7439 - val_masked_auc: 0.7514\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4559 - masked_acc: 0.7459 - masked_auc: 0.7580 - val_loss: 0.4403 - val_masked_acc: 0.7520 - val_masked_auc: 0.7710\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4500 - masked_acc: 0.7530 - masked_auc: 0.7742 - val_loss: 0.4377 - val_masked_acc: 0.7568 - val_masked_auc: 0.7815\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4516 - masked_acc: 0.7571 - masked_auc: 0.7833 - val_loss: 0.4380 - val_masked_acc: 0.7597 - val_masked_auc: 0.7878\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4468 - masked_acc: 0.7600 - masked_auc: 0.7889 - val_loss: 0.4370 - val_masked_acc: 0.7617 - val_masked_auc: 0.7919\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4486 - masked_acc: 0.7619 - masked_auc: 0.7926 - val_loss: 0.4381 - val_masked_acc: 0.7630 - val_masked_auc: 0.7947\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 108ms/step - loss: 0.4450 - masked_acc: 0.7632 - masked_auc: 0.7953 - val_loss: 0.4373 - val_masked_acc: 0.7641 - val_masked_auc: 0.7969\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4456 - masked_acc: 0.7641 - masked_auc: 0.7972 - val_loss: 0.4374 - val_masked_acc: 0.7649 - val_masked_auc: 0.7985\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4514 - masked_acc: 0.7648 - masked_auc: 0.7989 - val_loss: 0.4384 - val_masked_acc: 0.7655 - val_masked_auc: 0.7998\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4397 - masked_acc: 0.7656 - masked_auc: 0.8001 - val_loss: 0.4403 - val_masked_acc: 0.7660 - val_masked_auc: 0.8008\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4472 - masked_acc: 0.7661 - masked_auc: 0.8010 - val_loss: 0.4376 - val_masked_acc: 0.7665 - val_masked_auc: 0.8017\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4483 - masked_acc: 0.7664 - masked_auc: 0.8018 - val_loss: 0.4381 - val_masked_acc: 0.7668 - val_masked_auc: 0.8025\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4461 - masked_acc: 0.7669 - masked_auc: 0.8026 - val_loss: 0.4374 - val_masked_acc: 0.7671 - val_masked_auc: 0.8031\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4446 - masked_acc: 0.7672 - masked_auc: 0.8033 - val_loss: 0.4381 - val_masked_acc: 0.7674 - val_masked_auc: 0.8037\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4421 - masked_acc: 0.7674 - masked_auc: 0.8038 - val_loss: 0.4379 - val_masked_acc: 0.7677 - val_masked_auc: 0.8042\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.4459 - masked_acc: 0.7680 - masked_auc: 0.8045\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4428 - masked_acc: 0.7678 - masked_auc: 0.8046\n",
      "Test:  [0.4427962899208069, 0.7677906155586243, 0.8045549988746643]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 164ms/step - loss: 0.5916 - masked_acc: 0.6657 - masked_auc: 0.5745 - val_loss: 0.4764 - val_masked_acc: 0.7279 - val_masked_auc: 0.7001\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4619 - masked_acc: 0.7363 - masked_auc: 0.7212 - val_loss: 0.4519 - val_masked_acc: 0.7478 - val_masked_auc: 0.7530\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4543 - masked_acc: 0.7495 - masked_auc: 0.7601 - val_loss: 0.4501 - val_masked_acc: 0.7548 - val_masked_auc: 0.7725\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.4478 - masked_acc: 0.7559 - masked_auc: 0.7759 - val_loss: 0.4488 - val_masked_acc: 0.7586 - val_masked_auc: 0.7823\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4436 - masked_acc: 0.7593 - masked_auc: 0.7846 - val_loss: 0.4485 - val_masked_acc: 0.7609 - val_masked_auc: 0.7882\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4453 - masked_acc: 0.7611 - masked_auc: 0.7893 - val_loss: 0.4484 - val_masked_acc: 0.7625 - val_masked_auc: 0.7921\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4483 - masked_acc: 0.7626 - masked_auc: 0.7929 - val_loss: 0.4486 - val_masked_acc: 0.7636 - val_masked_auc: 0.7949\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4482 - masked_acc: 0.7637 - masked_auc: 0.7956 - val_loss: 0.4480 - val_masked_acc: 0.7644 - val_masked_auc: 0.7969\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4452 - masked_acc: 0.7645 - masked_auc: 0.7974 - val_loss: 0.4487 - val_masked_acc: 0.7651 - val_masked_auc: 0.7985\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4547 - masked_acc: 0.7649 - masked_auc: 0.7987 - val_loss: 0.4489 - val_masked_acc: 0.7656 - val_masked_auc: 0.7998\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4416 - masked_acc: 0.7656 - masked_auc: 0.8002 - val_loss: 0.4490 - val_masked_acc: 0.7659 - val_masked_auc: 0.8008\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4488 - masked_acc: 0.7659 - masked_auc: 0.8010 - val_loss: 0.4507 - val_masked_acc: 0.7662 - val_masked_auc: 0.8016\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4468 - masked_acc: 0.7662 - masked_auc: 0.8017 - val_loss: 0.4481 - val_masked_acc: 0.7665 - val_masked_auc: 0.8023\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4533 - masked_acc: 0.7664 - masked_auc: 0.8024 - val_loss: 0.4489 - val_masked_acc: 0.7667 - val_masked_auc: 0.8029\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4447 - masked_acc: 0.7668 - masked_auc: 0.8031 - val_loss: 0.4479 - val_masked_acc: 0.7670 - val_masked_auc: 0.8034\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4455 - masked_acc: 0.7670 - masked_auc: 0.8035 - val_loss: 0.4489 - val_masked_acc: 0.7672 - val_masked_auc: 0.8039\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4479 - masked_acc: 0.7671 - masked_auc: 0.8040 - val_loss: 0.4484 - val_masked_acc: 0.7674 - val_masked_auc: 0.8043\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 112ms/step - loss: 0.4479 - masked_acc: 0.7673 - masked_auc: 0.8045 - val_loss: 0.4486 - val_masked_acc: 0.7675 - val_masked_auc: 0.8047\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 108ms/step - loss: 0.4402 - masked_acc: 0.7675 - masked_auc: 0.8048 - val_loss: 0.4486 - val_masked_acc: 0.7676 - val_masked_auc: 0.8051\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4541 - masked_acc: 0.7676 - masked_auc: 0.8051 - val_loss: 0.4509 - val_masked_acc: 0.7678 - val_masked_auc: 0.8053\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 116ms/step - loss: 0.4477 - masked_acc: 0.7677 - masked_auc: 0.8054 - val_loss: 0.4482 - val_masked_acc: 0.7679 - val_masked_auc: 0.8056\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4534 - masked_acc: 0.7678 - masked_auc: 0.8056 - val_loss: 0.4492 - val_masked_acc: 0.7680 - val_masked_auc: 0.8058\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4491 - masked_acc: 0.7679 - masked_auc: 0.8058 - val_loss: 0.4484 - val_masked_acc: 0.7681 - val_masked_auc: 0.8060\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4490 - masked_acc: 0.7680 - masked_auc: 0.8061 - val_loss: 0.4483 - val_masked_acc: 0.7681 - val_masked_auc: 0.8062\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4406 - masked_acc: 0.7682 - masked_auc: 0.8063 - val_loss: 0.4482 - val_masked_acc: 0.7682 - val_masked_auc: 0.8064\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4462 - masked_acc: 0.7684 - masked_auc: 0.8067\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4278 - masked_acc: 0.7684 - masked_auc: 0.8067\n",
      "Test:  [0.4277721345424652, 0.7683572173118591, 0.8066724538803101]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 147ms/step - loss: 0.5800 - masked_acc: 0.6478 - masked_auc: 0.6141 - val_loss: 0.4904 - val_masked_acc: 0.7333 - val_masked_auc: 0.7064\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4585 - masked_acc: 0.7403 - masked_auc: 0.7253 - val_loss: 0.4688 - val_masked_acc: 0.7512 - val_masked_auc: 0.7575\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4470 - masked_acc: 0.7533 - masked_auc: 0.7642 - val_loss: 0.4655 - val_masked_acc: 0.7575 - val_masked_auc: 0.7755\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4417 - masked_acc: 0.7584 - masked_auc: 0.7788 - val_loss: 0.4646 - val_masked_acc: 0.7609 - val_masked_auc: 0.7848\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4397 - masked_acc: 0.7616 - masked_auc: 0.7865 - val_loss: 0.4641 - val_masked_acc: 0.7630 - val_masked_auc: 0.7904\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4444 - masked_acc: 0.7633 - masked_auc: 0.7915 - val_loss: 0.4645 - val_masked_acc: 0.7643 - val_masked_auc: 0.7940\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4460 - masked_acc: 0.7643 - masked_auc: 0.7946 - val_loss: 0.4663 - val_masked_acc: 0.7652 - val_masked_auc: 0.7966\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4404 - masked_acc: 0.7654 - masked_auc: 0.7971 - val_loss: 0.4643 - val_masked_acc: 0.7660 - val_masked_auc: 0.7984\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4419 - masked_acc: 0.7662 - masked_auc: 0.7989 - val_loss: 0.4642 - val_masked_acc: 0.7666 - val_masked_auc: 0.7999\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 113ms/step - loss: 0.4457 - masked_acc: 0.7665 - masked_auc: 0.8003 - val_loss: 0.4648 - val_masked_acc: 0.7670 - val_masked_auc: 0.8011\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4503 - masked_acc: 0.7670 - masked_auc: 0.8013 - val_loss: 0.4651 - val_masked_acc: 0.7674 - val_masked_auc: 0.8021\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4392 - masked_acc: 0.7675 - masked_auc: 0.8024 - val_loss: 0.4642 - val_masked_acc: 0.7677 - val_masked_auc: 0.8029\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 108ms/step - loss: 0.4396 - masked_acc: 0.7678 - masked_auc: 0.8032 - val_loss: 0.4634 - val_masked_acc: 0.7680 - val_masked_auc: 0.8036\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4435 - masked_acc: 0.7680 - masked_auc: 0.8038 - val_loss: 0.4635 - val_masked_acc: 0.7682 - val_masked_auc: 0.8042\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4431 - masked_acc: 0.7682 - masked_auc: 0.8042 - val_loss: 0.4664 - val_masked_acc: 0.7684 - val_masked_auc: 0.8047\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4530 - masked_acc: 0.7682 - masked_auc: 0.8047 - val_loss: 0.4666 - val_masked_acc: 0.7685 - val_masked_auc: 0.8051\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4448 - masked_acc: 0.7685 - masked_auc: 0.8052 - val_loss: 0.4639 - val_masked_acc: 0.7687 - val_masked_auc: 0.8054\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4400 - masked_acc: 0.7688 - masked_auc: 0.8056 - val_loss: 0.4634 - val_masked_acc: 0.7688 - val_masked_auc: 0.8058\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4459 - masked_acc: 0.7688 - masked_auc: 0.8058 - val_loss: 0.4645 - val_masked_acc: 0.7689 - val_masked_auc: 0.8061\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4480 - masked_acc: 0.7689 - masked_auc: 0.8060 - val_loss: 0.4645 - val_masked_acc: 0.7690 - val_masked_auc: 0.8063\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4435 - masked_acc: 0.7690 - masked_auc: 0.8064 - val_loss: 0.4631 - val_masked_acc: 0.7691 - val_masked_auc: 0.8066\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4448 - masked_acc: 0.7691 - masked_auc: 0.8066 - val_loss: 0.4650 - val_masked_acc: 0.7692 - val_masked_auc: 0.8068\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4457 - masked_acc: 0.7692 - masked_auc: 0.8069 - val_loss: 0.4644 - val_masked_acc: 0.7693 - val_masked_auc: 0.8070\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 2s 122ms/step - loss: 0.4401 - masked_acc: 0.7693 - masked_auc: 0.8071 - val_loss: 0.4639 - val_masked_acc: 0.7694 - val_masked_auc: 0.8072\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4482 - masked_acc: 0.7694 - masked_auc: 0.8073 - val_loss: 0.4638 - val_masked_acc: 0.7695 - val_masked_auc: 0.8074\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4468 - masked_acc: 0.7694 - masked_auc: 0.8074 - val_loss: 0.4642 - val_masked_acc: 0.7695 - val_masked_auc: 0.8076\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4448 - masked_acc: 0.7695 - masked_auc: 0.8076 - val_loss: 0.4696 - val_masked_acc: 0.7696 - val_masked_auc: 0.8077\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4494 - masked_acc: 0.7695 - masked_auc: 0.8077 - val_loss: 0.4639 - val_masked_acc: 0.7696 - val_masked_auc: 0.8078\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4429 - masked_acc: 0.7696 - masked_auc: 0.8079 - val_loss: 0.4634 - val_masked_acc: 0.7697 - val_masked_auc: 0.8080\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4569 - masked_acc: 0.7696 - masked_auc: 0.8080 - val_loss: 0.4658 - val_masked_acc: 0.7697 - val_masked_auc: 0.8081\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.4423 - masked_acc: 0.7697 - masked_auc: 0.8081 - val_loss: 0.4662 - val_masked_acc: 0.7698 - val_masked_auc: 0.8082\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.4436 - masked_acc: 0.7699 - masked_auc: 0.8084\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4378 - masked_acc: 0.7699 - masked_auc: 0.8083\n",
      "Test:  [0.4378395676612854, 0.7698503732681274, 0.8083392381668091]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 150ms/step - loss: 0.5891 - masked_acc: 0.6276 - masked_auc: 0.5783 - val_loss: 0.5102 - val_masked_acc: 0.7264 - val_masked_auc: 0.6960\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4752 - masked_acc: 0.7334 - masked_auc: 0.7164 - val_loss: 0.4869 - val_masked_acc: 0.7477 - val_masked_auc: 0.7522\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4497 - masked_acc: 0.7496 - masked_auc: 0.7588 - val_loss: 0.4827 - val_masked_acc: 0.7549 - val_masked_auc: 0.7717\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4368 - masked_acc: 0.7566 - masked_auc: 0.7755 - val_loss: 0.4814 - val_masked_acc: 0.7588 - val_masked_auc: 0.7818\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4363 - masked_acc: 0.7600 - masked_auc: 0.7842 - val_loss: 0.4823 - val_masked_acc: 0.7614 - val_masked_auc: 0.7879\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4415 - masked_acc: 0.7618 - masked_auc: 0.7891 - val_loss: 0.4822 - val_masked_acc: 0.7630 - val_masked_auc: 0.7919\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4362 - masked_acc: 0.7634 - masked_auc: 0.7929 - val_loss: 0.4816 - val_masked_acc: 0.7643 - val_masked_auc: 0.7948\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4354 - masked_acc: 0.7647 - masked_auc: 0.7956 - val_loss: 0.4806 - val_masked_acc: 0.7652 - val_masked_auc: 0.7969\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4478 - masked_acc: 0.7652 - masked_auc: 0.7972 - val_loss: 0.4835 - val_masked_acc: 0.7659 - val_masked_auc: 0.7985\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4495 - masked_acc: 0.7658 - masked_auc: 0.7987 - val_loss: 0.4821 - val_masked_acc: 0.7665 - val_masked_auc: 0.7998\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 117ms/step - loss: 0.4340 - masked_acc: 0.7667 - masked_auc: 0.8002 - val_loss: 0.4807 - val_masked_acc: 0.7670 - val_masked_auc: 0.8008\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4355 - masked_acc: 0.7671 - masked_auc: 0.8011 - val_loss: 0.4819 - val_masked_acc: 0.7673 - val_masked_auc: 0.8017\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 108ms/step - loss: 0.4473 - masked_acc: 0.7672 - masked_auc: 0.8018 - val_loss: 0.4839 - val_masked_acc: 0.7676 - val_masked_auc: 0.8024\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4472 - masked_acc: 0.7676 - masked_auc: 0.8026 - val_loss: 0.4826 - val_masked_acc: 0.7679 - val_masked_auc: 0.8030\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 1s 104ms/step - loss: 0.4404 - masked_acc: 0.7679 - masked_auc: 0.8032 - val_loss: 0.4820 - val_masked_acc: 0.7681 - val_masked_auc: 0.8036\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4430 - masked_acc: 0.7682 - masked_auc: 0.8037 - val_loss: 0.4847 - val_masked_acc: 0.7684 - val_masked_auc: 0.8040\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4417 - masked_acc: 0.7684 - masked_auc: 0.8041 - val_loss: 0.4810 - val_masked_acc: 0.7685 - val_masked_auc: 0.8044\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 114ms/step - loss: 0.4387 - masked_acc: 0.7686 - masked_auc: 0.8045 - val_loss: 0.4807 - val_masked_acc: 0.7687 - val_masked_auc: 0.8048\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4416 - masked_acc: 0.7690 - masked_auc: 0.8051\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4369 - masked_acc: 0.7689 - masked_auc: 0.8052\n",
      "Test:  [0.43689557909965515, 0.7688919305801392, 0.8051703572273254]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 148ms/step - loss: 0.5884 - masked_acc: 0.6344 - masked_auc: 0.5759 - val_loss: 0.4556 - val_masked_acc: 0.7269 - val_masked_auc: 0.6946\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 110ms/step - loss: 0.4644 - masked_acc: 0.7358 - masked_auc: 0.7181 - val_loss: 0.4408 - val_masked_acc: 0.7481 - val_masked_auc: 0.7523\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4494 - masked_acc: 0.7499 - masked_auc: 0.7590 - val_loss: 0.4378 - val_masked_acc: 0.7555 - val_masked_auc: 0.7719\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4507 - masked_acc: 0.7562 - masked_auc: 0.7750 - val_loss: 0.4369 - val_masked_acc: 0.7598 - val_masked_auc: 0.7821\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.4545 - masked_acc: 0.7599 - masked_auc: 0.7838 - val_loss: 0.4363 - val_masked_acc: 0.7624 - val_masked_auc: 0.7881\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4452 - masked_acc: 0.7626 - masked_auc: 0.7892 - val_loss: 0.4363 - val_masked_acc: 0.7641 - val_masked_auc: 0.7920\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4388 - masked_acc: 0.7644 - masked_auc: 0.7930 - val_loss: 0.4374 - val_masked_acc: 0.7653 - val_masked_auc: 0.7948\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 103ms/step - loss: 0.4408 - masked_acc: 0.7655 - masked_auc: 0.7955 - val_loss: 0.4359 - val_masked_acc: 0.7661 - val_masked_auc: 0.7969\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 105ms/step - loss: 0.4462 - masked_acc: 0.7662 - masked_auc: 0.7973 - val_loss: 0.4364 - val_masked_acc: 0.7668 - val_masked_auc: 0.7985\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 126ms/step - loss: 0.4492 - masked_acc: 0.7667 - masked_auc: 0.7988 - val_loss: 0.4360 - val_masked_acc: 0.7674 - val_masked_auc: 0.7998\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 109ms/step - loss: 0.4419 - masked_acc: 0.7675 - masked_auc: 0.8001 - val_loss: 0.4365 - val_masked_acc: 0.7679 - val_masked_auc: 0.8008\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 108ms/step - loss: 0.4436 - masked_acc: 0.7678 - masked_auc: 0.8010 - val_loss: 0.4367 - val_masked_acc: 0.7683 - val_masked_auc: 0.8017\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 106ms/step - loss: 0.4457 - masked_acc: 0.7682 - masked_auc: 0.8019 - val_loss: 0.4362 - val_masked_acc: 0.7685 - val_masked_auc: 0.8024\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4403 - masked_acc: 0.7686 - masked_auc: 0.8027 - val_loss: 0.4364 - val_masked_acc: 0.7688 - val_masked_auc: 0.8030\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 108ms/step - loss: 0.4407 - masked_acc: 0.7688 - masked_auc: 0.8032 - val_loss: 0.4361 - val_masked_acc: 0.7691 - val_masked_auc: 0.8035\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 115ms/step - loss: 0.4443 - masked_acc: 0.7690 - masked_auc: 0.8037 - val_loss: 0.4363 - val_masked_acc: 0.7693 - val_masked_auc: 0.8040\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.4524 - masked_acc: 0.7692 - masked_auc: 0.8041 - val_loss: 0.4361 - val_masked_acc: 0.7694 - val_masked_auc: 0.8044\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 1s 107ms/step - loss: 0.4323 - masked_acc: 0.7695 - masked_auc: 0.8046 - val_loss: 0.4366 - val_masked_acc: 0.7696 - val_masked_auc: 0.8048\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.4437 - masked_acc: 0.7699 - masked_auc: 0.8051\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4611 - masked_acc: 0.7697 - masked_auc: 0.8052\n",
      "Test:  [0.46114620566368103, 0.7697298526763916, 0.805233895778656]\n"
     ]
    }
   ],
   "source": [
    "# 5 fold cross validation with LSTM-based model\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "    \n",
    "    output = tf.concat([embedding_chap, embedding_sub_chap, embedding_ques, dense_features], axis = 2)\n",
    "\n",
    "    pred = Dense(1, input_shape = (None, 4*EMBEDDING_DIM), activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='logistic_regression'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T18:03:45.403935Z",
     "iopub.status.busy": "2021-08-08T18:03:45.403258Z",
     "iopub.status.idle": "2021-08-08T18:03:45.409081Z",
     "shell.execute_reply": "2021-08-08T18:03:45.409541Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.771838Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.910577,
     "end_time": "2021-08-08T18:03:45.409722",
     "exception": false,
     "start_time": "2021-08-08T18:03:44.499145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.44128995537757876 +/- 0.011049768482420026\n",
      "test avg acc:  0.7689239978790283 +/- 0.0007892271312043337\n",
      "test avg auc:  0.805994188785553 +/- 0.0013628874958386892\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T18:03:47.213921Z",
     "iopub.status.busy": "2021-08-08T18:03:47.212969Z",
     "iopub.status.idle": "2021-08-08T18:03:47.217071Z",
     "shell.execute_reply": "2021-08-08T18:03:47.216451Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.782922Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.906324,
     "end_time": "2021-08-08T18:03:47.217207",
     "exception": false,
     "start_time": "2021-08-08T18:03:46.310883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.44420082569122316 +/- 0.0017107781008522593\n",
      "train avg acc:  0.7690568566322327 +/- 0.0007747308503602136\n",
      "train avg auc:  0.8059497594833374 +/- 0.0013989418387437402\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 598.149486,
   "end_time": "2021-08-08T18:03:49.855730",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-08T17:53:51.706244",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
