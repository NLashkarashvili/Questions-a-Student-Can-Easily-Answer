{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T15:30:42.928830Z",
     "iopub.status.busy": "2021-08-08T15:30:42.928123Z",
     "iopub.status.idle": "2021-08-08T15:30:49.823568Z",
     "shell.execute_reply": "2021-08-08T15:30:49.822863Z",
     "shell.execute_reply.started": "2021-08-06T21:05:15.103244Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.938714,
     "end_time": "2021-08-08T15:30:49.823803",
     "exception": false,
     "start_time": "2021-08-08T15:30:42.885089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T15:38:38.170720Z",
     "iopub.status.busy": "2021-08-08T15:38:38.169765Z",
     "iopub.status.idle": "2021-08-08T15:38:38.172959Z",
     "shell.execute_reply": "2021-08-08T15:38:38.172306Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.04112Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.368506,
     "end_time": "2021-08-08T15:38:38.173113",
     "exception": false,
     "start_time": "2021-08-08T15:38:37.804607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 400\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T15:38:38.901664Z",
     "iopub.status.busy": "2021-08-08T15:38:38.900948Z",
     "iopub.status.idle": "2021-08-08T15:38:38.903559Z",
     "shell.execute_reply": "2021-08-08T15:38:38.904009Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.049329Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.370205,
     "end_time": "2021-08-08T15:38:38.904219",
     "exception": false,
     "start_time": "2021-08-08T15:38:38.534014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 37\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T15:38:43.623819Z",
     "iopub.status.busy": "2021-08-08T15:38:43.618636Z",
     "iopub.status.idle": "2021-08-08T15:44:16.398911Z",
     "shell.execute_reply": "2021-08-08T15:44:16.399853Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.318071Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 333.151788,
     "end_time": "2021-08-08T15:44:16.400241",
     "exception": false,
     "start_time": "2021-08-08T15:38:43.248453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 5s 240ms/step - loss: 0.5919 - masked_acc: 0.5624 - masked_auc: 0.5556 - val_loss: 0.4653 - val_masked_acc: 0.7102 - val_masked_auc: 0.7002\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.4499 - masked_acc: 0.7228 - masked_auc: 0.7287 - val_loss: 0.4391 - val_masked_acc: 0.7421 - val_masked_auc: 0.7646\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.4384 - masked_acc: 0.7459 - masked_auc: 0.7722 - val_loss: 0.4384 - val_masked_acc: 0.7536 - val_masked_auc: 0.7863\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.4322 - masked_acc: 0.7552 - masked_auc: 0.7899 - val_loss: 0.4358 - val_masked_acc: 0.7593 - val_masked_auc: 0.7972\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.4335 - masked_acc: 0.7599 - masked_auc: 0.7994 - val_loss: 0.4361 - val_masked_acc: 0.7628 - val_masked_auc: 0.8036\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.4313 - masked_acc: 0.7634 - masked_auc: 0.8050 - val_loss: 0.4354 - val_masked_acc: 0.7651 - val_masked_auc: 0.8080\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.4307 - masked_acc: 0.7655 - masked_auc: 0.8088 - val_loss: 0.4352 - val_masked_acc: 0.7668 - val_masked_auc: 0.8110\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.4327 - masked_acc: 0.7671 - masked_auc: 0.8117 - val_loss: 0.4349 - val_masked_acc: 0.7680 - val_masked_auc: 0.8132\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.4320 - masked_acc: 0.7682 - masked_auc: 0.8137 - val_loss: 0.4359 - val_masked_acc: 0.7689 - val_masked_auc: 0.8149\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.4367 - masked_acc: 0.7689 - masked_auc: 0.8152 - val_loss: 0.4343 - val_masked_acc: 0.7697 - val_masked_auc: 0.8162\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.4328 - masked_acc: 0.7698 - masked_auc: 0.8166 - val_loss: 0.4349 - val_masked_acc: 0.7703 - val_masked_auc: 0.8174\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4288 - masked_acc: 0.7704 - masked_auc: 0.8176 - val_loss: 0.4346 - val_masked_acc: 0.7709 - val_masked_auc: 0.8183\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.4291 - masked_acc: 0.7710 - masked_auc: 0.8186 - val_loss: 0.4357 - val_masked_acc: 0.7713 - val_masked_auc: 0.8191\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4271 - masked_acc: 0.7714 - masked_auc: 0.8193 - val_loss: 0.4356 - val_masked_acc: 0.7717 - val_masked_auc: 0.8198\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.4216 - masked_acc: 0.7719 - masked_auc: 0.8201 - val_loss: 0.4345 - val_masked_acc: 0.7721 - val_masked_auc: 0.8204\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4321 - masked_acc: 0.7720 - masked_auc: 0.8205 - val_loss: 0.4355 - val_masked_acc: 0.7723 - val_masked_auc: 0.8209\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4324 - masked_acc: 0.7723 - masked_auc: 0.8210 - val_loss: 0.4352 - val_masked_acc: 0.7726 - val_masked_auc: 0.8213\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4315 - masked_acc: 0.7726 - masked_auc: 0.8214 - val_loss: 0.4351 - val_masked_acc: 0.7728 - val_masked_auc: 0.8217\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4333 - masked_acc: 0.7728 - masked_auc: 0.8218 - val_loss: 0.4356 - val_masked_acc: 0.7730 - val_masked_auc: 0.8221\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4282 - masked_acc: 0.7731 - masked_auc: 0.8222 - val_loss: 0.4346 - val_masked_acc: 0.7732 - val_masked_auc: 0.8225\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4284 - masked_acc: 0.7736 - masked_auc: 0.8228\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4362 - masked_acc: 0.7735 - masked_auc: 0.8228\n",
      "Test:  [0.43617942929267883, 0.7734513282775879, 0.8227863311767578]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 197ms/step - loss: 0.5774 - masked_acc: 0.6070 - masked_auc: 0.5372 - val_loss: 0.4461 - val_masked_acc: 0.7222 - val_masked_auc: 0.7125\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4553 - masked_acc: 0.7317 - masked_auc: 0.7357 - val_loss: 0.4326 - val_masked_acc: 0.7483 - val_masked_auc: 0.7689\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4385 - masked_acc: 0.7508 - masked_auc: 0.7762 - val_loss: 0.4266 - val_masked_acc: 0.7570 - val_masked_auc: 0.7886\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.4339 - masked_acc: 0.7584 - masked_auc: 0.7921 - val_loss: 0.4247 - val_masked_acc: 0.7618 - val_masked_auc: 0.7988\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4286 - masked_acc: 0.7624 - masked_auc: 0.8006 - val_loss: 0.4240 - val_masked_acc: 0.7646 - val_masked_auc: 0.8048\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4326 - masked_acc: 0.7650 - masked_auc: 0.8061 - val_loss: 0.4250 - val_masked_acc: 0.7666 - val_masked_auc: 0.8087\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4308 - masked_acc: 0.7668 - masked_auc: 0.8097 - val_loss: 0.4250 - val_masked_acc: 0.7679 - val_masked_auc: 0.8115\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4340 - masked_acc: 0.7680 - masked_auc: 0.8120 - val_loss: 0.4245 - val_masked_acc: 0.7690 - val_masked_auc: 0.8135\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.4326 - masked_acc: 0.7690 - masked_auc: 0.8141 - val_loss: 0.4233 - val_masked_acc: 0.7698 - val_masked_auc: 0.8151\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4331 - masked_acc: 0.7698 - masked_auc: 0.8155 - val_loss: 0.4238 - val_masked_acc: 0.7704 - val_masked_auc: 0.8164\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4252 - masked_acc: 0.7706 - masked_auc: 0.8167 - val_loss: 0.4242 - val_masked_acc: 0.7710 - val_masked_auc: 0.8174\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4323 - masked_acc: 0.7711 - masked_auc: 0.8175 - val_loss: 0.4249 - val_masked_acc: 0.7715 - val_masked_auc: 0.8182\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4333 - masked_acc: 0.7715 - masked_auc: 0.8184 - val_loss: 0.4241 - val_masked_acc: 0.7718 - val_masked_auc: 0.8189\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.4407 - masked_acc: 0.7717 - masked_auc: 0.8189 - val_loss: 0.4237 - val_masked_acc: 0.7721 - val_masked_auc: 0.8195\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4280 - masked_acc: 0.7722 - masked_auc: 0.8196 - val_loss: 0.4245 - val_masked_acc: 0.7725 - val_masked_auc: 0.8200\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4350 - masked_acc: 0.7724 - masked_auc: 0.8201 - val_loss: 0.4251 - val_masked_acc: 0.7727 - val_masked_auc: 0.8205\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4330 - masked_acc: 0.7727 - masked_auc: 0.8205 - val_loss: 0.4242 - val_masked_acc: 0.7729 - val_masked_auc: 0.8209\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4350 - masked_acc: 0.7729 - masked_auc: 0.8210 - val_loss: 0.4241 - val_masked_acc: 0.7731 - val_masked_auc: 0.8213\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4290 - masked_acc: 0.7731 - masked_auc: 0.8214 - val_loss: 0.4241 - val_masked_acc: 0.7733 - val_masked_auc: 0.8216\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4314 - masked_acc: 0.7736 - masked_auc: 0.8219\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.4316 - masked_acc: 0.7733 - masked_auc: 0.8219\n",
      "Test:  [0.4315876364707947, 0.7733361721038818, 0.8218574523925781]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 190ms/step - loss: 0.5645 - masked_acc: 0.6342 - masked_auc: 0.5611 - val_loss: 0.4777 - val_masked_acc: 0.7252 - val_masked_auc: 0.7227\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4456 - masked_acc: 0.7349 - masked_auc: 0.7458 - val_loss: 0.4637 - val_masked_acc: 0.7492 - val_masked_auc: 0.7741\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4330 - masked_acc: 0.7519 - masked_auc: 0.7802 - val_loss: 0.4602 - val_masked_acc: 0.7573 - val_masked_auc: 0.7918\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.4321 - masked_acc: 0.7586 - masked_auc: 0.7951 - val_loss: 0.4570 - val_masked_acc: 0.7616 - val_masked_auc: 0.8009\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4326 - masked_acc: 0.7621 - masked_auc: 0.8027 - val_loss: 0.4584 - val_masked_acc: 0.7643 - val_masked_auc: 0.8062\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4280 - masked_acc: 0.7648 - masked_auc: 0.8076 - val_loss: 0.4579 - val_masked_acc: 0.7660 - val_masked_auc: 0.8098\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4327 - masked_acc: 0.7662 - masked_auc: 0.8105 - val_loss: 0.4583 - val_masked_acc: 0.7672 - val_masked_auc: 0.8123\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4263 - masked_acc: 0.7675 - masked_auc: 0.8130 - val_loss: 0.4571 - val_masked_acc: 0.7682 - val_masked_auc: 0.8142\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.4343 - masked_acc: 0.7683 - masked_auc: 0.8146 - val_loss: 0.4583 - val_masked_acc: 0.7690 - val_masked_auc: 0.8156\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4286 - masked_acc: 0.7691 - masked_auc: 0.8160 - val_loss: 0.4569 - val_masked_acc: 0.7695 - val_masked_auc: 0.8168\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4303 - masked_acc: 0.7696 - masked_auc: 0.8171 - val_loss: 0.4571 - val_masked_acc: 0.7700 - val_masked_auc: 0.8177\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.4271 - masked_acc: 0.7701 - masked_auc: 0.8180 - val_loss: 0.4567 - val_masked_acc: 0.7705 - val_masked_auc: 0.8185\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4340 - masked_acc: 0.7705 - masked_auc: 0.8186 - val_loss: 0.4573 - val_masked_acc: 0.7708 - val_masked_auc: 0.8191\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4305 - masked_acc: 0.7708 - masked_auc: 0.8193 - val_loss: 0.4565 - val_masked_acc: 0.7711 - val_masked_auc: 0.8197\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4272 - masked_acc: 0.7712 - masked_auc: 0.8199 - val_loss: 0.4591 - val_masked_acc: 0.7714 - val_masked_auc: 0.8202\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4309 - masked_acc: 0.7714 - masked_auc: 0.8204 - val_loss: 0.4576 - val_masked_acc: 0.7716 - val_masked_auc: 0.8206\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4327 - masked_acc: 0.7716 - masked_auc: 0.8206 - val_loss: 0.4581 - val_masked_acc: 0.7718 - val_masked_auc: 0.8209\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4307 - masked_acc: 0.7718 - masked_auc: 0.8210 - val_loss: 0.4589 - val_masked_acc: 0.7720 - val_masked_auc: 0.8213\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.4244 - masked_acc: 0.7720 - masked_auc: 0.8213 - val_loss: 0.4568 - val_masked_acc: 0.7721 - val_masked_auc: 0.8215\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4283 - masked_acc: 0.7721 - masked_auc: 0.8216 - val_loss: 0.4573 - val_masked_acc: 0.7722 - val_masked_auc: 0.8218\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4373 - masked_acc: 0.7722 - masked_auc: 0.8218 - val_loss: 0.4572 - val_masked_acc: 0.7724 - val_masked_auc: 0.8220\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4328 - masked_acc: 0.7723 - masked_auc: 0.8221 - val_loss: 0.4575 - val_masked_acc: 0.7725 - val_masked_auc: 0.8222\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.4311 - masked_acc: 0.7725 - masked_auc: 0.8222 - val_loss: 0.4570 - val_masked_acc: 0.7726 - val_masked_auc: 0.8224\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4271 - masked_acc: 0.7726 - masked_auc: 0.8224 - val_loss: 0.4573 - val_masked_acc: 0.7727 - val_masked_auc: 0.8226\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4281 - masked_acc: 0.7729 - masked_auc: 0.8229\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4150 - masked_acc: 0.7729 - masked_auc: 0.8229\n",
      "Test:  [0.41504985094070435, 0.7728535532951355, 0.8229106664657593]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 199ms/step - loss: 0.5613 - masked_acc: 0.6233 - masked_auc: 0.5728 - val_loss: 0.4512 - val_masked_acc: 0.7251 - val_masked_auc: 0.7240\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4508 - masked_acc: 0.7337 - masked_auc: 0.7452 - val_loss: 0.4373 - val_masked_acc: 0.7494 - val_masked_auc: 0.7740\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.4367 - masked_acc: 0.7518 - masked_auc: 0.7804 - val_loss: 0.4324 - val_masked_acc: 0.7576 - val_masked_auc: 0.7918\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4309 - masked_acc: 0.7592 - masked_auc: 0.7951 - val_loss: 0.4308 - val_masked_acc: 0.7620 - val_masked_auc: 0.8008\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.4296 - masked_acc: 0.7626 - masked_auc: 0.8024 - val_loss: 0.4303 - val_masked_acc: 0.7647 - val_masked_auc: 0.8062\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4328 - masked_acc: 0.7653 - masked_auc: 0.8075 - val_loss: 0.4322 - val_masked_acc: 0.7665 - val_masked_auc: 0.8097\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4364 - masked_acc: 0.7666 - masked_auc: 0.8104 - val_loss: 0.4314 - val_masked_acc: 0.7678 - val_masked_auc: 0.8122\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4316 - masked_acc: 0.7679 - masked_auc: 0.8127 - val_loss: 0.4298 - val_masked_acc: 0.7688 - val_masked_auc: 0.8140\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4344 - masked_acc: 0.7688 - masked_auc: 0.8144 - val_loss: 0.4304 - val_masked_acc: 0.7696 - val_masked_auc: 0.8155\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4320 - masked_acc: 0.7696 - masked_auc: 0.8158 - val_loss: 0.4296 - val_masked_acc: 0.7702 - val_masked_auc: 0.8167\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.4299 - masked_acc: 0.7703 - masked_auc: 0.8170 - val_loss: 0.4302 - val_masked_acc: 0.7708 - val_masked_auc: 0.8177\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4280 - masked_acc: 0.7708 - masked_auc: 0.8179 - val_loss: 0.4307 - val_masked_acc: 0.7712 - val_masked_auc: 0.8185\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.4269 - masked_acc: 0.7713 - masked_auc: 0.8186 - val_loss: 0.4296 - val_masked_acc: 0.7716 - val_masked_auc: 0.8192\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4263 - masked_acc: 0.7717 - masked_auc: 0.8194 - val_loss: 0.4309 - val_masked_acc: 0.7719 - val_masked_auc: 0.8197\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4289 - masked_acc: 0.7719 - masked_auc: 0.8198 - val_loss: 0.4296 - val_masked_acc: 0.7722 - val_masked_auc: 0.8202\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4280 - masked_acc: 0.7722 - masked_auc: 0.8203 - val_loss: 0.4328 - val_masked_acc: 0.7724 - val_masked_auc: 0.8206\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4344 - masked_acc: 0.7723 - masked_auc: 0.8207 - val_loss: 0.4299 - val_masked_acc: 0.7726 - val_masked_auc: 0.8210\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.4285 - masked_acc: 0.7726 - masked_auc: 0.8211 - val_loss: 0.4295 - val_masked_acc: 0.7728 - val_masked_auc: 0.8213\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.4264 - masked_acc: 0.7728 - masked_auc: 0.8214 - val_loss: 0.4306 - val_masked_acc: 0.7730 - val_masked_auc: 0.8216\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4323 - masked_acc: 0.7729 - masked_auc: 0.8217 - val_loss: 0.4320 - val_masked_acc: 0.7731 - val_masked_auc: 0.8218\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4335 - masked_acc: 0.7731 - masked_auc: 0.8218 - val_loss: 0.4330 - val_masked_acc: 0.7732 - val_masked_auc: 0.8220\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4335 - masked_acc: 0.7732 - masked_auc: 0.8220 - val_loss: 0.4304 - val_masked_acc: 0.7733 - val_masked_auc: 0.8223\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4282 - masked_acc: 0.7734 - masked_auc: 0.8223 - val_loss: 0.4302 - val_masked_acc: 0.7735 - val_masked_auc: 0.8225\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.4368 - masked_acc: 0.7734 - masked_auc: 0.8225 - val_loss: 0.4293 - val_masked_acc: 0.7736 - val_masked_auc: 0.8227\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4279 - masked_acc: 0.7736 - masked_auc: 0.8227 - val_loss: 0.4312 - val_masked_acc: 0.7737 - val_masked_auc: 0.8228\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4313 - masked_acc: 0.7736 - masked_auc: 0.8229 - val_loss: 0.4297 - val_masked_acc: 0.7738 - val_masked_auc: 0.8230\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4304 - masked_acc: 0.7738 - masked_auc: 0.8230 - val_loss: 0.4316 - val_masked_acc: 0.7739 - val_masked_auc: 0.8232\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4233 - masked_acc: 0.7739 - masked_auc: 0.8232 - val_loss: 0.4304 - val_masked_acc: 0.7739 - val_masked_auc: 0.8233\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.4319 - masked_acc: 0.7739 - masked_auc: 0.8233 - val_loss: 0.4304 - val_masked_acc: 0.7740 - val_masked_auc: 0.8234\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4331 - masked_acc: 0.7740 - masked_auc: 0.8234 - val_loss: 0.4299 - val_masked_acc: 0.7741 - val_masked_auc: 0.8236\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4347 - masked_acc: 0.7740 - masked_auc: 0.8235 - val_loss: 0.4300 - val_masked_acc: 0.7742 - val_masked_auc: 0.8237\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4307 - masked_acc: 0.7741 - masked_auc: 0.8237 - val_loss: 0.4291 - val_masked_acc: 0.7742 - val_masked_auc: 0.8238\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.4360 - masked_acc: 0.7742 - masked_auc: 0.8238 - val_loss: 0.4299 - val_masked_acc: 0.7743 - val_masked_auc: 0.8239\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.4297 - masked_acc: 0.7743 - masked_auc: 0.8239 - val_loss: 0.4295 - val_masked_acc: 0.7743 - val_masked_auc: 0.8240\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4317 - masked_acc: 0.7743 - masked_auc: 0.8240 - val_loss: 0.4294 - val_masked_acc: 0.7744 - val_masked_auc: 0.8241\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4340 - masked_acc: 0.7744 - masked_auc: 0.8241 - val_loss: 0.4288 - val_masked_acc: 0.7745 - val_masked_auc: 0.8242\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.4274 - masked_acc: 0.7745 - masked_auc: 0.8242 - val_loss: 0.4298 - val_masked_acc: 0.7745 - val_masked_auc: 0.8243\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.4299 - masked_acc: 0.7745 - masked_auc: 0.8243 - val_loss: 0.4296 - val_masked_acc: 0.7746 - val_masked_auc: 0.8244\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4313 - masked_acc: 0.7745 - masked_auc: 0.8244 - val_loss: 0.4296 - val_masked_acc: 0.7746 - val_masked_auc: 0.8244\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4316 - masked_acc: 0.7746 - masked_auc: 0.8245 - val_loss: 0.4306 - val_masked_acc: 0.7747 - val_masked_auc: 0.8245\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.4269 - masked_acc: 0.7747 - masked_auc: 0.8246 - val_loss: 0.4296 - val_masked_acc: 0.7747 - val_masked_auc: 0.8246\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4289 - masked_acc: 0.7747 - masked_auc: 0.8246 - val_loss: 0.4301 - val_masked_acc: 0.7747 - val_masked_auc: 0.8247\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4345 - masked_acc: 0.7747 - masked_auc: 0.8246 - val_loss: 0.4305 - val_masked_acc: 0.7748 - val_masked_auc: 0.8247\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4282 - masked_acc: 0.7748 - masked_auc: 0.8247 - val_loss: 0.4294 - val_masked_acc: 0.7748 - val_masked_auc: 0.8248\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4345 - masked_acc: 0.7748 - masked_auc: 0.8248 - val_loss: 0.4296 - val_masked_acc: 0.7748 - val_masked_auc: 0.8249\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4288 - masked_acc: 0.7748 - masked_auc: 0.8249 - val_loss: 0.4304 - val_masked_acc: 0.7749 - val_masked_auc: 0.8249\n",
      "28/28 [==============================] - 1s 34ms/step - loss: 0.4306 - masked_acc: 0.7750 - masked_auc: 0.8250\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4281 - masked_acc: 0.7749 - masked_auc: 0.8250\n",
      "Test:  [0.4281165599822998, 0.7749157547950745, 0.8249724507331848]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 4s 199ms/step - loss: 0.5667 - masked_acc: 0.6413 - masked_auc: 0.5654 - val_loss: 0.4802 - val_masked_acc: 0.7271 - val_masked_auc: 0.7200\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.4486 - masked_acc: 0.7354 - masked_auc: 0.7408 - val_loss: 0.4614 - val_masked_acc: 0.7501 - val_masked_auc: 0.7728\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.4321 - masked_acc: 0.7528 - masked_auc: 0.7795 - val_loss: 0.4585 - val_masked_acc: 0.7583 - val_masked_auc: 0.7911\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4323 - masked_acc: 0.7595 - masked_auc: 0.7944 - val_loss: 0.4569 - val_masked_acc: 0.7624 - val_masked_auc: 0.8004\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.4313 - masked_acc: 0.7631 - masked_auc: 0.8022 - val_loss: 0.4556 - val_masked_acc: 0.7651 - val_masked_auc: 0.8059\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4209 - masked_acc: 0.7660 - masked_auc: 0.8074 - val_loss: 0.4565 - val_masked_acc: 0.7670 - val_masked_auc: 0.8096\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.4251 - masked_acc: 0.7674 - masked_auc: 0.8106 - val_loss: 0.4553 - val_masked_acc: 0.7682 - val_masked_auc: 0.8122\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4289 - masked_acc: 0.7683 - masked_auc: 0.8127 - val_loss: 0.4561 - val_masked_acc: 0.7691 - val_masked_auc: 0.8141\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4251 - masked_acc: 0.7693 - masked_auc: 0.8145 - val_loss: 0.4569 - val_masked_acc: 0.7698 - val_masked_auc: 0.8156\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.4234 - masked_acc: 0.7701 - masked_auc: 0.8160 - val_loss: 0.4564 - val_masked_acc: 0.7705 - val_masked_auc: 0.8167\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.4294 - masked_acc: 0.7705 - masked_auc: 0.8169 - val_loss: 0.4561 - val_masked_acc: 0.7710 - val_masked_auc: 0.8176\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.4247 - masked_acc: 0.7710 - masked_auc: 0.8179 - val_loss: 0.4559 - val_masked_acc: 0.7713 - val_masked_auc: 0.8184\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.4265 - masked_acc: 0.7714 - masked_auc: 0.8187 - val_loss: 0.4560 - val_masked_acc: 0.7717 - val_masked_auc: 0.8191\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4286 - masked_acc: 0.7718 - masked_auc: 0.8193 - val_loss: 0.4569 - val_masked_acc: 0.7720 - val_masked_auc: 0.8197\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.4327 - masked_acc: 0.7720 - masked_auc: 0.8198 - val_loss: 0.4561 - val_masked_acc: 0.7722 - val_masked_auc: 0.8201\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.4296 - masked_acc: 0.7722 - masked_auc: 0.8202 - val_loss: 0.4561 - val_masked_acc: 0.7724 - val_masked_auc: 0.8206\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.4264 - masked_acc: 0.7724 - masked_auc: 0.8207 - val_loss: 0.4559 - val_masked_acc: 0.7726 - val_masked_auc: 0.8210\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.4277 - masked_acc: 0.7730 - masked_auc: 0.8214\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4215 - masked_acc: 0.7729 - masked_auc: 0.8215\n",
      "Test:  [0.4215153753757477, 0.7728830575942993, 0.8214892148971558]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "    \n",
    "    output = tf.concat([embedding_chap, embedding_sub_chap, embedding_ques, embedding_shifted, dense_features], axis = 2)\n",
    "\n",
    "    pred = Dense(1, input_shape = (None, 5*EMBEDDING_DIM), activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='logistic_regression'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T15:44:18.376749Z",
     "iopub.status.busy": "2021-08-08T15:44:18.375780Z",
     "iopub.status.idle": "2021-08-08T15:44:18.386523Z",
     "shell.execute_reply": "2021-08-08T15:44:18.387513Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.771838Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.999131,
     "end_time": "2021-08-08T15:44:18.387865",
     "exception": false,
     "start_time": "2021-08-08T15:44:17.388734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.42648977041244507 +/- 0.007458425240890819\n",
      "test avg acc:  0.7734879732131958 +/- 0.0007525102274471956\n",
      "test avg auc:  0.8228032231330872 +/- 0.0012114848514652014\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T15:44:20.403835Z",
     "iopub.status.busy": "2021-08-08T15:44:20.402827Z",
     "iopub.status.idle": "2021-08-08T15:44:20.409328Z",
     "shell.execute_reply": "2021-08-08T15:44:20.408706Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.782922Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 1.052893,
     "end_time": "2021-08-08T15:44:20.409512",
     "exception": false,
     "start_time": "2021-08-08T15:44:19.356619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.42924904227256777 +/- 0.0014931366780111895\n",
      "train avg acc:  0.7736101865768432 +/- 0.0007442579316099335\n",
      "train avg auc:  0.822801387310028 +/- 0.0012348429740052598\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 829.393114,
   "end_time": "2021-08-08T15:44:23.963102",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-08T15:30:34.569988",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
