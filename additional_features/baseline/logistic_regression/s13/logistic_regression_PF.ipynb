{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:11:15.270556Z",
     "iopub.status.busy": "2021-08-12T22:11:15.269899Z",
     "iopub.status.idle": "2021-08-12T22:11:21.855343Z",
     "shell.execute_reply": "2021-08-12T22:11:21.854641Z",
     "shell.execute_reply.started": "2021-08-06T21:05:15.103244Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.629571,
     "end_time": "2021-08-12T22:11:21.855546",
     "exception": false,
     "start_time": "2021-08-12T22:11:15.225975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:50.157117Z",
     "iopub.status.busy": "2021-08-12T22:17:50.156389Z",
     "iopub.status.idle": "2021-08-12T22:17:50.158381Z",
     "shell.execute_reply": "2021-08-12T22:17:50.158892Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.04112Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.364013,
     "end_time": "2021-08-12T22:17:50.159069",
     "exception": false,
     "start_time": "2021-08-12T22:17:49.795056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:50.878177Z",
     "iopub.status.busy": "2021-08-12T22:17:50.877535Z",
     "iopub.status.idle": "2021-08-12T22:17:50.882079Z",
     "shell.execute_reply": "2021-08-12T22:17:50.881537Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.049329Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.365009,
     "end_time": "2021-08-12T22:17:50.882217",
     "exception": false,
     "start_time": "2021-08-12T22:17:50.517208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:55.694528Z",
     "iopub.status.busy": "2021-08-12T22:17:55.693650Z",
     "iopub.status.idle": "2021-08-12T22:18:18.562799Z",
     "shell.execute_reply": "2021-08-12T22:18:18.561828Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.318071Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 23.270069,
     "end_time": "2021-08-12T22:18:18.562953",
     "exception": false,
     "start_time": "2021-08-12T22:17:55.292884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 83ms/step - loss: 0.6074 - masked_acc: 0.6308 - masked_auc: 0.6163 - val_loss: 0.5227 - val_masked_acc: 0.7333 - val_masked_auc: 0.6514\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4537 - masked_acc: 0.7426 - masked_auc: 0.6845 - val_loss: 0.4951 - val_masked_acc: 0.7557 - val_masked_auc: 0.7339\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4289 - masked_acc: 0.7595 - masked_auc: 0.7476 - val_loss: 0.4949 - val_masked_acc: 0.7657 - val_masked_auc: 0.7675\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4158 - masked_acc: 0.7678 - masked_auc: 0.7742 - val_loss: 0.5014 - val_masked_acc: 0.7714 - val_masked_auc: 0.7842\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4087 - masked_acc: 0.7731 - masked_auc: 0.7881 - val_loss: 0.5054 - val_masked_acc: 0.7748 - val_masked_auc: 0.7943\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4138 - masked_acc: 0.7758 - masked_auc: 0.7969 - val_loss: 0.5034 - val_masked_acc: 0.7768 - val_masked_auc: 0.8008\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4003 - masked_acc: 0.7780 - masked_auc: 0.8031 - val_loss: 0.5070 - val_masked_acc: 0.7787 - val_masked_auc: 0.8055\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4134 - masked_acc: 0.7791 - masked_auc: 0.8070 - val_loss: 0.5112 - val_masked_acc: 0.7798 - val_masked_auc: 0.8090\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4032 - masked_acc: 0.7804 - masked_auc: 0.8101 - val_loss: 0.5106 - val_masked_acc: 0.7807 - val_masked_auc: 0.8116\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4088 - masked_acc: 0.7810 - masked_auc: 0.8125 - val_loss: 0.5129 - val_masked_acc: 0.7813 - val_masked_auc: 0.8138\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4133 - masked_acc: 0.7815 - masked_auc: 0.8144 - val_loss: 0.5118 - val_masked_acc: 0.7820 - val_masked_auc: 0.8155\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4069 - masked_acc: 0.7823 - masked_auc: 0.8163 - val_loss: 0.5167 - val_masked_acc: 0.7825 - val_masked_auc: 0.8170\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4063 - masked_acc: 0.7828 - masked_auc: 0.8177 - val_loss: 0.5133 - val_masked_acc: 0.7831 - val_masked_auc: 0.8183\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4057 - masked_acc: 0.7837 - masked_auc: 0.8195\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4785 - masked_acc: 0.7840 - masked_auc: 0.8198\n",
      "Test:  [0.4785197079181671, 0.7840127944946289, 0.8198422789573669]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 56ms/step - loss: 0.6053 - masked_acc: 0.6632 - masked_auc: 0.6229 - val_loss: 0.5503 - val_masked_acc: 0.7391 - val_masked_auc: 0.6445\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4479 - masked_acc: 0.7481 - masked_auc: 0.6802 - val_loss: 0.5480 - val_masked_acc: 0.7613 - val_masked_auc: 0.7297\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4204 - masked_acc: 0.7654 - masked_auc: 0.7457 - val_loss: 0.5532 - val_masked_acc: 0.7707 - val_masked_auc: 0.7653\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4079 - masked_acc: 0.7733 - masked_auc: 0.7727 - val_loss: 0.5701 - val_masked_acc: 0.7763 - val_masked_auc: 0.7822\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3987 - masked_acc: 0.7781 - masked_auc: 0.7869 - val_loss: 0.5721 - val_masked_acc: 0.7795 - val_masked_auc: 0.7927\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3994 - masked_acc: 0.7804 - masked_auc: 0.7958 - val_loss: 0.5821 - val_masked_acc: 0.7816 - val_masked_auc: 0.7996\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4058 - masked_acc: 0.7822 - masked_auc: 0.8019 - val_loss: 0.5823 - val_masked_acc: 0.7834 - val_masked_auc: 0.8044\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3983 - masked_acc: 0.7842 - masked_auc: 0.8060 - val_loss: 0.5936 - val_masked_acc: 0.7847 - val_masked_auc: 0.8078\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3924 - masked_acc: 0.7855 - masked_auc: 0.8091 - val_loss: 0.5924 - val_masked_acc: 0.7857 - val_masked_auc: 0.8106\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4066 - masked_acc: 0.7860 - masked_auc: 0.8117 - val_loss: 0.5932 - val_masked_acc: 0.7864 - val_masked_auc: 0.8128\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4007 - masked_acc: 0.7868 - masked_auc: 0.8136 - val_loss: 0.6010 - val_masked_acc: 0.7870 - val_masked_auc: 0.8146\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.3993 - masked_acc: 0.7874 - masked_auc: 0.8153 - val_loss: 0.6010 - val_masked_acc: 0.7876 - val_masked_auc: 0.8160\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3970 - masked_acc: 0.7884 - masked_auc: 0.8176\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5155 - masked_acc: 0.7887 - masked_auc: 0.8183\n",
      "Test:  [0.5154991149902344, 0.7887091040611267, 0.8183008432388306]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 52ms/step - loss: 0.6118 - masked_acc: 0.6341 - masked_auc: 0.5592 - val_loss: 0.4868 - val_masked_acc: 0.7290 - val_masked_auc: 0.6481\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4678 - masked_acc: 0.7372 - masked_auc: 0.6804 - val_loss: 0.4800 - val_masked_acc: 0.7527 - val_masked_auc: 0.7330\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4326 - masked_acc: 0.7565 - masked_auc: 0.7458 - val_loss: 0.4777 - val_masked_acc: 0.7636 - val_masked_auc: 0.7673\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4325 - masked_acc: 0.7647 - masked_auc: 0.7731 - val_loss: 0.4827 - val_masked_acc: 0.7697 - val_masked_auc: 0.7840\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4244 - masked_acc: 0.7710 - masked_auc: 0.7877 - val_loss: 0.4950 - val_masked_acc: 0.7736 - val_masked_auc: 0.7942\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4202 - masked_acc: 0.7745 - masked_auc: 0.7968 - val_loss: 0.4938 - val_masked_acc: 0.7760 - val_masked_auc: 0.8007\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4263 - masked_acc: 0.7764 - masked_auc: 0.8022 - val_loss: 0.4954 - val_masked_acc: 0.7773 - val_masked_auc: 0.8054\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4141 - masked_acc: 0.7778 - masked_auc: 0.8071 - val_loss: 0.5007 - val_masked_acc: 0.7787 - val_masked_auc: 0.8087\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4094 - masked_acc: 0.7791 - masked_auc: 0.8099 - val_loss: 0.5000 - val_masked_acc: 0.7799 - val_masked_auc: 0.8114\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4039 - masked_acc: 0.7806 - masked_auc: 0.8126 - val_loss: 0.5032 - val_masked_acc: 0.7808 - val_masked_auc: 0.8136\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4183 - masked_acc: 0.7810 - masked_auc: 0.8143 - val_loss: 0.4999 - val_masked_acc: 0.7813 - val_masked_auc: 0.8153\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4100 - masked_acc: 0.7816 - masked_auc: 0.8161 - val_loss: 0.5085 - val_masked_acc: 0.7818 - val_masked_auc: 0.8168\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4162 - masked_acc: 0.7820 - masked_auc: 0.8171 - val_loss: 0.5049 - val_masked_acc: 0.7822 - val_masked_auc: 0.8179\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4120 - masked_acc: 0.7826 - masked_auc: 0.8192\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4350 - masked_acc: 0.7829 - masked_auc: 0.8195\n",
      "Test:  [0.4350070655345917, 0.7829146385192871, 0.8195151090621948]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 53ms/step - loss: 0.6014 - masked_acc: 0.7008 - masked_auc: 0.6068 - val_loss: 0.5417 - val_masked_acc: 0.7488 - val_masked_auc: 0.6660\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4603 - masked_acc: 0.7538 - masked_auc: 0.6910 - val_loss: 0.5069 - val_masked_acc: 0.7649 - val_masked_auc: 0.7368\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4277 - masked_acc: 0.7677 - masked_auc: 0.7503 - val_loss: 0.5224 - val_masked_acc: 0.7728 - val_masked_auc: 0.7692\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4126 - masked_acc: 0.7748 - masked_auc: 0.7755 - val_loss: 0.5294 - val_masked_acc: 0.7770 - val_masked_auc: 0.7848\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4093 - masked_acc: 0.7785 - masked_auc: 0.7891 - val_loss: 0.5347 - val_masked_acc: 0.7801 - val_masked_auc: 0.7947\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4112 - masked_acc: 0.7806 - masked_auc: 0.7972 - val_loss: 0.5343 - val_masked_acc: 0.7818 - val_masked_auc: 0.8011\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4011 - masked_acc: 0.7827 - masked_auc: 0.8030 - val_loss: 0.5408 - val_masked_acc: 0.7834 - val_masked_auc: 0.8058\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4104 - masked_acc: 0.7839 - masked_auc: 0.8073 - val_loss: 0.5426 - val_masked_acc: 0.7849 - val_masked_auc: 0.8094\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4060 - masked_acc: 0.7853 - masked_auc: 0.8106 - val_loss: 0.5431 - val_masked_acc: 0.7858 - val_masked_auc: 0.8121\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4044 - masked_acc: 0.7861 - masked_auc: 0.8127 - val_loss: 0.5447 - val_masked_acc: 0.7864 - val_masked_auc: 0.8142\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4049 - masked_acc: 0.7867 - masked_auc: 0.8148 - val_loss: 0.5477 - val_masked_acc: 0.7870 - val_masked_auc: 0.8160\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4095 - masked_acc: 0.7871 - masked_auc: 0.8164 - val_loss: 0.5484 - val_masked_acc: 0.7875 - val_masked_auc: 0.8175\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3992 - masked_acc: 0.7883 - masked_auc: 0.8189\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5249 - masked_acc: 0.7884 - masked_auc: 0.8195\n",
      "Test:  [0.5248719453811646, 0.7884208559989929, 0.8194671869277954]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 56ms/step - loss: 0.6089 - masked_acc: 0.6617 - masked_auc: 0.6225 - val_loss: 0.4542 - val_masked_acc: 0.7422 - val_masked_auc: 0.6670\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4710 - masked_acc: 0.7477 - masked_auc: 0.6929 - val_loss: 0.4619 - val_masked_acc: 0.7607 - val_masked_auc: 0.7399\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4268 - masked_acc: 0.7645 - masked_auc: 0.7530 - val_loss: 0.4597 - val_masked_acc: 0.7700 - val_masked_auc: 0.7710\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4171 - masked_acc: 0.7721 - masked_auc: 0.7775 - val_loss: 0.4686 - val_masked_acc: 0.7748 - val_masked_auc: 0.7867\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4173 - masked_acc: 0.7758 - masked_auc: 0.7910 - val_loss: 0.4746 - val_masked_acc: 0.7777 - val_masked_auc: 0.7963\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4112 - masked_acc: 0.7788 - masked_auc: 0.7989 - val_loss: 0.4854 - val_masked_acc: 0.7797 - val_masked_auc: 0.8023\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4153 - masked_acc: 0.7802 - masked_auc: 0.8042 - val_loss: 0.4833 - val_masked_acc: 0.7812 - val_masked_auc: 0.8068\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4049 - masked_acc: 0.7818 - masked_auc: 0.8087 - val_loss: 0.4867 - val_masked_acc: 0.7823 - val_masked_auc: 0.8101\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4148 - masked_acc: 0.7826 - masked_auc: 0.8110 - val_loss: 0.4895 - val_masked_acc: 0.7833 - val_masked_auc: 0.8127\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4089 - masked_acc: 0.7835 - masked_auc: 0.8136 - val_loss: 0.4965 - val_masked_acc: 0.7842 - val_masked_auc: 0.8148\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4134 - masked_acc: 0.7844 - masked_auc: 0.8157 - val_loss: 0.4957 - val_masked_acc: 0.7848 - val_masked_auc: 0.8165\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4091 - masked_acc: 0.7853 - masked_auc: 0.8180\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4845 - masked_acc: 0.7856 - masked_auc: 0.8187\n",
      "Test:  [0.4845280647277832, 0.7856069803237915, 0.8187052011489868]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_shifted_t.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_shifted_t.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_shifted_t.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    \n",
    "    output = tf.concat([embedding_chap, embedding_sub_chap, embedding_ques, embedding_shifted], axis = 2)\n",
    "\n",
    "    pred = Dense(1, input_shape = (None, 4*EMBEDDING_DIM), activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted],\n",
    "        outputs=pred,\n",
    "        name='logistic_regression'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:18:19.418174Z",
     "iopub.status.busy": "2021-08-12T22:18:19.417135Z",
     "iopub.status.idle": "2021-08-12T22:18:19.423239Z",
     "shell.execute_reply": "2021-08-12T22:18:19.422173Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.771838Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.436851,
     "end_time": "2021-08-12T22:18:19.423500",
     "exception": false,
     "start_time": "2021-08-12T22:18:18.986649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.48768517971038816 +/- 0.03170308344029125\n",
      "test avg acc:  0.7859328746795654 +/- 0.0023151745157455007\n",
      "test avg auc:  0.8191661238670349 +/- 0.0005710999311391571\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:18:20.328491Z",
     "iopub.status.busy": "2021-08-12T22:18:20.327347Z",
     "iopub.status.idle": "2021-08-12T22:18:20.334491Z",
     "shell.execute_reply": "2021-08-12T22:18:20.333683Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.782922Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.460591,
     "end_time": "2021-08-12T22:18:20.334718",
     "exception": false,
     "start_time": "2021-08-12T22:18:19.874127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.4046068608760834 +/- 0.005708836042257659\n",
      "train avg acc:  0.7856924414634705 +/- 0.002346901241846015\n",
      "train avg auc:  0.8186350107192993 +/- 0.0007118611473241689\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 436.062631,
   "end_time": "2021-08-12T22:18:23.211414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T22:11:07.148783",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
