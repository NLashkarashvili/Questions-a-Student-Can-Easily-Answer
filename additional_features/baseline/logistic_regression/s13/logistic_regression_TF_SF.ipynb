{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:11:01.657075Z",
     "iopub.status.busy": "2021-08-12T22:11:01.656446Z",
     "iopub.status.idle": "2021-08-12T22:11:08.833935Z",
     "shell.execute_reply": "2021-08-12T22:11:08.833071Z",
     "shell.execute_reply.started": "2021-08-06T21:05:15.103244Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.219309,
     "end_time": "2021-08-12T22:11:08.834099",
     "exception": false,
     "start_time": "2021-08-12T22:11:01.614790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:35.880659Z",
     "iopub.status.busy": "2021-08-12T22:17:35.879871Z",
     "iopub.status.idle": "2021-08-12T22:17:35.884682Z",
     "shell.execute_reply": "2021-08-12T22:17:35.884103Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.04112Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.368579,
     "end_time": "2021-08-12T22:17:35.884828",
     "exception": false,
     "start_time": "2021-08-12T22:17:35.516249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:36.612783Z",
     "iopub.status.busy": "2021-08-12T22:17:36.611938Z",
     "iopub.status.idle": "2021-08-12T22:17:36.615093Z",
     "shell.execute_reply": "2021-08-12T22:17:36.614555Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.049329Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.369572,
     "end_time": "2021-08-12T22:17:36.615280",
     "exception": false,
     "start_time": "2021-08-12T22:17:36.245708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 39\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:41.508683Z",
     "iopub.status.busy": "2021-08-12T22:17:41.507612Z",
     "iopub.status.idle": "2021-08-12T22:18:04.990214Z",
     "shell.execute_reply": "2021-08-12T22:18:04.989646Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.318071Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 23.855637,
     "end_time": "2021-08-12T22:18:04.990354",
     "exception": false,
     "start_time": "2021-08-12T22:17:41.134717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 83ms/step - loss: 0.6048 - masked_acc: 0.6019 - masked_auc: 0.5366 - val_loss: 0.5333 - val_masked_acc: 0.7209 - val_masked_auc: 0.6397\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4803 - masked_acc: 0.7287 - masked_auc: 0.6735 - val_loss: 0.5633 - val_masked_acc: 0.7464 - val_masked_auc: 0.7244\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4250 - masked_acc: 0.7511 - masked_auc: 0.7401 - val_loss: 0.5554 - val_masked_acc: 0.7579 - val_masked_auc: 0.7588\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4055 - masked_acc: 0.7614 - masked_auc: 0.7664 - val_loss: 0.5555 - val_masked_acc: 0.7646 - val_masked_auc: 0.7759\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4150 - masked_acc: 0.7665 - masked_auc: 0.7809 - val_loss: 0.5665 - val_masked_acc: 0.7687 - val_masked_auc: 0.7863\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4066 - masked_acc: 0.7699 - masked_auc: 0.7894 - val_loss: 0.5709 - val_masked_acc: 0.7712 - val_masked_auc: 0.7935\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4075 - masked_acc: 0.7722 - masked_auc: 0.7958 - val_loss: 0.5720 - val_masked_acc: 0.7736 - val_masked_auc: 0.7986\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4037 - masked_acc: 0.7746 - masked_auc: 0.8008 - val_loss: 0.5788 - val_masked_acc: 0.7754 - val_masked_auc: 0.8024\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4070 - masked_acc: 0.7760 - masked_auc: 0.8037 - val_loss: 0.5820 - val_masked_acc: 0.7767 - val_masked_auc: 0.8053\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4003 - masked_acc: 0.7773 - masked_auc: 0.8068 - val_loss: 0.5829 - val_masked_acc: 0.7777 - val_masked_auc: 0.8077\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3976 - masked_acc: 0.7784 - masked_auc: 0.8088 - val_loss: 0.5833 - val_masked_acc: 0.7786 - val_masked_auc: 0.8096\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4040 - masked_acc: 0.7794 - masked_auc: 0.8114\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4697 - masked_acc: 0.7801 - masked_auc: 0.8124\n",
      "Test:  [0.46968692541122437, 0.7801176309585571, 0.8123928308486938]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 73ms/step - loss: 0.6517 - masked_acc: 0.5225 - masked_auc: 0.5433 - val_loss: 0.5177 - val_masked_acc: 0.7064 - val_masked_auc: 0.5993\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4696 - masked_acc: 0.7214 - masked_auc: 0.6354 - val_loss: 0.5126 - val_masked_acc: 0.7401 - val_masked_auc: 0.6994\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4395 - masked_acc: 0.7454 - masked_auc: 0.7156 - val_loss: 0.5089 - val_masked_acc: 0.7540 - val_masked_auc: 0.7427\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4183 - masked_acc: 0.7569 - masked_auc: 0.7513 - val_loss: 0.5117 - val_masked_acc: 0.7612 - val_masked_auc: 0.7642\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4016 - masked_acc: 0.7638 - masked_auc: 0.7698 - val_loss: 0.5221 - val_masked_acc: 0.7661 - val_masked_auc: 0.7770\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4145 - masked_acc: 0.7675 - masked_auc: 0.7803 - val_loss: 0.5161 - val_masked_acc: 0.7694 - val_masked_auc: 0.7858\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4136 - masked_acc: 0.7704 - masked_auc: 0.7879 - val_loss: 0.5252 - val_masked_acc: 0.7718 - val_masked_auc: 0.7917\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4054 - masked_acc: 0.7728 - masked_auc: 0.7936 - val_loss: 0.5261 - val_masked_acc: 0.7734 - val_masked_auc: 0.7963\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4175 - masked_acc: 0.7738 - masked_auc: 0.7977 - val_loss: 0.5320 - val_masked_acc: 0.7749 - val_masked_auc: 0.7998\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3908 - masked_acc: 0.7759 - masked_auc: 0.8015 - val_loss: 0.5325 - val_masked_acc: 0.7760 - val_masked_auc: 0.8029\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4035 - masked_acc: 0.7766 - masked_auc: 0.8040 - val_loss: 0.5337 - val_masked_acc: 0.7769 - val_masked_auc: 0.8052\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4114 - masked_acc: 0.7773 - masked_auc: 0.8061 - val_loss: 0.5433 - val_masked_acc: 0.7778 - val_masked_auc: 0.8071\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4081 - masked_acc: 0.7782 - masked_auc: 0.8078 - val_loss: 0.5329 - val_masked_acc: 0.7785 - val_masked_auc: 0.8087\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4013 - masked_acc: 0.7793 - masked_auc: 0.8103\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4965 - masked_acc: 0.7795 - masked_auc: 0.8112\n",
      "Test:  [0.49654749035835266, 0.7794520854949951, 0.8111664056777954]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 53ms/step - loss: 0.5912 - masked_acc: 0.6799 - masked_auc: 0.5094 - val_loss: 0.4957 - val_masked_acc: 0.7319 - val_masked_auc: 0.6424\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4672 - masked_acc: 0.7401 - masked_auc: 0.6829 - val_loss: 0.4905 - val_masked_acc: 0.7517 - val_masked_auc: 0.7283\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4463 - masked_acc: 0.7544 - masked_auc: 0.7409 - val_loss: 0.4896 - val_masked_acc: 0.7614 - val_masked_auc: 0.7618\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4213 - masked_acc: 0.7642 - masked_auc: 0.7680 - val_loss: 0.5047 - val_masked_acc: 0.7671 - val_masked_auc: 0.7789\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4217 - masked_acc: 0.7685 - masked_auc: 0.7828 - val_loss: 0.5036 - val_masked_acc: 0.7709 - val_masked_auc: 0.7893\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4188 - masked_acc: 0.7717 - masked_auc: 0.7917 - val_loss: 0.5084 - val_masked_acc: 0.7734 - val_masked_auc: 0.7961\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4123 - masked_acc: 0.7742 - masked_auc: 0.7983 - val_loss: 0.5095 - val_masked_acc: 0.7750 - val_masked_auc: 0.8009\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4175 - masked_acc: 0.7754 - masked_auc: 0.8022 - val_loss: 0.5116 - val_masked_acc: 0.7761 - val_masked_auc: 0.8046\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4068 - masked_acc: 0.7766 - masked_auc: 0.8059 - val_loss: 0.5146 - val_masked_acc: 0.7769 - val_masked_auc: 0.8074\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4230 - masked_acc: 0.7770 - masked_auc: 0.8084 - val_loss: 0.5137 - val_masked_acc: 0.7780 - val_masked_auc: 0.8099\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4140 - masked_acc: 0.7782 - masked_auc: 0.8105 - val_loss: 0.5170 - val_masked_acc: 0.7786 - val_masked_auc: 0.8117\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4158 - masked_acc: 0.7789 - masked_auc: 0.8125 - val_loss: 0.5195 - val_masked_acc: 0.7795 - val_masked_auc: 0.8133\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4129 - masked_acc: 0.7797 - masked_auc: 0.8139 - val_loss: 0.5218 - val_masked_acc: 0.7800 - val_masked_auc: 0.8146\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4079 - masked_acc: 0.7806 - masked_auc: 0.8160\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4671 - masked_acc: 0.7808 - masked_auc: 0.8166\n",
      "Test:  [0.4671310782432556, 0.7808085083961487, 0.8165595531463623]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 55ms/step - loss: 0.5861 - masked_acc: 0.6755 - masked_auc: 0.5401 - val_loss: 0.5183 - val_masked_acc: 0.7355 - val_masked_auc: 0.6702\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4508 - masked_acc: 0.7443 - masked_auc: 0.7065 - val_loss: 0.5147 - val_masked_acc: 0.7539 - val_masked_auc: 0.7444\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4225 - masked_acc: 0.7582 - masked_auc: 0.7563 - val_loss: 0.5149 - val_masked_acc: 0.7636 - val_masked_auc: 0.7722\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4157 - masked_acc: 0.7658 - masked_auc: 0.7778 - val_loss: 0.5276 - val_masked_acc: 0.7688 - val_masked_auc: 0.7872\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4179 - masked_acc: 0.7698 - masked_auc: 0.7908 - val_loss: 0.5310 - val_masked_acc: 0.7714 - val_masked_auc: 0.7960\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4101 - masked_acc: 0.7723 - masked_auc: 0.7982 - val_loss: 0.5324 - val_masked_acc: 0.7733 - val_masked_auc: 0.8017\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4106 - masked_acc: 0.7741 - masked_auc: 0.8034 - val_loss: 0.5398 - val_masked_acc: 0.7750 - val_masked_auc: 0.8058\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4075 - masked_acc: 0.7755 - masked_auc: 0.8072 - val_loss: 0.5409 - val_masked_acc: 0.7762 - val_masked_auc: 0.8089\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4060 - masked_acc: 0.7768 - masked_auc: 0.8100 - val_loss: 0.5389 - val_masked_acc: 0.7772 - val_masked_auc: 0.8115\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4008 - masked_acc: 0.7777 - masked_auc: 0.8126 - val_loss: 0.5459 - val_masked_acc: 0.7781 - val_masked_auc: 0.8135\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4062 - masked_acc: 0.7784 - masked_auc: 0.8143 - val_loss: 0.5418 - val_masked_acc: 0.7787 - val_masked_auc: 0.8152\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4114 - masked_acc: 0.7790 - masked_auc: 0.8155 - val_loss: 0.5478 - val_masked_acc: 0.7794 - val_masked_auc: 0.8166\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4028 - masked_acc: 0.7800 - masked_auc: 0.8180\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4975 - masked_acc: 0.7805 - masked_auc: 0.8185\n",
      "Test:  [0.4975454807281494, 0.7804718017578125, 0.818529486656189]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 56ms/step - loss: 0.5983 - masked_acc: 0.5831 - masked_auc: 0.5661 - val_loss: 0.4847 - val_masked_acc: 0.7214 - val_masked_auc: 0.6659\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4621 - masked_acc: 0.7329 - masked_auc: 0.6979 - val_loss: 0.4765 - val_masked_acc: 0.7478 - val_masked_auc: 0.7405\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4235 - masked_acc: 0.7537 - masked_auc: 0.7539 - val_loss: 0.4786 - val_masked_acc: 0.7598 - val_masked_auc: 0.7703\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4222 - masked_acc: 0.7624 - masked_auc: 0.7762 - val_loss: 0.4819 - val_masked_acc: 0.7655 - val_masked_auc: 0.7849\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4241 - masked_acc: 0.7667 - masked_auc: 0.7887 - val_loss: 0.4890 - val_masked_acc: 0.7694 - val_masked_auc: 0.7939\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4167 - masked_acc: 0.7705 - masked_auc: 0.7968 - val_loss: 0.4880 - val_masked_acc: 0.7722 - val_masked_auc: 0.8004\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4188 - masked_acc: 0.7730 - masked_auc: 0.8022 - val_loss: 0.4939 - val_masked_acc: 0.7741 - val_masked_auc: 0.8047\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4104 - masked_acc: 0.7750 - masked_auc: 0.8064 - val_loss: 0.4930 - val_masked_acc: 0.7758 - val_masked_auc: 0.8082\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4178 - masked_acc: 0.7761 - masked_auc: 0.8092 - val_loss: 0.5073 - val_masked_acc: 0.7767 - val_masked_auc: 0.8106\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4080 - masked_acc: 0.7773 - masked_auc: 0.8117 - val_loss: 0.4989 - val_masked_acc: 0.7775 - val_masked_auc: 0.8125\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4103 - masked_acc: 0.7781 - masked_auc: 0.8135 - val_loss: 0.5022 - val_masked_acc: 0.7785 - val_masked_auc: 0.8142\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4176 - masked_acc: 0.7787 - masked_auc: 0.8147 - val_loss: 0.5062 - val_masked_acc: 0.7790 - val_masked_auc: 0.8156\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4084 - masked_acc: 0.7798 - masked_auc: 0.8171\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4770 - masked_acc: 0.7800 - masked_auc: 0.8177\n",
      "Test:  [0.47699466347694397, 0.7799575328826904, 0.817650556564331]\n"
     ]
    }
   ],
   "source": [
    "# 5 fold cross validation with LSTM-based model\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "    \n",
    "    output = tf.concat([embedding_chap, embedding_sub_chap, embedding_ques, dense_features], axis = 2)\n",
    "\n",
    "    pred = Dense(1, input_shape = (None, 4*EMBEDDING_DIM), activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='logistic_regression'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:18:05.848589Z",
     "iopub.status.busy": "2021-08-12T22:18:05.847884Z",
     "iopub.status.idle": "2021-08-12T22:18:05.851881Z",
     "shell.execute_reply": "2021-08-12T22:18:05.852384Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.771838Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.435588,
     "end_time": "2021-08-12T22:18:05.852553",
     "exception": false,
     "start_time": "2021-08-12T22:18:05.416965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.4815811276435852 +/- 0.013039664184991601\n",
      "test avg acc:  0.7801615118980407 +/- 0.00046080431042528567\n",
      "test avg auc:  0.8152597665786743 +/- 0.0029350064806416996\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:18:06.710641Z",
     "iopub.status.busy": "2021-08-12T22:18:06.709913Z",
     "iopub.status.idle": "2021-08-12T22:18:06.715132Z",
     "shell.execute_reply": "2021-08-12T22:18:06.715691Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.782922Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.437386,
     "end_time": "2021-08-12T22:18:06.715859",
     "exception": false,
     "start_time": "2021-08-12T22:18:06.278473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.4048911690711975 +/- 0.0027915491596637956\n",
      "train avg acc:  0.7798261046409607 +/- 0.0004575553093252135\n",
      "train avg auc:  0.8145546913146973 +/- 0.0031261904269724713\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 436.256148,
   "end_time": "2021-08-12T22:18:09.327570",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T22:10:53.071422",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
