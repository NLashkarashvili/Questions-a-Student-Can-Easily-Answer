{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:10:39.957465Z",
     "iopub.status.busy": "2021-08-12T22:10:39.956747Z",
     "iopub.status.idle": "2021-08-12T22:10:47.232081Z",
     "shell.execute_reply": "2021-08-12T22:10:47.232609Z",
     "shell.execute_reply.started": "2021-08-06T21:05:15.103244Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.327662,
     "end_time": "2021-08-12T22:10:47.232933",
     "exception": false,
     "start_time": "2021-08-12T22:10:39.905271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:33.049280Z",
     "iopub.status.busy": "2021-08-12T22:17:33.048333Z",
     "iopub.status.idle": "2021-08-12T22:17:33.051956Z",
     "shell.execute_reply": "2021-08-12T22:17:33.051402Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.04112Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.375507,
     "end_time": "2021-08-12T22:17:33.052096",
     "exception": false,
     "start_time": "2021-08-12T22:17:32.676589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:33.778286Z",
     "iopub.status.busy": "2021-08-12T22:17:33.777590Z",
     "iopub.status.idle": "2021-08-12T22:17:33.779431Z",
     "shell.execute_reply": "2021-08-12T22:17:33.779950Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.049329Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.366491,
     "end_time": "2021-08-12T22:17:33.780123",
     "exception": false,
     "start_time": "2021-08-12T22:17:33.413632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 39\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:17:38.790150Z",
     "iopub.status.busy": "2021-08-12T22:17:38.789060Z",
     "iopub.status.idle": "2021-08-12T22:18:04.649522Z",
     "shell.execute_reply": "2021-08-12T22:18:04.650006Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.318071Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 26.225428,
     "end_time": "2021-08-12T22:18:04.650205",
     "exception": false,
     "start_time": "2021-08-12T22:17:38.424777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 90ms/step - loss: 0.6100 - masked_acc: 0.5795 - masked_auc: 0.5452 - val_loss: 0.5083 - val_masked_acc: 0.7191 - val_masked_auc: 0.6471\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4650 - masked_acc: 0.7322 - masked_auc: 0.6826 - val_loss: 0.5110 - val_masked_acc: 0.7500 - val_masked_auc: 0.7321\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4216 - masked_acc: 0.7555 - masked_auc: 0.7467 - val_loss: 0.5061 - val_masked_acc: 0.7633 - val_masked_auc: 0.7674\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4252 - masked_acc: 0.7653 - masked_auc: 0.7741 - val_loss: 0.5199 - val_masked_acc: 0.7702 - val_masked_auc: 0.7852\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4035 - masked_acc: 0.7719 - masked_auc: 0.7898 - val_loss: 0.5276 - val_masked_acc: 0.7745 - val_masked_auc: 0.7960\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4059 - masked_acc: 0.7757 - masked_auc: 0.7989 - val_loss: 0.5323 - val_masked_acc: 0.7774 - val_masked_auc: 0.8031\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.3987 - masked_acc: 0.7784 - masked_auc: 0.8053 - val_loss: 0.5352 - val_masked_acc: 0.7796 - val_masked_auc: 0.8082\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4013 - masked_acc: 0.7804 - masked_auc: 0.8098 - val_loss: 0.5471 - val_masked_acc: 0.7813 - val_masked_auc: 0.8120\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4047 - masked_acc: 0.7816 - masked_auc: 0.8132 - val_loss: 0.5486 - val_masked_acc: 0.7824 - val_masked_auc: 0.8149\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3971 - masked_acc: 0.7829 - masked_auc: 0.8160 - val_loss: 0.5479 - val_masked_acc: 0.7835 - val_masked_auc: 0.8172\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4015 - masked_acc: 0.7839 - masked_auc: 0.8180 - val_loss: 0.5559 - val_masked_acc: 0.7844 - val_masked_auc: 0.8191\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3981 - masked_acc: 0.7848 - masked_auc: 0.8197 - val_loss: 0.5614 - val_masked_acc: 0.7851 - val_masked_auc: 0.8207\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3923 - masked_acc: 0.7855 - masked_auc: 0.8214 - val_loss: 0.5557 - val_masked_acc: 0.7857 - val_masked_auc: 0.8221\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3970 - masked_acc: 0.7865 - masked_auc: 0.8235\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4798 - masked_acc: 0.7868 - masked_auc: 0.8240\n",
      "Test:  [0.47981464862823486, 0.7868155241012573, 0.8240474462509155]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 76ms/step - loss: 0.5741 - masked_acc: 0.6932 - masked_auc: 0.5693 - val_loss: 0.5107 - val_masked_acc: 0.7477 - val_masked_auc: 0.6913\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4312 - masked_acc: 0.7572 - masked_auc: 0.7226 - val_loss: 0.5286 - val_masked_acc: 0.7619 - val_masked_auc: 0.7552\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4257 - masked_acc: 0.7646 - masked_auc: 0.7667 - val_loss: 0.5314 - val_masked_acc: 0.7710 - val_masked_auc: 0.7813\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4012 - masked_acc: 0.7732 - masked_auc: 0.7878 - val_loss: 0.5524 - val_masked_acc: 0.7746 - val_masked_auc: 0.7947\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4013 - masked_acc: 0.7758 - masked_auc: 0.7987 - val_loss: 0.5545 - val_masked_acc: 0.7776 - val_masked_auc: 0.8032\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4015 - masked_acc: 0.7786 - masked_auc: 0.8057 - val_loss: 0.5602 - val_masked_acc: 0.7796 - val_masked_auc: 0.8090\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3999 - masked_acc: 0.7803 - masked_auc: 0.8110 - val_loss: 0.5667 - val_masked_acc: 0.7812 - val_masked_auc: 0.8129\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.3982 - masked_acc: 0.7819 - masked_auc: 0.8144 - val_loss: 0.5731 - val_masked_acc: 0.7824 - val_masked_auc: 0.8158\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4028 - masked_acc: 0.7827 - masked_auc: 0.8168 - val_loss: 0.5740 - val_masked_acc: 0.7832 - val_masked_auc: 0.8180\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3959 - masked_acc: 0.7837 - masked_auc: 0.8187 - val_loss: 0.5802 - val_masked_acc: 0.7840 - val_masked_auc: 0.8199\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3970 - masked_acc: 0.7843 - masked_auc: 0.8207 - val_loss: 0.5787 - val_masked_acc: 0.7847 - val_masked_auc: 0.8214\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3941 - masked_acc: 0.7854 - masked_auc: 0.8230\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4659 - masked_acc: 0.7858 - masked_auc: 0.8241\n",
      "Test:  [0.4658880829811096, 0.7858436703681946, 0.8240906000137329]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 59ms/step - loss: 0.5723 - masked_acc: 0.7229 - masked_auc: 0.5843 - val_loss: 0.4758 - val_masked_acc: 0.7488 - val_masked_auc: 0.6675\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4600 - masked_acc: 0.7547 - masked_auc: 0.7017 - val_loss: 0.4639 - val_masked_acc: 0.7660 - val_masked_auc: 0.7460\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4219 - masked_acc: 0.7697 - masked_auc: 0.7593 - val_loss: 0.4586 - val_masked_acc: 0.7748 - val_masked_auc: 0.7765\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4063 - masked_acc: 0.7774 - masked_auc: 0.7828 - val_loss: 0.4612 - val_masked_acc: 0.7793 - val_masked_auc: 0.7922\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4145 - masked_acc: 0.7805 - masked_auc: 0.7957 - val_loss: 0.4635 - val_masked_acc: 0.7822 - val_masked_auc: 0.8014\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4172 - masked_acc: 0.7827 - masked_auc: 0.8041 - val_loss: 0.4651 - val_masked_acc: 0.7844 - val_masked_auc: 0.8077\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4069 - masked_acc: 0.7850 - masked_auc: 0.8098 - val_loss: 0.4668 - val_masked_acc: 0.7858 - val_masked_auc: 0.8120\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4050 - masked_acc: 0.7865 - masked_auc: 0.8134 - val_loss: 0.4708 - val_masked_acc: 0.7868 - val_masked_auc: 0.8154\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4073 - masked_acc: 0.7872 - masked_auc: 0.8166 - val_loss: 0.4700 - val_masked_acc: 0.7878 - val_masked_auc: 0.8180\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4040 - masked_acc: 0.7883 - masked_auc: 0.8189 - val_loss: 0.4748 - val_masked_acc: 0.7887 - val_masked_auc: 0.8201\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4042 - masked_acc: 0.7890 - masked_auc: 0.8209 - val_loss: 0.4706 - val_masked_acc: 0.7892 - val_masked_auc: 0.8218\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4057 - masked_acc: 0.7894 - masked_auc: 0.8225 - val_loss: 0.4756 - val_masked_acc: 0.7897 - val_masked_auc: 0.8233\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4033 - masked_acc: 0.7901 - masked_auc: 0.8238 - val_loss: 0.4740 - val_masked_acc: 0.7903 - val_masked_auc: 0.8246\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3999 - masked_acc: 0.7909 - masked_auc: 0.8259\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4854 - masked_acc: 0.7909 - masked_auc: 0.8264\n",
      "Test:  [0.4854038655757904, 0.7908599376678467, 0.8264012932777405]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 58ms/step - loss: 0.6098 - masked_acc: 0.5678 - masked_auc: 0.5519 - val_loss: 0.5120 - val_masked_acc: 0.7207 - val_masked_auc: 0.6476\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4597 - masked_acc: 0.7325 - masked_auc: 0.6835 - val_loss: 0.5004 - val_masked_acc: 0.7498 - val_masked_auc: 0.7353\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4307 - masked_acc: 0.7541 - masked_auc: 0.7493 - val_loss: 0.4938 - val_masked_acc: 0.7610 - val_masked_auc: 0.7692\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4247 - masked_acc: 0.7633 - masked_auc: 0.7754 - val_loss: 0.4990 - val_masked_acc: 0.7679 - val_masked_auc: 0.7866\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4160 - masked_acc: 0.7692 - masked_auc: 0.7903 - val_loss: 0.5034 - val_masked_acc: 0.7724 - val_masked_auc: 0.7973\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4091 - masked_acc: 0.7735 - masked_auc: 0.8003 - val_loss: 0.5061 - val_masked_acc: 0.7753 - val_masked_auc: 0.8044\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4139 - masked_acc: 0.7760 - masked_auc: 0.8061 - val_loss: 0.5099 - val_masked_acc: 0.7774 - val_masked_auc: 0.8093\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.3989 - masked_acc: 0.7782 - masked_auc: 0.8111 - val_loss: 0.5129 - val_masked_acc: 0.7791 - val_masked_auc: 0.8131\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4147 - masked_acc: 0.7792 - masked_auc: 0.8140 - val_loss: 0.5168 - val_masked_acc: 0.7803 - val_masked_auc: 0.8160\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4058 - masked_acc: 0.7809 - masked_auc: 0.8169 - val_loss: 0.5182 - val_masked_acc: 0.7813 - val_masked_auc: 0.8183\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4138 - masked_acc: 0.7814 - masked_auc: 0.8187 - val_loss: 0.5166 - val_masked_acc: 0.7821 - val_masked_auc: 0.8202\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.3956 - masked_acc: 0.7825 - masked_auc: 0.8210 - val_loss: 0.5241 - val_masked_acc: 0.7827 - val_masked_auc: 0.8217\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4015 - masked_acc: 0.7831 - masked_auc: 0.8222 - val_loss: 0.5210 - val_masked_acc: 0.7835 - val_masked_auc: 0.8231\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3983 - masked_acc: 0.7842 - masked_auc: 0.8244\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4673 - masked_acc: 0.7846 - masked_auc: 0.8249\n",
      "Test:  [0.4672662317752838, 0.7845722436904907, 0.8248674869537354]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 57ms/step - loss: 0.5707 - masked_acc: 0.7192 - masked_auc: 0.5540 - val_loss: 0.5017 - val_masked_acc: 0.7447 - val_masked_auc: 0.6809\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4623 - masked_acc: 0.7497 - masked_auc: 0.7129 - val_loss: 0.4816 - val_masked_acc: 0.7616 - val_masked_auc: 0.7540\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4257 - masked_acc: 0.7651 - masked_auc: 0.7656 - val_loss: 0.4894 - val_masked_acc: 0.7710 - val_masked_auc: 0.7820\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4049 - masked_acc: 0.7737 - masked_auc: 0.7883 - val_loss: 0.4932 - val_masked_acc: 0.7753 - val_masked_auc: 0.7965\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4128 - masked_acc: 0.7765 - masked_auc: 0.8001 - val_loss: 0.4954 - val_masked_acc: 0.7785 - val_masked_auc: 0.8052\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4103 - masked_acc: 0.7790 - masked_auc: 0.8075 - val_loss: 0.4960 - val_masked_acc: 0.7804 - val_masked_auc: 0.8112\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4062 - masked_acc: 0.7810 - masked_auc: 0.8130 - val_loss: 0.5002 - val_masked_acc: 0.7816 - val_masked_auc: 0.8156\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4063 - masked_acc: 0.7818 - masked_auc: 0.8170 - val_loss: 0.4992 - val_masked_acc: 0.7826 - val_masked_auc: 0.8188\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4131 - masked_acc: 0.7828 - masked_auc: 0.8198 - val_loss: 0.5009 - val_masked_acc: 0.7835 - val_masked_auc: 0.8213\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4097 - masked_acc: 0.7837 - masked_auc: 0.8221 - val_loss: 0.5109 - val_masked_acc: 0.7843 - val_masked_auc: 0.8233\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.3967 - masked_acc: 0.7848 - masked_auc: 0.8240 - val_loss: 0.5080 - val_masked_acc: 0.7850 - val_masked_auc: 0.8248\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4007 - masked_acc: 0.7852 - masked_auc: 0.8255 - val_loss: 0.5071 - val_masked_acc: 0.7855 - val_masked_auc: 0.8262\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3992 - masked_acc: 0.7860 - masked_auc: 0.8276\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4641 - masked_acc: 0.7863 - masked_auc: 0.8279\n",
      "Test:  [0.46406984329223633, 0.786250650882721, 0.8279287815093994]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "    \n",
    "    output = tf.concat([embedding_chap, embedding_sub_chap, embedding_ques, embedding_shifted, dense_features], axis = 2)\n",
    "\n",
    "    pred = Dense(1, input_shape = (None, 5*EMBEDDING_DIM), activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='logistic_regression'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:18:05.511881Z",
     "iopub.status.busy": "2021-08-12T22:18:05.510819Z",
     "iopub.status.idle": "2021-08-12T22:18:05.521935Z",
     "shell.execute_reply": "2021-08-12T22:18:05.521363Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.771838Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.444406,
     "end_time": "2021-08-12T22:18:05.522075",
     "exception": false,
     "start_time": "2021-08-12T22:18:05.077669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.472488534450531 +/- 0.008511057427496041\n",
      "test avg acc:  0.786868405342102 +/- 0.0021278715845775304\n",
      "test avg auc:  0.8254671216011047 +/- 0.0014968164694641162\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:18:06.393662Z",
     "iopub.status.busy": "2021-08-12T22:18:06.392993Z",
     "iopub.status.idle": "2021-08-12T22:18:06.401854Z",
     "shell.execute_reply": "2021-08-12T22:18:06.402388Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.782922Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.44547,
     "end_time": "2021-08-12T22:18:06.402563",
     "exception": false,
     "start_time": "2021-08-12T22:18:05.957093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.3976888537406921 +/- 0.002038230535757541\n",
      "train avg acc:  0.7865806221961975 +/- 0.0022771689982637963\n",
      "train avg auc:  0.8248626589775085 +/- 0.0016659799233584892\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 458.194816,
   "end_time": "2021-08-12T22:18:09.325111",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T22:10:31.130295",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
