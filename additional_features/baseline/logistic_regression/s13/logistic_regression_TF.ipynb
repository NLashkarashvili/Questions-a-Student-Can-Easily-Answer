{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:07:44.992185Z",
     "iopub.status.busy": "2021-08-12T22:07:44.991408Z",
     "iopub.status.idle": "2021-08-12T22:07:52.210694Z",
     "shell.execute_reply": "2021-08-12T22:07:52.209855Z",
     "shell.execute_reply.started": "2021-08-06T21:05:15.103244Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.265358,
     "end_time": "2021-08-12T22:07:52.210882",
     "exception": false,
     "start_time": "2021-08-12T22:07:44.945524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:14:35.703332Z",
     "iopub.status.busy": "2021-08-12T22:14:35.701981Z",
     "iopub.status.idle": "2021-08-12T22:14:35.703979Z",
     "shell.execute_reply": "2021-08-12T22:14:35.704452Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.04112Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.364083,
     "end_time": "2021-08-12T22:14:35.704610",
     "exception": false,
     "start_time": "2021-08-12T22:14:35.340527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:14:36.425501Z",
     "iopub.status.busy": "2021-08-12T22:14:36.424811Z",
     "iopub.status.idle": "2021-08-12T22:14:36.426705Z",
     "shell.execute_reply": "2021-08-12T22:14:36.427229Z",
     "shell.execute_reply.started": "2021-08-06T21:09:46.049329Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.365189,
     "end_time": "2021-08-12T22:14:36.427394",
     "exception": false,
     "start_time": "2021-08-12T22:14:36.062205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 2\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:14:41.196628Z",
     "iopub.status.busy": "2021-08-12T22:14:41.191359Z",
     "iopub.status.idle": "2021-08-12T22:15:04.566344Z",
     "shell.execute_reply": "2021-08-12T22:15:04.565728Z",
     "shell.execute_reply.started": "2021-08-06T21:09:47.318071Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 23.749799,
     "end_time": "2021-08-12T22:15:04.566495",
     "exception": false,
     "start_time": "2021-08-12T22:14:40.816696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 3s 90ms/step - loss: 0.6152 - masked_acc: 0.5885 - masked_auc: 0.5599 - val_loss: 0.4992 - val_masked_acc: 0.7236 - val_masked_auc: 0.6486\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4756 - masked_acc: 0.7333 - masked_auc: 0.6728 - val_loss: 0.4928 - val_masked_acc: 0.7480 - val_masked_auc: 0.7217\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4366 - masked_acc: 0.7524 - masked_auc: 0.7363 - val_loss: 0.4949 - val_masked_acc: 0.7587 - val_masked_auc: 0.7553\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4389 - masked_acc: 0.7597 - masked_auc: 0.7614 - val_loss: 0.5031 - val_masked_acc: 0.7646 - val_masked_auc: 0.7713\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4222 - masked_acc: 0.7660 - masked_auc: 0.7751 - val_loss: 0.5138 - val_masked_acc: 0.7677 - val_masked_auc: 0.7808\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4281 - masked_acc: 0.7684 - masked_auc: 0.7829 - val_loss: 0.5109 - val_masked_acc: 0.7699 - val_masked_auc: 0.7873\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4230 - masked_acc: 0.7707 - masked_auc: 0.7891 - val_loss: 0.5192 - val_masked_acc: 0.7717 - val_masked_auc: 0.7919\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4228 - masked_acc: 0.7722 - masked_auc: 0.7934 - val_loss: 0.5212 - val_masked_acc: 0.7730 - val_masked_auc: 0.7954\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4240 - masked_acc: 0.7735 - masked_auc: 0.7965 - val_loss: 0.5219 - val_masked_acc: 0.7741 - val_masked_auc: 0.7982\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4214 - masked_acc: 0.7745 - masked_auc: 0.7991 - val_loss: 0.5260 - val_masked_acc: 0.7750 - val_masked_auc: 0.8003\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4276 - masked_acc: 0.7750 - masked_auc: 0.8010 - val_loss: 0.5281 - val_masked_acc: 0.7757 - val_masked_auc: 0.8021\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4267 - masked_acc: 0.7759 - masked_auc: 0.8026 - val_loss: 0.5292 - val_masked_acc: 0.7762 - val_masked_auc: 0.8035\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4177 - masked_acc: 0.7768 - masked_auc: 0.8049\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4736 - masked_acc: 0.7771 - masked_auc: 0.8056\n",
      "Test:  [0.47355759143829346, 0.7770758271217346, 0.8056098818778992]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 73ms/step - loss: 0.6139 - masked_acc: 0.6248 - masked_auc: 0.5881 - val_loss: 0.5565 - val_masked_acc: 0.7284 - val_masked_auc: 0.6382\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4627 - masked_acc: 0.7384 - masked_auc: 0.6670 - val_loss: 0.5302 - val_masked_acc: 0.7503 - val_masked_auc: 0.7160\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4293 - masked_acc: 0.7546 - masked_auc: 0.7314 - val_loss: 0.5269 - val_masked_acc: 0.7598 - val_masked_auc: 0.7525\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4181 - masked_acc: 0.7621 - masked_auc: 0.7596 - val_loss: 0.5330 - val_masked_acc: 0.7652 - val_masked_auc: 0.7704\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4143 - masked_acc: 0.7667 - masked_auc: 0.7748 - val_loss: 0.5359 - val_masked_acc: 0.7684 - val_masked_auc: 0.7811\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4260 - masked_acc: 0.7690 - masked_auc: 0.7839 - val_loss: 0.5401 - val_masked_acc: 0.7706 - val_masked_auc: 0.7881\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4156 - masked_acc: 0.7713 - masked_auc: 0.7901 - val_loss: 0.5442 - val_masked_acc: 0.7723 - val_masked_auc: 0.7931\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4307 - masked_acc: 0.7728 - masked_auc: 0.7943 - val_loss: 0.5477 - val_masked_acc: 0.7738 - val_masked_auc: 0.7968\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4204 - masked_acc: 0.7741 - masked_auc: 0.7978 - val_loss: 0.5522 - val_masked_acc: 0.7748 - val_masked_auc: 0.7996\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4135 - masked_acc: 0.7750 - masked_auc: 0.8007 - val_loss: 0.5504 - val_masked_acc: 0.7752 - val_masked_auc: 0.8018\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4116 - masked_acc: 0.7756 - masked_auc: 0.8027 - val_loss: 0.5499 - val_masked_acc: 0.7758 - val_masked_auc: 0.8037\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4152 - masked_acc: 0.7761 - masked_auc: 0.8044 - val_loss: 0.5557 - val_masked_acc: 0.7763 - val_masked_auc: 0.8053\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4104 - masked_acc: 0.7766 - masked_auc: 0.8060 - val_loss: 0.5514 - val_masked_acc: 0.7767 - val_masked_auc: 0.8067\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4115 - masked_acc: 0.7773 - masked_auc: 0.8081\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5046 - masked_acc: 0.7776 - masked_auc: 0.8086\n",
      "Test:  [0.5045920610427856, 0.7775555849075317, 0.8086242079734802]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 56ms/step - loss: 0.6160 - masked_acc: 0.6497 - masked_auc: 0.5905 - val_loss: 0.4851 - val_masked_acc: 0.7336 - val_masked_auc: 0.6470\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4699 - masked_acc: 0.7408 - masked_auc: 0.6757 - val_loss: 0.4846 - val_masked_acc: 0.7527 - val_masked_auc: 0.7227\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4395 - masked_acc: 0.7566 - masked_auc: 0.7376 - val_loss: 0.4916 - val_masked_acc: 0.7611 - val_masked_auc: 0.7569\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4244 - masked_acc: 0.7639 - masked_auc: 0.7639 - val_loss: 0.5037 - val_masked_acc: 0.7661 - val_masked_auc: 0.7719\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4352 - masked_acc: 0.7670 - masked_auc: 0.7758 - val_loss: 0.5182 - val_masked_acc: 0.7690 - val_masked_auc: 0.7818\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4321 - masked_acc: 0.7698 - masked_auc: 0.7842 - val_loss: 0.5234 - val_masked_acc: 0.7711 - val_masked_auc: 0.7881\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4223 - masked_acc: 0.7719 - masked_auc: 0.7907 - val_loss: 0.5316 - val_masked_acc: 0.7720 - val_masked_auc: 0.7927\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4313 - masked_acc: 0.7723 - masked_auc: 0.7941 - val_loss: 0.5355 - val_masked_acc: 0.7731 - val_masked_auc: 0.7960\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4280 - masked_acc: 0.7736 - masked_auc: 0.7972 - val_loss: 0.5437 - val_masked_acc: 0.7739 - val_masked_auc: 0.7986\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.4259 - masked_acc: 0.7742 - masked_auc: 0.7998 - val_loss: 0.5426 - val_masked_acc: 0.7744 - val_masked_auc: 0.8008\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.4208 - masked_acc: 0.7748 - masked_auc: 0.8019 - val_loss: 0.5433 - val_masked_acc: 0.7751 - val_masked_auc: 0.8026\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4199 - masked_acc: 0.7755 - masked_auc: 0.8033 - val_loss: 0.5500 - val_masked_acc: 0.7757 - val_masked_auc: 0.8041\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4187 - masked_acc: 0.7763 - masked_auc: 0.8057\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4680 - masked_acc: 0.7765 - masked_auc: 0.8065\n",
      "Test:  [0.46804869174957275, 0.7765282988548279, 0.8064651489257812]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 55ms/step - loss: 0.6130 - masked_acc: 0.6091 - masked_auc: 0.5803 - val_loss: 0.5692 - val_masked_acc: 0.7226 - val_masked_auc: 0.6352\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4764 - masked_acc: 0.7308 - masked_auc: 0.6605 - val_loss: 0.5381 - val_masked_acc: 0.7448 - val_masked_auc: 0.7135\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4358 - masked_acc: 0.7497 - masked_auc: 0.7274 - val_loss: 0.5308 - val_masked_acc: 0.7562 - val_masked_auc: 0.7512\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4261 - masked_acc: 0.7588 - masked_auc: 0.7585 - val_loss: 0.5428 - val_masked_acc: 0.7632 - val_masked_auc: 0.7696\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4170 - masked_acc: 0.7651 - masked_auc: 0.7738 - val_loss: 0.5466 - val_masked_acc: 0.7665 - val_masked_auc: 0.7805\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4087 - masked_acc: 0.7681 - masked_auc: 0.7832 - val_loss: 0.5473 - val_masked_acc: 0.7692 - val_masked_auc: 0.7877\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4164 - masked_acc: 0.7701 - masked_auc: 0.7898 - val_loss: 0.5560 - val_masked_acc: 0.7710 - val_masked_auc: 0.7929\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4121 - masked_acc: 0.7716 - masked_auc: 0.7944 - val_loss: 0.5561 - val_masked_acc: 0.7723 - val_masked_auc: 0.7966\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4158 - masked_acc: 0.7729 - masked_auc: 0.7980 - val_loss: 0.5547 - val_masked_acc: 0.7734 - val_masked_auc: 0.7998\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4270 - masked_acc: 0.7735 - masked_auc: 0.8005 - val_loss: 0.5555 - val_masked_acc: 0.7742 - val_masked_auc: 0.8021\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4106 - masked_acc: 0.7748 - masked_auc: 0.8031 - val_loss: 0.5648 - val_masked_acc: 0.7750 - val_masked_auc: 0.8039\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4096 - masked_acc: 0.7754 - masked_auc: 0.8046 - val_loss: 0.5540 - val_masked_acc: 0.7757 - val_masked_auc: 0.8056\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.4085 - masked_acc: 0.7760 - masked_auc: 0.8063 - val_loss: 0.5612 - val_masked_acc: 0.7761 - val_masked_auc: 0.8070\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4102 - masked_acc: 0.7768 - masked_auc: 0.8083\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4956 - masked_acc: 0.7771 - masked_auc: 0.8088\n",
      "Test:  [0.49556443095207214, 0.7771236300468445, 0.8088390231132507]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 2s 56ms/step - loss: 0.6149 - masked_acc: 0.6573 - masked_auc: 0.5585 - val_loss: 0.5027 - val_masked_acc: 0.7266 - val_masked_auc: 0.6223\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4668 - masked_acc: 0.7363 - masked_auc: 0.6592 - val_loss: 0.5059 - val_masked_acc: 0.7515 - val_masked_auc: 0.7146\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4344 - masked_acc: 0.7559 - masked_auc: 0.7305 - val_loss: 0.5084 - val_masked_acc: 0.7615 - val_masked_auc: 0.7528\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4368 - masked_acc: 0.7629 - masked_auc: 0.7601 - val_loss: 0.5196 - val_masked_acc: 0.7668 - val_masked_auc: 0.7708\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4159 - masked_acc: 0.7684 - masked_auc: 0.7747 - val_loss: 0.5272 - val_masked_acc: 0.7704 - val_masked_auc: 0.7818\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4110 - masked_acc: 0.7717 - masked_auc: 0.7850 - val_loss: 0.5312 - val_masked_acc: 0.7727 - val_masked_auc: 0.7892\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4213 - masked_acc: 0.7735 - masked_auc: 0.7912 - val_loss: 0.5311 - val_masked_acc: 0.7745 - val_masked_auc: 0.7942\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4207 - masked_acc: 0.7750 - masked_auc: 0.7956 - val_loss: 0.5346 - val_masked_acc: 0.7758 - val_masked_auc: 0.7979\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4185 - masked_acc: 0.7762 - masked_auc: 0.7993 - val_loss: 0.5412 - val_masked_acc: 0.7768 - val_masked_auc: 0.8010\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4140 - masked_acc: 0.7773 - masked_auc: 0.8020 - val_loss: 0.5392 - val_masked_acc: 0.7777 - val_masked_auc: 0.8033\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4158 - masked_acc: 0.7781 - masked_auc: 0.8042 - val_loss: 0.5367 - val_masked_acc: 0.7786 - val_masked_auc: 0.8052\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4109 - masked_acc: 0.7794 - masked_auc: 0.8070\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5253 - masked_acc: 0.7795 - masked_auc: 0.8076\n",
      "Test:  [0.5252897143363953, 0.7794773578643799, 0.8076157569885254]\n"
     ]
    }
   ],
   "source": [
    "# 5 fold cross validation with LSTM-based model\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "    \n",
    "    output = tf.concat([embedding_chap, embedding_sub_chap, embedding_ques, dense_features], axis = 2)\n",
    "\n",
    "    pred = Dense(1, input_shape = (None, 4*EMBEDDING_DIM), activation='sigmoid')(output)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='logistic_regression'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:15:05.452343Z",
     "iopub.status.busy": "2021-08-12T22:15:05.451259Z",
     "iopub.status.idle": "2021-08-12T22:15:05.458010Z",
     "shell.execute_reply": "2021-08-12T22:15:05.457473Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.771838Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.463035,
     "end_time": "2021-08-12T22:15:05.458174",
     "exception": false,
     "start_time": "2021-08-12T22:15:04.995139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.49341049790382385 +/- 0.02089646060315748\n",
      "test avg acc:  0.7775521397590637 +/- 0.0010163878316092928\n",
      "test avg auc:  0.8074308037757874 +/- 0.0012401410258456817\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:15:06.330980Z",
     "iopub.status.busy": "2021-08-12T22:15:06.330170Z",
     "iopub.status.idle": "2021-08-12T22:15:06.335927Z",
     "shell.execute_reply": "2021-08-12T22:15:06.335350Z",
     "shell.execute_reply.started": "2021-08-06T21:11:24.782922Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.444135,
     "end_time": "2021-08-12T22:15:06.336087",
     "exception": false,
     "start_time": "2021-08-12T22:15:05.891952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.41380901336669923 +/- 0.0036448443872381456\n",
      "train avg acc:  0.777300238609314 +/- 0.0010733419882888013\n",
      "train avg auc:  0.8068000555038453 +/- 0.0013204170091770835\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 453.095485,
   "end_time": "2021-08-12T22:15:09.399333",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T22:07:36.303848",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
