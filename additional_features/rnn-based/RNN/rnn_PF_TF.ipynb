{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T20:58:46.015631Z",
     "iopub.status.busy": "2021-08-12T20:58:46.014942Z",
     "iopub.status.idle": "2021-08-12T20:58:53.233106Z",
     "shell.execute_reply": "2021-08-12T20:58:53.232336Z",
     "shell.execute_reply.started": "2021-08-06T20:53:41.672006Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.263776,
     "end_time": "2021-08-12T20:58:53.233310",
     "exception": false,
     "start_time": "2021-08-12T20:58:45.969534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import SimpleRNN as RNN\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:47.800095Z",
     "iopub.status.busy": "2021-08-12T21:06:47.799149Z",
     "iopub.status.idle": "2021-08-12T21:06:47.802760Z",
     "shell.execute_reply": "2021-08-12T21:06:47.802120Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.012606Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.367464,
     "end_time": "2021-08-12T21:06:47.802915",
     "exception": false,
     "start_time": "2021-08-12T21:06:47.435451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "RNN_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:48.556191Z",
     "iopub.status.busy": "2021-08-12T21:06:48.555318Z",
     "iopub.status.idle": "2021-08-12T21:06:48.563384Z",
     "shell.execute_reply": "2021-08-12T21:06:48.562814Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.932106Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.400679,
     "end_time": "2021-08-12T21:06:48.563590",
     "exception": false,
     "start_time": "2021-08-12T21:06:48.162911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 2\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:53.526328Z",
     "iopub.status.busy": "2021-08-12T21:06:53.525206Z",
     "iopub.status.idle": "2021-08-12T21:07:58.746188Z",
     "shell.execute_reply": "2021-08-12T21:07:58.746796Z",
     "shell.execute_reply.started": "2021-08-06T21:04:56.750188Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 65.599912,
     "end_time": "2021-08-12T21:07:58.747002",
     "exception": false,
     "start_time": "2021-08-12T21:06:53.147090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 8s 156ms/step - loss: 0.6189 - masked_acc: 0.5835 - masked_auc: 0.5334 - val_loss: 0.4781 - val_masked_acc: 0.7186 - val_masked_auc: 0.6293\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4451 - masked_acc: 0.7313 - masked_auc: 0.6762 - val_loss: 0.5057 - val_masked_acc: 0.7515 - val_masked_auc: 0.7413\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3505 - masked_acc: 0.7616 - masked_auc: 0.7648 - val_loss: 0.5826 - val_masked_acc: 0.7763 - val_masked_auc: 0.7973\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2737 - masked_acc: 0.7849 - masked_auc: 0.8129 - val_loss: 0.6703 - val_masked_acc: 0.7970 - val_masked_auc: 0.8333\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2390 - masked_acc: 0.8034 - masked_auc: 0.8427 - val_loss: 0.7903 - val_masked_acc: 0.8122 - val_masked_auc: 0.8562\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2104 - masked_acc: 0.8169 - masked_auc: 0.8630 - val_loss: 0.9507 - val_masked_acc: 0.8249 - val_masked_auc: 0.8732\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1893 - masked_acc: 0.8287 - masked_auc: 0.8783 - val_loss: 0.9720 - val_masked_acc: 0.8353 - val_masked_auc: 0.8859\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1776 - masked_acc: 0.8385 - masked_auc: 0.8896 - val_loss: 1.0371 - val_masked_acc: 0.8438 - val_masked_auc: 0.8954\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1540 - masked_acc: 0.8466 - masked_auc: 0.8987 - val_loss: 1.2270 - val_masked_acc: 0.8511 - val_masked_auc: 0.9034\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1390 - masked_acc: 0.8535 - masked_auc: 0.9062 - val_loss: 1.3476 - val_masked_acc: 0.8573 - val_masked_auc: 0.9101\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1276 - masked_acc: 0.8594 - masked_auc: 0.9125 - val_loss: 1.3695 - val_masked_acc: 0.8629 - val_masked_auc: 0.9157\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1055 - masked_acc: 0.8665 - masked_auc: 0.9196\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2446 - masked_acc: 0.8687 - masked_auc: 0.9213\n",
      "Test:  [1.2445950508117676, 0.8686792850494385, 0.9213402271270752]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 6s 128ms/step - loss: 0.5846 - masked_acc: 0.6946 - masked_auc: 0.5700 - val_loss: 0.5244 - val_masked_acc: 0.7476 - val_masked_auc: 0.6684\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4229 - masked_acc: 0.7561 - masked_auc: 0.7136 - val_loss: 0.5274 - val_masked_acc: 0.7712 - val_masked_auc: 0.7613\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3282 - masked_acc: 0.7806 - masked_auc: 0.7827 - val_loss: 0.6452 - val_masked_acc: 0.7936 - val_masked_auc: 0.8127\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2568 - masked_acc: 0.8012 - masked_auc: 0.8264 - val_loss: 0.7630 - val_masked_acc: 0.8120 - val_masked_auc: 0.8454\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2214 - masked_acc: 0.8174 - masked_auc: 0.8543 - val_loss: 0.9097 - val_masked_acc: 0.8258 - val_masked_auc: 0.8668\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1859 - masked_acc: 0.8303 - masked_auc: 0.8732 - val_loss: 1.0453 - val_masked_acc: 0.8373 - val_masked_auc: 0.8821\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1651 - masked_acc: 0.8408 - masked_auc: 0.8867 - val_loss: 1.2547 - val_masked_acc: 0.8466 - val_masked_auc: 0.8932\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1484 - masked_acc: 0.8496 - masked_auc: 0.8967 - val_loss: 1.3213 - val_masked_acc: 0.8544 - val_masked_auc: 0.9018\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1410 - masked_acc: 0.8569 - masked_auc: 0.9045 - val_loss: 1.4055 - val_masked_acc: 0.8610 - val_masked_auc: 0.9084\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1273 - masked_acc: 0.8632 - masked_auc: 0.9109 - val_loss: 1.4591 - val_masked_acc: 0.8665 - val_masked_auc: 0.9138\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1146 - masked_acc: 0.8686 - masked_auc: 0.9160 - val_loss: 1.6419 - val_masked_acc: 0.8716 - val_masked_auc: 0.9183\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0957 - masked_acc: 0.8748 - masked_auc: 0.9218\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3380 - masked_acc: 0.8767 - masked_auc: 0.9233\n",
      "Test:  [1.3380062580108643, 0.8767417669296265, 0.9233134984970093]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 134ms/step - loss: 0.5922 - masked_acc: 0.6450 - masked_auc: 0.5152 - val_loss: 0.5078 - val_masked_acc: 0.7319 - val_masked_auc: 0.6755\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4122 - masked_acc: 0.7456 - masked_auc: 0.7195 - val_loss: 0.5027 - val_masked_acc: 0.7632 - val_masked_auc: 0.7692\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3372 - masked_acc: 0.7730 - masked_auc: 0.7892 - val_loss: 0.6574 - val_masked_acc: 0.7859 - val_masked_auc: 0.8157\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2803 - masked_acc: 0.7932 - masked_auc: 0.8279 - val_loss: 0.7094 - val_masked_acc: 0.8048 - val_masked_auc: 0.8463\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2230 - masked_acc: 0.8109 - masked_auc: 0.8554 - val_loss: 0.7708 - val_masked_acc: 0.8197 - val_masked_auc: 0.8677\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2021 - masked_acc: 0.8244 - masked_auc: 0.8737 - val_loss: 0.9758 - val_masked_acc: 0.8317 - val_masked_auc: 0.8828\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1887 - masked_acc: 0.8352 - masked_auc: 0.8871 - val_loss: 1.1173 - val_masked_acc: 0.8410 - val_masked_auc: 0.8934\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1583 - masked_acc: 0.8442 - masked_auc: 0.8971 - val_loss: 1.1487 - val_masked_acc: 0.8489 - val_masked_auc: 0.9021\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1463 - masked_acc: 0.8515 - masked_auc: 0.9051 - val_loss: 1.2271 - val_masked_acc: 0.8557 - val_masked_auc: 0.9093\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1291 - masked_acc: 0.8581 - masked_auc: 0.9119 - val_loss: 1.3915 - val_masked_acc: 0.8618 - val_masked_auc: 0.9152\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1147 - masked_acc: 0.8638 - masked_auc: 0.9175 - val_loss: 1.4014 - val_masked_acc: 0.8670 - val_masked_auc: 0.9201\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1151 - masked_acc: 0.8687 - masked_auc: 0.9219 - val_loss: 1.3502 - val_masked_acc: 0.8715 - val_masked_auc: 0.9243\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1014 - masked_acc: 0.8745 - masked_auc: 0.9273\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1442 - masked_acc: 0.8763 - masked_auc: 0.9288\n",
      "Test:  [1.1442147493362427, 0.8763490319252014, 0.9287794828414917]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 126ms/step - loss: 0.5941 - masked_acc: 0.6098 - masked_auc: 0.5386 - val_loss: 0.5339 - val_masked_acc: 0.7225 - val_masked_auc: 0.6566\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4354 - masked_acc: 0.7353 - masked_auc: 0.6976 - val_loss: 0.5397 - val_masked_acc: 0.7555 - val_masked_auc: 0.7538\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3383 - masked_acc: 0.7659 - masked_auc: 0.7761 - val_loss: 0.6259 - val_masked_acc: 0.7815 - val_masked_auc: 0.8067\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2789 - masked_acc: 0.7891 - masked_auc: 0.8197 - val_loss: 0.8397 - val_masked_acc: 0.8010 - val_masked_auc: 0.8393\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2280 - masked_acc: 0.8070 - masked_auc: 0.8487 - val_loss: 0.8607 - val_masked_acc: 0.8165 - val_masked_auc: 0.8616\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1977 - masked_acc: 0.8213 - masked_auc: 0.8683 - val_loss: 0.9650 - val_masked_acc: 0.8280 - val_masked_auc: 0.8775\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1815 - masked_acc: 0.8317 - masked_auc: 0.8822 - val_loss: 1.2320 - val_masked_acc: 0.8378 - val_masked_auc: 0.8889\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1586 - masked_acc: 0.8410 - masked_auc: 0.8929 - val_loss: 1.1740 - val_masked_acc: 0.8458 - val_masked_auc: 0.8979\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1531 - masked_acc: 0.8483 - masked_auc: 0.9009 - val_loss: 1.3453 - val_masked_acc: 0.8524 - val_masked_auc: 0.9047\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1407 - masked_acc: 0.8547 - masked_auc: 0.9071 - val_loss: 1.4452 - val_masked_acc: 0.8584 - val_masked_auc: 0.9102\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1225 - masked_acc: 0.8606 - masked_auc: 0.9125 - val_loss: 1.6925 - val_masked_acc: 0.8639 - val_masked_auc: 0.9154\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1000 - masked_acc: 0.8674 - masked_auc: 0.9190\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4358 - masked_acc: 0.8696 - masked_auc: 0.9209\n",
      "Test:  [1.4358006715774536, 0.8696155548095703, 0.9209021329879761]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 125ms/step - loss: 0.5983 - masked_acc: 0.7351 - masked_auc: 0.5321 - val_loss: 0.4905 - val_masked_acc: 0.7437 - val_masked_auc: 0.6374\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4494 - masked_acc: 0.7502 - masked_auc: 0.6821 - val_loss: 0.4788 - val_masked_acc: 0.7631 - val_masked_auc: 0.7407\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3543 - masked_acc: 0.7719 - masked_auc: 0.7638 - val_loss: 0.5495 - val_masked_acc: 0.7824 - val_masked_auc: 0.7934\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2827 - masked_acc: 0.7906 - masked_auc: 0.8088 - val_loss: 0.6500 - val_masked_acc: 0.8019 - val_masked_auc: 0.8297\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2418 - masked_acc: 0.8079 - masked_auc: 0.8398 - val_loss: 0.8255 - val_masked_acc: 0.8168 - val_masked_auc: 0.8537\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1938 - masked_acc: 0.8218 - masked_auc: 0.8612 - val_loss: 0.9302 - val_masked_acc: 0.8291 - val_masked_auc: 0.8715\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1714 - masked_acc: 0.8333 - masked_auc: 0.8772 - val_loss: 0.9719 - val_masked_acc: 0.8389 - val_masked_auc: 0.8843\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1623 - masked_acc: 0.8422 - masked_auc: 0.8888 - val_loss: 1.1006 - val_masked_acc: 0.8473 - val_masked_auc: 0.8946\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1420 - masked_acc: 0.8503 - masked_auc: 0.8983 - val_loss: 1.2668 - val_masked_acc: 0.8544 - val_masked_auc: 0.9027\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1393 - masked_acc: 0.8566 - masked_auc: 0.9054 - val_loss: 1.3965 - val_masked_acc: 0.8604 - val_masked_auc: 0.9092\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1263 - masked_acc: 0.8625 - masked_auc: 0.9116 - val_loss: 1.3591 - val_masked_acc: 0.8655 - val_masked_auc: 0.9145\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1138 - masked_acc: 0.8675 - masked_auc: 0.9165 - val_loss: 1.5128 - val_masked_acc: 0.8702 - val_masked_auc: 0.9191\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0924 - masked_acc: 0.8734 - masked_auc: 0.9225\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4137 - masked_acc: 0.8753 - masked_auc: 0.9239\n",
      "Test:  [1.413666844367981, 0.8752940893173218, 0.9239031076431274]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr RNN layers\n",
    "    RNN_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    RNN_sub_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    RNN_ques = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    RNN_shif = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "    RNN_features = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    RNN_output = tf.concat([RNN_chap, RNN_sub_chap, RNN_ques, RNN_shif, RNN_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 5*EMBEDDING_DIM), activation='relu')(RNN_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='RNN_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:07:59.790179Z",
     "iopub.status.busy": "2021-08-12T21:07:59.789509Z",
     "iopub.status.idle": "2021-08-12T21:07:59.799967Z",
     "shell.execute_reply": "2021-08-12T21:07:59.798784Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.876306Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.53112,
     "end_time": "2021-08-12T21:07:59.800224",
     "exception": false,
     "start_time": "2021-08-12T21:07:59.269104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  1.3152567148208618 +/- 0.10861064914707526\n",
      "test avg acc:  0.8733359456062317 +/- 0.003465210818025682\n",
      "test avg auc:  0.923647689819336 +/- 0.002806231926169945\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:08:00.848157Z",
     "iopub.status.busy": "2021-08-12T21:08:00.847144Z",
     "iopub.status.idle": "2021-08-12T21:08:00.853132Z",
     "shell.execute_reply": "2021-08-12T21:08:00.852529Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.886927Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.531593,
     "end_time": "2021-08-12T21:08:00.853274",
     "exception": false,
     "start_time": "2021-08-12T21:08:00.321681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.09898394644260407 +/- 0.00452781191249994\n",
      "train avg acc:  0.8713037729263305 +/- 0.003613687111585131\n",
      "train avg auc:  0.9220280289649964 +/- 0.0029240704122354914\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 567.264004,
   "end_time": "2021-08-12T21:08:04.445848",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T20:58:37.181844",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
