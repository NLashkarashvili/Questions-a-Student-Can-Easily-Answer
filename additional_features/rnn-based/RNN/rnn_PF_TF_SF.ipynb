{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T20:58:25.916925Z",
     "iopub.status.busy": "2021-08-12T20:58:25.915718Z",
     "iopub.status.idle": "2021-08-12T20:58:32.772964Z",
     "shell.execute_reply": "2021-08-12T20:58:32.771302Z",
     "shell.execute_reply.started": "2021-08-06T20:53:41.672006Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.892278,
     "end_time": "2021-08-12T20:58:32.773218",
     "exception": false,
     "start_time": "2021-08-12T20:58:25.880940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import SimpleRNN as RNN\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:05:18.235312Z",
     "iopub.status.busy": "2021-08-12T21:05:18.234593Z",
     "iopub.status.idle": "2021-08-12T21:05:18.238846Z",
     "shell.execute_reply": "2021-08-12T21:05:18.239325Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.012606Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.370313,
     "end_time": "2021-08-12T21:05:18.239529",
     "exception": false,
     "start_time": "2021-08-12T21:05:17.869216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "RNN_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:05:18.983265Z",
     "iopub.status.busy": "2021-08-12T21:05:18.982640Z",
     "iopub.status.idle": "2021-08-12T21:05:18.987819Z",
     "shell.execute_reply": "2021-08-12T21:05:18.988316Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.932106Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.383266,
     "end_time": "2021-08-12T21:05:18.988501",
     "exception": false,
     "start_time": "2021-08-12T21:05:18.605235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 39\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:05:23.892132Z",
     "iopub.status.busy": "2021-08-12T21:05:23.886819Z",
     "iopub.status.idle": "2021-08-12T21:06:31.284006Z",
     "shell.execute_reply": "2021-08-12T21:06:31.283421Z",
     "shell.execute_reply.started": "2021-08-06T21:04:56.750188Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 67.791482,
     "end_time": "2021-08-12T21:06:31.284173",
     "exception": false,
     "start_time": "2021-08-12T21:05:23.492691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 8s 162ms/step - loss: 0.5819 - masked_acc: 0.6346 - masked_auc: 0.5655 - val_loss: 0.4899 - val_masked_acc: 0.7306 - val_masked_auc: 0.6714\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4333 - masked_acc: 0.7402 - masked_auc: 0.7082 - val_loss: 0.5172 - val_masked_acc: 0.7582 - val_masked_auc: 0.7592\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3432 - masked_acc: 0.7677 - masked_auc: 0.7801 - val_loss: 0.5902 - val_masked_acc: 0.7817 - val_masked_auc: 0.8080\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2829 - masked_acc: 0.7896 - masked_auc: 0.8214 - val_loss: 0.7431 - val_masked_acc: 0.8009 - val_masked_auc: 0.8397\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2404 - masked_acc: 0.8069 - masked_auc: 0.8488 - val_loss: 0.9100 - val_masked_acc: 0.8158 - val_masked_auc: 0.8604\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2032 - masked_acc: 0.8206 - masked_auc: 0.8672 - val_loss: 0.9466 - val_masked_acc: 0.8276 - val_masked_auc: 0.8756\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1910 - masked_acc: 0.8315 - masked_auc: 0.8803 - val_loss: 1.1440 - val_masked_acc: 0.8377 - val_masked_auc: 0.8871\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1611 - masked_acc: 0.8410 - masked_auc: 0.8912 - val_loss: 1.2679 - val_masked_acc: 0.8465 - val_masked_auc: 0.8966\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1414 - masked_acc: 0.8492 - masked_auc: 0.8998 - val_loss: 1.3628 - val_masked_acc: 0.8534 - val_masked_auc: 0.9040\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.1338 - masked_acc: 0.8559 - masked_auc: 0.9067 - val_loss: 1.4084 - val_masked_acc: 0.8598 - val_masked_auc: 0.9100\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1233 - masked_acc: 0.8619 - masked_auc: 0.9122 - val_loss: 1.4657 - val_masked_acc: 0.8651 - val_masked_auc: 0.9149\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1038 - masked_acc: 0.8686 - masked_auc: 0.9188\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2336 - masked_acc: 0.8707 - masked_auc: 0.9204\n",
      "Test:  [1.2336392402648926, 0.8706543445587158, 0.9203732013702393]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 135ms/step - loss: 0.5771 - masked_acc: 0.7223 - masked_auc: 0.5581 - val_loss: 0.5230 - val_masked_acc: 0.7427 - val_masked_auc: 0.6532\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4550 - masked_acc: 0.7482 - masked_auc: 0.6901 - val_loss: 0.5062 - val_masked_acc: 0.7620 - val_masked_auc: 0.7460\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3413 - masked_acc: 0.7716 - masked_auc: 0.7697 - val_loss: 0.5448 - val_masked_acc: 0.7832 - val_masked_auc: 0.7996\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2753 - masked_acc: 0.7918 - masked_auc: 0.8143 - val_loss: 0.6646 - val_masked_acc: 0.8021 - val_masked_auc: 0.8344\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2365 - masked_acc: 0.8084 - masked_auc: 0.8443 - val_loss: 0.7921 - val_masked_acc: 0.8172 - val_masked_auc: 0.8578\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1973 - masked_acc: 0.8224 - masked_auc: 0.8655 - val_loss: 0.8945 - val_masked_acc: 0.8297 - val_masked_auc: 0.8749\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1839 - masked_acc: 0.8334 - masked_auc: 0.8801 - val_loss: 1.0953 - val_masked_acc: 0.8392 - val_masked_auc: 0.8875\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1656 - masked_acc: 0.8424 - masked_auc: 0.8916 - val_loss: 1.1615 - val_masked_acc: 0.8470 - val_masked_auc: 0.8966\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.1454 - masked_acc: 0.8499 - masked_auc: 0.8999 - val_loss: 1.2061 - val_masked_acc: 0.8538 - val_masked_auc: 0.9040\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1274 - masked_acc: 0.8564 - masked_auc: 0.9069 - val_loss: 1.3235 - val_masked_acc: 0.8600 - val_masked_auc: 0.9102\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.1099 - masked_acc: 0.8623 - masked_auc: 0.9127 - val_loss: 1.5011 - val_masked_acc: 0.8657 - val_masked_auc: 0.9156\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1043 - masked_acc: 0.8677 - masked_auc: 0.9176 - val_loss: 1.5889 - val_masked_acc: 0.8704 - val_masked_auc: 0.9199\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0851 - masked_acc: 0.8736 - masked_auc: 0.9235\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.6166 - masked_acc: 0.8755 - masked_auc: 0.9248\n",
      "Test:  [1.6166040897369385, 0.8755174875259399, 0.9248144626617432]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 138ms/step - loss: 0.5939 - masked_acc: 0.6576 - masked_auc: 0.5342 - val_loss: 0.5126 - val_masked_acc: 0.7313 - val_masked_auc: 0.6494\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4499 - masked_acc: 0.7399 - masked_auc: 0.6900 - val_loss: 0.5045 - val_masked_acc: 0.7534 - val_masked_auc: 0.7437\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3608 - masked_acc: 0.7624 - masked_auc: 0.7657 - val_loss: 0.5390 - val_masked_acc: 0.7765 - val_masked_auc: 0.7971\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3002 - masked_acc: 0.7835 - masked_auc: 0.8114 - val_loss: 0.6309 - val_masked_acc: 0.7951 - val_masked_auc: 0.8315\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2538 - masked_acc: 0.8009 - masked_auc: 0.8410 - val_loss: 0.8170 - val_masked_acc: 0.8105 - val_masked_auc: 0.8549\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2095 - masked_acc: 0.8155 - masked_auc: 0.8619 - val_loss: 0.8044 - val_masked_acc: 0.8234 - val_masked_auc: 0.8726\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1804 - masked_acc: 0.8277 - masked_auc: 0.8782 - val_loss: 0.9842 - val_masked_acc: 0.8346 - val_masked_auc: 0.8860\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1562 - masked_acc: 0.8382 - masked_auc: 0.8905 - val_loss: 1.1040 - val_masked_acc: 0.8441 - val_masked_auc: 0.8966\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1328 - masked_acc: 0.8471 - masked_auc: 0.9002 - val_loss: 1.0657 - val_masked_acc: 0.8515 - val_masked_auc: 0.9049\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1430 - masked_acc: 0.8539 - masked_auc: 0.9076 - val_loss: 1.3587 - val_masked_acc: 0.8580 - val_masked_auc: 0.9111\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1192 - masked_acc: 0.8603 - masked_auc: 0.9134 - val_loss: 1.2350 - val_masked_acc: 0.8639 - val_masked_auc: 0.9167\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1076 - masked_acc: 0.8659 - masked_auc: 0.9187 - val_loss: 1.4791 - val_masked_acc: 0.8694 - val_masked_auc: 0.9216\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0790 - masked_acc: 0.8729 - masked_auc: 0.9251\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.3647 - masked_acc: 0.8753 - masked_auc: 0.9271\n",
      "Test:  [1.3647067546844482, 0.8753002882003784, 0.9271050691604614]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 129ms/step - loss: 0.5854 - masked_acc: 0.6890 - masked_auc: 0.5336 - val_loss: 0.4915 - val_masked_acc: 0.7408 - val_masked_auc: 0.6561\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4298 - masked_acc: 0.7504 - masked_auc: 0.6988 - val_loss: 0.5017 - val_masked_acc: 0.7671 - val_masked_auc: 0.7579\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3266 - masked_acc: 0.7768 - masked_auc: 0.7803 - val_loss: 0.5732 - val_masked_acc: 0.7891 - val_masked_auc: 0.8106\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2862 - masked_acc: 0.7961 - masked_auc: 0.8236 - val_loss: 0.7313 - val_masked_acc: 0.8072 - val_masked_auc: 0.8431\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2333 - masked_acc: 0.8128 - masked_auc: 0.8519 - val_loss: 0.8804 - val_masked_acc: 0.8211 - val_masked_auc: 0.8646\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1948 - masked_acc: 0.8257 - masked_auc: 0.8714 - val_loss: 0.9725 - val_masked_acc: 0.8332 - val_masked_auc: 0.8806\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1739 - masked_acc: 0.8371 - masked_auc: 0.8857 - val_loss: 1.1718 - val_masked_acc: 0.8431 - val_masked_auc: 0.8924\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1592 - masked_acc: 0.8462 - masked_auc: 0.8960 - val_loss: 1.1091 - val_masked_acc: 0.8506 - val_masked_auc: 0.9011\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1485 - masked_acc: 0.8532 - masked_auc: 0.9041 - val_loss: 1.2380 - val_masked_acc: 0.8572 - val_masked_auc: 0.9083\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1254 - masked_acc: 0.8597 - masked_auc: 0.9111 - val_loss: 1.4380 - val_masked_acc: 0.8632 - val_masked_auc: 0.9142\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1230 - masked_acc: 0.8651 - masked_auc: 0.9163 - val_loss: 1.5607 - val_masked_acc: 0.8683 - val_masked_auc: 0.9189\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1093 - masked_acc: 0.8714 - masked_auc: 0.9224\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4437 - masked_acc: 0.8734 - masked_auc: 0.9236\n",
      "Test:  [1.4437177181243896, 0.8733537793159485, 0.9235920906066895]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 8s 127ms/step - loss: 0.5833 - masked_acc: 0.7340 - masked_auc: 0.5430 - val_loss: 0.5340 - val_masked_acc: 0.7452 - val_masked_auc: 0.6318\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4474 - masked_acc: 0.7521 - masked_auc: 0.6737 - val_loss: 0.5294 - val_masked_acc: 0.7605 - val_masked_auc: 0.7357\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3569 - masked_acc: 0.7688 - masked_auc: 0.7599 - val_loss: 0.5755 - val_masked_acc: 0.7823 - val_masked_auc: 0.7928\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2941 - masked_acc: 0.7895 - masked_auc: 0.8079 - val_loss: 0.6527 - val_masked_acc: 0.8007 - val_masked_auc: 0.8301\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2575 - masked_acc: 0.8060 - masked_auc: 0.8395 - val_loss: 0.8517 - val_masked_acc: 0.8159 - val_masked_auc: 0.8542\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1992 - masked_acc: 0.8207 - masked_auc: 0.8615 - val_loss: 0.8654 - val_masked_acc: 0.8284 - val_masked_auc: 0.8727\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1810 - masked_acc: 0.8323 - masked_auc: 0.8781 - val_loss: 1.0158 - val_masked_acc: 0.8383 - val_masked_auc: 0.8859\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1743 - masked_acc: 0.8413 - masked_auc: 0.8898 - val_loss: 1.0815 - val_masked_acc: 0.8463 - val_masked_auc: 0.8955\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1578 - masked_acc: 0.8490 - masked_auc: 0.8986 - val_loss: 1.0857 - val_masked_acc: 0.8530 - val_masked_auc: 0.9030\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1530 - masked_acc: 0.8550 - masked_auc: 0.9056 - val_loss: 1.3232 - val_masked_acc: 0.8587 - val_masked_auc: 0.9093\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1243 - masked_acc: 0.8607 - masked_auc: 0.9117 - val_loss: 1.4131 - val_masked_acc: 0.8640 - val_masked_auc: 0.9147\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.1159 - masked_acc: 0.8659 - masked_auc: 0.9167 - val_loss: 1.6045 - val_masked_acc: 0.8689 - val_masked_auc: 0.9194\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0960 - masked_acc: 0.8720 - masked_auc: 0.9227\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4969 - masked_acc: 0.8739 - masked_auc: 0.9239\n",
      "Test:  [1.4968602657318115, 0.8738716840744019, 0.923891544342041]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr RNN layers\n",
    "    RNN_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    RNN_sub_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    RNN_ques = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    RNN_shif = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "    RNN_features = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    RNN_output = tf.concat([RNN_chap, RNN_sub_chap, RNN_ques, RNN_shif, RNN_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 5*EMBEDDING_DIM), activation='relu')(RNN_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='RNN_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:32.404953Z",
     "iopub.status.busy": "2021-08-12T21:06:32.404164Z",
     "iopub.status.idle": "2021-08-12T21:06:32.408389Z",
     "shell.execute_reply": "2021-08-12T21:06:32.408899Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.876306Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.561311,
     "end_time": "2021-08-12T21:06:32.409149",
     "exception": false,
     "start_time": "2021-08-12T21:06:31.847838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  1.431105613708496 +/- 0.12829201157518996\n",
      "test avg acc:  0.8737395167350769 +/- 0.0017482412087554877\n",
      "test avg auc:  0.9239552736282348 +/- 0.002173781161050703\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:33.463254Z",
     "iopub.status.busy": "2021-08-12T21:06:33.462585Z",
     "iopub.status.idle": "2021-08-12T21:06:33.467190Z",
     "shell.execute_reply": "2021-08-12T21:06:33.466677Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.886927Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.531002,
     "end_time": "2021-08-12T21:06:33.467356",
     "exception": false,
     "start_time": "2021-08-12T21:06:32.936354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.09464169144630433 +/- 0.01124901822643321\n",
      "train avg acc:  0.8717126488685608 +/- 0.00174178772508192\n",
      "train avg auc:  0.9224883198738099 +/- 0.0020936984387261975\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 499.197178,
   "end_time": "2021-08-12T21:06:36.695248",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T20:58:17.498070",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
