{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T20:57:46.085088Z",
     "iopub.status.busy": "2021-08-12T20:57:46.084227Z",
     "iopub.status.idle": "2021-08-12T20:57:52.471798Z",
     "shell.execute_reply": "2021-08-12T20:57:52.470883Z",
     "shell.execute_reply.started": "2021-08-06T20:53:41.672006Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.435722,
     "end_time": "2021-08-12T20:57:52.472001",
     "exception": false,
     "start_time": "2021-08-12T20:57:46.036279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import SimpleRNN as RNN\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:05:42.036413Z",
     "iopub.status.busy": "2021-08-12T21:05:42.035234Z",
     "iopub.status.idle": "2021-08-12T21:05:42.038024Z",
     "shell.execute_reply": "2021-08-12T21:05:42.037412Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.012606Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.37324,
     "end_time": "2021-08-12T21:05:42.038160",
     "exception": false,
     "start_time": "2021-08-12T21:05:41.664920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "RNN_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:05:42.779482Z",
     "iopub.status.busy": "2021-08-12T21:05:42.778843Z",
     "iopub.status.idle": "2021-08-12T21:05:42.781338Z",
     "shell.execute_reply": "2021-08-12T21:05:42.780727Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.932106Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.370632,
     "end_time": "2021-08-12T21:05:42.781493",
     "exception": false,
     "start_time": "2021-08-12T21:05:42.410861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 37\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:05:47.396918Z",
     "iopub.status.busy": "2021-08-12T21:05:47.396139Z",
     "iopub.status.idle": "2021-08-12T21:06:40.953253Z",
     "shell.execute_reply": "2021-08-12T21:06:40.952732Z",
     "shell.execute_reply.started": "2021-08-06T21:04:56.750188Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 53.922204,
     "end_time": "2021-08-12T21:06:40.953424",
     "exception": false,
     "start_time": "2021-08-12T21:05:47.031220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 6s 164ms/step - loss: 0.6122 - masked_acc: 0.5934 - masked_auc: 0.5048 - val_loss: 0.5565 - val_masked_acc: 0.7138 - val_masked_auc: 0.5605\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4835 - masked_acc: 0.7221 - masked_auc: 0.6097 - val_loss: 0.5387 - val_masked_acc: 0.7356 - val_masked_auc: 0.6868\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3944 - masked_acc: 0.7443 - masked_auc: 0.7130 - val_loss: 0.6413 - val_masked_acc: 0.7588 - val_masked_auc: 0.7532\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3251 - masked_acc: 0.7666 - masked_auc: 0.7710 - val_loss: 0.6908 - val_masked_acc: 0.7791 - val_masked_auc: 0.7973\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2567 - masked_acc: 0.7861 - masked_auc: 0.8102 - val_loss: 0.8702 - val_masked_acc: 0.7960 - val_masked_auc: 0.8273\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2355 - masked_acc: 0.8011 - masked_auc: 0.8359 - val_loss: 1.0046 - val_masked_acc: 0.8094 - val_masked_auc: 0.8485\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2069 - masked_acc: 0.8137 - masked_auc: 0.8551 - val_loss: 1.0803 - val_masked_acc: 0.8206 - val_masked_auc: 0.8648\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1800 - masked_acc: 0.8244 - masked_auc: 0.8700 - val_loss: 1.1740 - val_masked_acc: 0.8299 - val_masked_auc: 0.8768\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1627 - masked_acc: 0.8330 - masked_auc: 0.8809 - val_loss: 1.3446 - val_masked_acc: 0.8376 - val_masked_auc: 0.8863\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1469 - masked_acc: 0.8404 - masked_auc: 0.8899 - val_loss: 1.2843 - val_masked_acc: 0.8445 - val_masked_auc: 0.8942\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1435 - masked_acc: 0.8469 - masked_auc: 0.8971 - val_loss: 1.5858 - val_masked_acc: 0.8504 - val_masked_auc: 0.9003\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1231 - masked_acc: 0.8525 - masked_auc: 0.9028 - val_loss: 1.7144 - val_masked_acc: 0.8558 - val_masked_auc: 0.9057\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0997 - masked_acc: 0.8594 - masked_auc: 0.9099\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3334 - masked_acc: 0.8615 - masked_auc: 0.9118\n",
      "Test:  [1.3334044218063354, 0.8615292906761169, 0.9117895364761353]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 5s 108ms/step - loss: 0.6060 - masked_acc: 0.6666 - masked_auc: 0.5074 - val_loss: 0.5302 - val_masked_acc: 0.7279 - val_masked_auc: 0.5867\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4783 - masked_acc: 0.7301 - masked_auc: 0.6348 - val_loss: 0.5362 - val_masked_acc: 0.7385 - val_masked_auc: 0.7022\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3803 - masked_acc: 0.7481 - masked_auc: 0.7295 - val_loss: 0.5921 - val_masked_acc: 0.7608 - val_masked_auc: 0.7651\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3194 - masked_acc: 0.7679 - masked_auc: 0.7820 - val_loss: 0.6706 - val_masked_acc: 0.7786 - val_masked_auc: 0.8043\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2741 - masked_acc: 0.7847 - masked_auc: 0.8151 - val_loss: 0.9110 - val_masked_acc: 0.7949 - val_masked_auc: 0.8317\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2427 - masked_acc: 0.7998 - masked_auc: 0.8395 - val_loss: 0.9132 - val_masked_acc: 0.8081 - val_masked_auc: 0.8515\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2139 - masked_acc: 0.8122 - masked_auc: 0.8575 - val_loss: 1.0064 - val_masked_acc: 0.8188 - val_masked_auc: 0.8662\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1845 - masked_acc: 0.8224 - masked_auc: 0.8711 - val_loss: 1.1560 - val_masked_acc: 0.8278 - val_masked_auc: 0.8776\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1770 - masked_acc: 0.8308 - masked_auc: 0.8814 - val_loss: 1.2142 - val_masked_acc: 0.8354 - val_masked_auc: 0.8864\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1640 - masked_acc: 0.8378 - masked_auc: 0.8895 - val_loss: 1.3853 - val_masked_acc: 0.8420 - val_masked_auc: 0.8936\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1438 - masked_acc: 0.8443 - masked_auc: 0.8964 - val_loss: 1.3947 - val_masked_acc: 0.8479 - val_masked_auc: 0.8998\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1243 - masked_acc: 0.8518 - masked_auc: 0.9043\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2968 - masked_acc: 0.8542 - masked_auc: 0.9062\n",
      "Test:  [1.2968038320541382, 0.8541862964630127, 0.9061577320098877]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 6s 165ms/step - loss: 0.5990 - masked_acc: 0.5917 - masked_auc: 0.5378 - val_loss: 0.5109 - val_masked_acc: 0.7197 - val_masked_auc: 0.6198\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4825 - masked_acc: 0.7231 - masked_auc: 0.6597 - val_loss: 0.5127 - val_masked_acc: 0.7361 - val_masked_auc: 0.7156\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3739 - masked_acc: 0.7471 - masked_auc: 0.7414 - val_loss: 0.5861 - val_masked_acc: 0.7612 - val_masked_auc: 0.7732\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3305 - masked_acc: 0.7683 - masked_auc: 0.7883 - val_loss: 0.7272 - val_masked_acc: 0.7816 - val_masked_auc: 0.8113\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.2557 - masked_acc: 0.7881 - masked_auc: 0.8223 - val_loss: 0.7832 - val_masked_acc: 0.7973 - val_masked_auc: 0.8379\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2400 - masked_acc: 0.8022 - masked_auc: 0.8457 - val_loss: 0.9146 - val_masked_acc: 0.8102 - val_masked_auc: 0.8564\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2013 - masked_acc: 0.8144 - masked_auc: 0.8621 - val_loss: 1.0800 - val_masked_acc: 0.8211 - val_masked_auc: 0.8707\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1837 - masked_acc: 0.8246 - masked_auc: 0.8751 - val_loss: 1.1337 - val_masked_acc: 0.8302 - val_masked_auc: 0.8816\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1676 - masked_acc: 0.8332 - masked_auc: 0.8855 - val_loss: 1.3229 - val_masked_acc: 0.8378 - val_masked_auc: 0.8905\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1495 - masked_acc: 0.8405 - masked_auc: 0.8934 - val_loss: 1.3959 - val_masked_acc: 0.8444 - val_masked_auc: 0.8975\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1379 - masked_acc: 0.8468 - masked_auc: 0.9000 - val_loss: 1.3508 - val_masked_acc: 0.8503 - val_masked_auc: 0.9035\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1214 - masked_acc: 0.8541 - masked_auc: 0.9078\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4395 - masked_acc: 0.8563 - masked_auc: 0.9095\n",
      "Test:  [1.4394835233688354, 0.8563095927238464, 0.9095351696014404]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 5s 108ms/step - loss: 0.5874 - masked_acc: 0.6469 - masked_auc: 0.5461 - val_loss: 0.5480 - val_masked_acc: 0.7267 - val_masked_auc: 0.6286\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4642 - masked_acc: 0.7348 - masked_auc: 0.6693 - val_loss: 0.5437 - val_masked_acc: 0.7493 - val_masked_auc: 0.7232\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3815 - masked_acc: 0.7574 - masked_auc: 0.7452 - val_loss: 0.5685 - val_masked_acc: 0.7703 - val_masked_auc: 0.7782\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3135 - masked_acc: 0.7780 - masked_auc: 0.7930 - val_loss: 0.7848 - val_masked_acc: 0.7891 - val_masked_auc: 0.8126\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2592 - masked_acc: 0.7949 - masked_auc: 0.8230 - val_loss: 0.9409 - val_masked_acc: 0.8043 - val_masked_auc: 0.8379\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2208 - masked_acc: 0.8091 - masked_auc: 0.8454 - val_loss: 0.9842 - val_masked_acc: 0.8169 - val_masked_auc: 0.8566\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1924 - masked_acc: 0.8211 - masked_auc: 0.8626 - val_loss: 1.1984 - val_masked_acc: 0.8277 - val_masked_auc: 0.8710\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1684 - masked_acc: 0.8312 - masked_auc: 0.8757 - val_loss: 1.3129 - val_masked_acc: 0.8367 - val_masked_auc: 0.8819\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1538 - masked_acc: 0.8398 - masked_auc: 0.8857 - val_loss: 1.3111 - val_masked_acc: 0.8442 - val_masked_auc: 0.8903\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1500 - masked_acc: 0.8467 - masked_auc: 0.8935 - val_loss: 1.3355 - val_masked_acc: 0.8507 - val_masked_auc: 0.8974\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1416 - masked_acc: 0.8529 - masked_auc: 0.9000 - val_loss: 1.5913 - val_masked_acc: 0.8567 - val_masked_auc: 0.9036\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1197 - masked_acc: 0.8587 - masked_auc: 0.9058 - val_loss: 1.7662 - val_masked_acc: 0.8619 - val_masked_auc: 0.9086\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1039 - masked_acc: 0.8652 - masked_auc: 0.9125\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4903 - masked_acc: 0.8673 - masked_auc: 0.9141\n",
      "Test:  [1.4902642965316772, 0.867316722869873, 0.9141080379486084]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 5s 113ms/step - loss: 0.6001 - masked_acc: 0.6223 - masked_auc: 0.5244 - val_loss: 0.5148 - val_masked_acc: 0.7227 - val_masked_auc: 0.6175\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.4505 - masked_acc: 0.7367 - masked_auc: 0.6644 - val_loss: 0.5053 - val_masked_acc: 0.7521 - val_masked_auc: 0.7249\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.3711 - masked_acc: 0.7611 - masked_auc: 0.7482 - val_loss: 0.6007 - val_masked_acc: 0.7758 - val_masked_auc: 0.7834\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2977 - masked_acc: 0.7836 - masked_auc: 0.7979 - val_loss: 0.7415 - val_masked_acc: 0.7950 - val_masked_auc: 0.8196\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.2514 - masked_acc: 0.8007 - masked_auc: 0.8297 - val_loss: 0.8485 - val_masked_acc: 0.8100 - val_masked_auc: 0.8444\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2145 - masked_acc: 0.8149 - masked_auc: 0.8517 - val_loss: 0.9038 - val_masked_acc: 0.8223 - val_masked_auc: 0.8624\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.2062 - masked_acc: 0.8258 - masked_auc: 0.8675 - val_loss: 0.9929 - val_masked_acc: 0.8318 - val_masked_auc: 0.8751\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1936 - masked_acc: 0.8347 - masked_auc: 0.8791 - val_loss: 1.1224 - val_masked_acc: 0.8397 - val_masked_auc: 0.8849\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1619 - masked_acc: 0.8425 - masked_auc: 0.8884 - val_loss: 1.2832 - val_masked_acc: 0.8468 - val_masked_auc: 0.8934\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 0.1498 - masked_acc: 0.8492 - masked_auc: 0.8963 - val_loss: 1.3595 - val_masked_acc: 0.8529 - val_masked_auc: 0.9003\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 26ms/step - loss: 0.1440 - masked_acc: 0.8549 - masked_auc: 0.9027 - val_loss: 1.4044 - val_masked_acc: 0.8579 - val_masked_auc: 0.9057\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.1305 - masked_acc: 0.8597 - masked_auc: 0.9078 - val_loss: 1.4630 - val_masked_acc: 0.8624 - val_masked_auc: 0.9104\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1091 - masked_acc: 0.8656 - masked_auc: 0.9140\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2723 - masked_acc: 0.8676 - masked_auc: 0.9155\n",
      "Test:  [1.2722690105438232, 0.8675636649131775, 0.9154717922210693]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr RNN layers\n",
    "    RNN_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    RNN_sub_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    RNN_ques = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    RNN_features = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    RNN_output = tf.concat([RNN_chap, RNN_sub_chap, RNN_ques, RNN_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(RNN_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='RNN_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:41.919071Z",
     "iopub.status.busy": "2021-08-12T21:06:41.918044Z",
     "iopub.status.idle": "2021-08-12T21:06:41.928124Z",
     "shell.execute_reply": "2021-08-12T21:06:41.927639Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.876306Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.493786,
     "end_time": "2021-08-12T21:06:41.928271",
     "exception": false,
     "start_time": "2021-08-12T21:06:41.434485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  1.3664450168609619 +/- 0.0842336431122188\n",
      "test avg acc:  0.8613811135292053 +/- 0.005494780654812523\n",
      "test avg auc:  0.9114124536514282 +/- 0.003317314899652497\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:42.906736Z",
     "iopub.status.busy": "2021-08-12T21:06:42.905522Z",
     "iopub.status.idle": "2021-08-12T21:06:42.911180Z",
     "shell.execute_reply": "2021-08-12T21:06:42.911713Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.886927Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.497885,
     "end_time": "2021-08-12T21:06:42.911910",
     "exception": false,
     "start_time": "2021-08-12T21:06:42.414025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.11170771121978759 +/- 0.009634427386933915\n",
      "train avg acc:  0.8592277288436889 +/- 0.0056279015669506854\n",
      "train avg auc:  0.9096763610839844 +/- 0.003435887383291346\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 548.116889,
   "end_time": "2021-08-12T21:06:46.153245",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T20:57:38.036356",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
