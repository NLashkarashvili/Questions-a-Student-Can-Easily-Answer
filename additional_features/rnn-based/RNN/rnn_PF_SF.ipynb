{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T20:57:59.958402Z",
     "iopub.status.busy": "2021-08-12T20:57:59.957773Z",
     "iopub.status.idle": "2021-08-12T20:58:06.084279Z",
     "shell.execute_reply": "2021-08-12T20:58:06.083348Z",
     "shell.execute_reply.started": "2021-08-06T20:53:41.672006Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.17014,
     "end_time": "2021-08-12T20:58:06.084485",
     "exception": false,
     "start_time": "2021-08-12T20:57:59.914345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import SimpleRNN as RNN\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:04:52.518807Z",
     "iopub.status.busy": "2021-08-12T21:04:52.518009Z",
     "iopub.status.idle": "2021-08-12T21:04:52.520783Z",
     "shell.execute_reply": "2021-08-12T21:04:52.521259Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.012606Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.372698,
     "end_time": "2021-08-12T21:04:52.521448",
     "exception": false,
     "start_time": "2021-08-12T21:04:52.148750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "RNN_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:04:53.262180Z",
     "iopub.status.busy": "2021-08-12T21:04:53.261067Z",
     "iopub.status.idle": "2021-08-12T21:04:53.265366Z",
     "shell.execute_reply": "2021-08-12T21:04:53.265843Z",
     "shell.execute_reply.started": "2021-08-06T21:04:51.932106Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.374538,
     "end_time": "2021-08-12T21:04:53.266038",
     "exception": false,
     "start_time": "2021-08-12T21:04:52.891500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 37\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:04:58.318996Z",
     "iopub.status.busy": "2021-08-12T21:04:58.313342Z",
     "iopub.status.idle": "2021-08-12T21:06:02.382790Z",
     "shell.execute_reply": "2021-08-12T21:06:02.383470Z",
     "shell.execute_reply.started": "2021-08-06T21:04:56.750188Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 64.445246,
     "end_time": "2021-08-12T21:06:02.383726",
     "exception": false,
     "start_time": "2021-08-12T21:04:57.938480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 8s 169ms/step - loss: 0.5932 - masked_acc: 0.5996 - masked_auc: 0.5277 - val_loss: 0.4871 - val_masked_acc: 0.7223 - val_masked_auc: 0.6633\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4385 - masked_acc: 0.7356 - masked_auc: 0.7051 - val_loss: 0.4998 - val_masked_acc: 0.7573 - val_masked_auc: 0.7585\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3421 - masked_acc: 0.7670 - masked_auc: 0.7804 - val_loss: 0.5965 - val_masked_acc: 0.7808 - val_masked_auc: 0.8098\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2825 - masked_acc: 0.7884 - masked_auc: 0.8225 - val_loss: 0.7421 - val_masked_acc: 0.8006 - val_masked_auc: 0.8417\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2386 - masked_acc: 0.8065 - masked_auc: 0.8508 - val_loss: 0.8488 - val_masked_acc: 0.8151 - val_masked_auc: 0.8628\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2055 - masked_acc: 0.8197 - masked_auc: 0.8691 - val_loss: 1.0422 - val_masked_acc: 0.8274 - val_masked_auc: 0.8781\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.1754 - masked_acc: 0.8312 - masked_auc: 0.8831 - val_loss: 1.0533 - val_masked_acc: 0.8370 - val_masked_auc: 0.8898\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1649 - masked_acc: 0.8401 - masked_auc: 0.8937 - val_loss: 1.0974 - val_masked_acc: 0.8454 - val_masked_auc: 0.8990\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1635 - masked_acc: 0.8480 - masked_auc: 0.9020 - val_loss: 1.1471 - val_masked_acc: 0.8523 - val_masked_auc: 0.9061\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1319 - masked_acc: 0.8548 - masked_auc: 0.9086 - val_loss: 1.3150 - val_masked_acc: 0.8584 - val_masked_auc: 0.9119\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1323 - masked_acc: 0.8603 - masked_auc: 0.9140 - val_loss: 1.3100 - val_masked_acc: 0.8636 - val_masked_auc: 0.9167\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1147 - masked_acc: 0.8670 - masked_auc: 0.9203\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1170 - masked_acc: 0.8691 - masked_auc: 0.9219\n",
      "Test:  [1.1170108318328857, 0.8690647482872009, 0.921941876411438]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 130ms/step - loss: 0.5810 - masked_acc: 0.7051 - masked_auc: 0.5313 - val_loss: 0.5446 - val_masked_acc: 0.7384 - val_masked_auc: 0.6598\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4507 - masked_acc: 0.7445 - masked_auc: 0.6988 - val_loss: 0.5296 - val_masked_acc: 0.7603 - val_masked_auc: 0.7511\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3392 - masked_acc: 0.7692 - masked_auc: 0.7733 - val_loss: 0.5872 - val_masked_acc: 0.7836 - val_masked_auc: 0.8060\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2697 - masked_acc: 0.7916 - masked_auc: 0.8207 - val_loss: 0.7165 - val_masked_acc: 0.8025 - val_masked_auc: 0.8396\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2349 - masked_acc: 0.8084 - masked_auc: 0.8490 - val_loss: 0.7907 - val_masked_acc: 0.8168 - val_masked_auc: 0.8619\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2165 - masked_acc: 0.8216 - masked_auc: 0.8683 - val_loss: 1.0402 - val_masked_acc: 0.8283 - val_masked_auc: 0.8761\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1757 - masked_acc: 0.8323 - masked_auc: 0.8812 - val_loss: 1.0475 - val_masked_acc: 0.8376 - val_masked_auc: 0.8876\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1612 - masked_acc: 0.8410 - masked_auc: 0.8917 - val_loss: 1.3491 - val_masked_acc: 0.8460 - val_masked_auc: 0.8967\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1440 - masked_acc: 0.8489 - masked_auc: 0.9000 - val_loss: 1.3654 - val_masked_acc: 0.8531 - val_masked_auc: 0.9038\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1375 - masked_acc: 0.8554 - masked_auc: 0.9065 - val_loss: 1.5141 - val_masked_acc: 0.8591 - val_masked_auc: 0.9097\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1191 - masked_acc: 0.8612 - masked_auc: 0.9120 - val_loss: 1.5171 - val_masked_acc: 0.8644 - val_masked_auc: 0.9148\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1135 - masked_acc: 0.8662 - masked_auc: 0.9168 - val_loss: 1.8393 - val_masked_acc: 0.8690 - val_masked_auc: 0.9190\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1013 - masked_acc: 0.8721 - masked_auc: 0.9223\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3714 - masked_acc: 0.8738 - masked_auc: 0.9234\n",
      "Test:  [1.3714447021484375, 0.8737784028053284, 0.9234279990196228]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 135ms/step - loss: 0.6103 - masked_acc: 0.5557 - masked_auc: 0.5425 - val_loss: 0.4605 - val_masked_acc: 0.7095 - val_masked_auc: 0.6384\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4628 - masked_acc: 0.7211 - masked_auc: 0.6770 - val_loss: 0.4649 - val_masked_acc: 0.7449 - val_masked_auc: 0.7387\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3525 - masked_acc: 0.7556 - masked_auc: 0.7632 - val_loss: 0.5428 - val_masked_acc: 0.7730 - val_masked_auc: 0.7984\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2845 - masked_acc: 0.7816 - masked_auc: 0.8131 - val_loss: 0.6829 - val_masked_acc: 0.7945 - val_masked_auc: 0.8344\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2388 - masked_acc: 0.8009 - masked_auc: 0.8447 - val_loss: 0.7486 - val_masked_acc: 0.8115 - val_masked_auc: 0.8591\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2091 - masked_acc: 0.8167 - masked_auc: 0.8661 - val_loss: 0.9044 - val_masked_acc: 0.8244 - val_masked_auc: 0.8757\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1909 - masked_acc: 0.8284 - masked_auc: 0.8806 - val_loss: 1.0513 - val_masked_acc: 0.8349 - val_masked_auc: 0.8878\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1577 - masked_acc: 0.8384 - masked_auc: 0.8921 - val_loss: 1.0894 - val_masked_acc: 0.8436 - val_masked_auc: 0.8974\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1560 - masked_acc: 0.8464 - masked_auc: 0.9007 - val_loss: 1.1671 - val_masked_acc: 0.8509 - val_masked_auc: 0.9052\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1395 - masked_acc: 0.8533 - masked_auc: 0.9078 - val_loss: 1.3174 - val_masked_acc: 0.8571 - val_masked_auc: 0.9114\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1214 - masked_acc: 0.8592 - masked_auc: 0.9137 - val_loss: 1.5228 - val_masked_acc: 0.8627 - val_masked_auc: 0.9167\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1064 - masked_acc: 0.8662 - masked_auc: 0.9205\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4420 - masked_acc: 0.8684 - masked_auc: 0.9219\n",
      "Test:  [1.4420074224472046, 0.8683600425720215, 0.9218959808349609]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 128ms/step - loss: 0.5997 - masked_acc: 0.5663 - masked_auc: 0.5153 - val_loss: 0.5160 - val_masked_acc: 0.7164 - val_masked_auc: 0.6461\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4434 - masked_acc: 0.7303 - masked_auc: 0.6859 - val_loss: 0.5110 - val_masked_acc: 0.7508 - val_masked_auc: 0.7454\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3500 - masked_acc: 0.7609 - masked_auc: 0.7680 - val_loss: 0.5697 - val_masked_acc: 0.7743 - val_masked_auc: 0.7983\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2948 - masked_acc: 0.7821 - masked_auc: 0.8113 - val_loss: 0.7512 - val_masked_acc: 0.7937 - val_masked_auc: 0.8304\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2467 - masked_acc: 0.7998 - masked_auc: 0.8401 - val_loss: 0.8162 - val_masked_acc: 0.8093 - val_masked_auc: 0.8537\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2116 - masked_acc: 0.8144 - masked_auc: 0.8610 - val_loss: 1.0154 - val_masked_acc: 0.8219 - val_masked_auc: 0.8703\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1880 - masked_acc: 0.8258 - masked_auc: 0.8754 - val_loss: 1.2189 - val_masked_acc: 0.8323 - val_masked_auc: 0.8828\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1689 - masked_acc: 0.8357 - masked_auc: 0.8871 - val_loss: 1.2185 - val_masked_acc: 0.8413 - val_masked_auc: 0.8929\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1491 - masked_acc: 0.8444 - masked_auc: 0.8965 - val_loss: 1.3314 - val_masked_acc: 0.8490 - val_masked_auc: 0.9009\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1421 - masked_acc: 0.8514 - masked_auc: 0.9037 - val_loss: 1.5626 - val_masked_acc: 0.8557 - val_masked_auc: 0.9073\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.1248 - masked_acc: 0.8580 - masked_auc: 0.9097 - val_loss: 1.6509 - val_masked_acc: 0.8612 - val_masked_auc: 0.9124\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1081 - masked_acc: 0.8634 - masked_auc: 0.9146 - val_loss: 1.8393 - val_masked_acc: 0.8664 - val_masked_auc: 0.9169\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0992 - masked_acc: 0.8698 - masked_auc: 0.9204\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4259 - masked_acc: 0.8718 - masked_auc: 0.9218\n",
      "Test:  [1.4259284734725952, 0.8717698454856873, 0.9217554330825806]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 7s 122ms/step - loss: 0.6105 - masked_acc: 0.5556 - masked_auc: 0.5212 - val_loss: 0.5172 - val_masked_acc: 0.7185 - val_masked_auc: 0.6249\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4521 - masked_acc: 0.7329 - masked_auc: 0.6653 - val_loss: 0.5236 - val_masked_acc: 0.7526 - val_masked_auc: 0.7303\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3539 - masked_acc: 0.7624 - masked_auc: 0.7556 - val_loss: 0.5503 - val_masked_acc: 0.7783 - val_masked_auc: 0.7913\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2786 - masked_acc: 0.7866 - masked_auc: 0.8072 - val_loss: 0.6458 - val_masked_acc: 0.7993 - val_masked_auc: 0.8304\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2371 - masked_acc: 0.8055 - masked_auc: 0.8408 - val_loss: 0.9078 - val_masked_acc: 0.8147 - val_masked_auc: 0.8544\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.1997 - masked_acc: 0.8196 - masked_auc: 0.8617 - val_loss: 0.8868 - val_masked_acc: 0.8274 - val_masked_auc: 0.8716\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1600 - masked_acc: 0.8317 - masked_auc: 0.8774 - val_loss: 1.0339 - val_masked_acc: 0.8378 - val_masked_auc: 0.8852\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.1597 - masked_acc: 0.8411 - masked_auc: 0.8896 - val_loss: 1.1907 - val_masked_acc: 0.8466 - val_masked_auc: 0.8955\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1558 - masked_acc: 0.8492 - masked_auc: 0.8986 - val_loss: 1.2795 - val_masked_acc: 0.8534 - val_masked_auc: 0.9028\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.1409 - masked_acc: 0.8557 - masked_auc: 0.9055 - val_loss: 1.3470 - val_masked_acc: 0.8594 - val_masked_auc: 0.9087\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.1291 - masked_acc: 0.8615 - masked_auc: 0.9110 - val_loss: 1.3977 - val_masked_acc: 0.8648 - val_masked_auc: 0.9141\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1093 - masked_acc: 0.8683 - masked_auc: 0.9179\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4314 - masked_acc: 0.8703 - masked_auc: 0.9192\n",
      "Test:  [1.4313527345657349, 0.8702919483184814, 0.919187068939209]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr RNN layers\n",
    "    RNN_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    RNN_sub_chap = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    RNN_ques = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    RNN_shif = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "    RNN_features = RNN(RNN_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    RNN_output = tf.concat([RNN_chap, RNN_sub_chap, RNN_ques, RNN_shif, RNN_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 5*EMBEDDING_DIM), activation='relu')(RNN_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='RNN_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:03.365941Z",
     "iopub.status.busy": "2021-08-12T21:06:03.365239Z",
     "iopub.status.idle": "2021-08-12T21:06:03.371030Z",
     "shell.execute_reply": "2021-08-12T21:06:03.371727Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.876306Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.500141,
     "end_time": "2021-08-12T21:06:03.371954",
     "exception": false,
     "start_time": "2021-08-12T21:06:02.871813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  1.3575488328933716 +/- 0.1227254412367368\n",
      "test avg acc:  0.8706529974937439 +/- 0.0019455612105961327\n",
      "test avg auc:  0.9216416716575623 +/- 0.0013699472736696432\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:06:04.362700Z",
     "iopub.status.busy": "2021-08-12T21:06:04.361711Z",
     "iopub.status.idle": "2021-08-12T21:06:04.367082Z",
     "shell.execute_reply": "2021-08-12T21:06:04.366580Z",
     "shell.execute_reply.started": "2021-08-06T21:22:41.886927Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.506132,
     "end_time": "2021-08-12T21:06:04.367262",
     "exception": false,
     "start_time": "2021-08-12T21:06:03.861130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.10621164590120316 +/- 0.005553249719130647\n",
      "train avg acc:  0.8686715126037597 +/- 0.0021046879726309125\n",
      "train avg auc:  0.9202641010284424 +/- 0.0013981002427241281\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 495.085782,
   "end_time": "2021-08-12T21:06:07.481595",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T20:57:52.395813",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
