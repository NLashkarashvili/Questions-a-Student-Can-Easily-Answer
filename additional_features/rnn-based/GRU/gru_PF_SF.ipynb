{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:11:23.309318Z",
     "iopub.status.busy": "2021-08-12T21:11:23.308656Z",
     "iopub.status.idle": "2021-08-12T21:11:30.429865Z",
     "shell.execute_reply": "2021-08-12T21:11:30.428654Z",
     "shell.execute_reply.started": "2021-07-31T12:06:59.141322Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.152497,
     "end_time": "2021-08-12T21:11:30.430037",
     "exception": false,
     "start_time": "2021-08-12T21:11:23.277540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:17:56.814207Z",
     "iopub.status.busy": "2021-08-12T21:17:56.813545Z",
     "iopub.status.idle": "2021-08-12T21:17:56.815413Z",
     "shell.execute_reply": "2021-08-12T21:17:56.815852Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.831612Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.275293,
     "end_time": "2021-08-12T21:17:56.816029",
     "exception": false,
     "start_time": "2021-08-12T21:17:56.540736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "GRU_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:17:57.355922Z",
     "iopub.status.busy": "2021-08-12T21:17:57.355248Z",
     "iopub.status.idle": "2021-08-12T21:17:57.359834Z",
     "shell.execute_reply": "2021-08-12T21:17:57.359318Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.84337Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.275184,
     "end_time": "2021-08-12T21:17:57.359973",
     "exception": false,
     "start_time": "2021-08-12T21:17:57.084789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 37\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:18:01.328706Z",
     "iopub.status.busy": "2021-08-12T21:18:01.327947Z",
     "iopub.status.idle": "2021-08-12T21:19:38.555397Z",
     "shell.execute_reply": "2021-08-12T21:19:38.555820Z",
     "shell.execute_reply.started": "2021-07-31T12:07:33.257302Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 97.513251,
     "end_time": "2021-08-12T21:19:38.556005",
     "exception": false,
     "start_time": "2021-08-12T21:18:01.042754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 224ms/step - loss: 0.6032 - masked_acc: 0.6255 - masked_auc: 0.5230 - val_loss: 0.5050 - val_masked_acc: 0.7203 - val_masked_auc: 0.6280\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4703 - masked_acc: 0.7291 - masked_auc: 0.6702 - val_loss: 0.5261 - val_masked_acc: 0.7455 - val_masked_auc: 0.7259\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4166 - masked_acc: 0.7513 - masked_auc: 0.7423 - val_loss: 0.5052 - val_masked_acc: 0.7594 - val_masked_auc: 0.7652\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4043 - masked_acc: 0.7621 - masked_auc: 0.7738 - val_loss: 0.5272 - val_masked_acc: 0.7684 - val_masked_auc: 0.7877\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3876 - masked_acc: 0.7709 - masked_auc: 0.7934 - val_loss: 0.5439 - val_masked_acc: 0.7751 - val_masked_auc: 0.8027\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3614 - masked_acc: 0.7775 - masked_auc: 0.8077 - val_loss: 0.5658 - val_masked_acc: 0.7806 - val_masked_auc: 0.8151\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3479 - masked_acc: 0.7824 - masked_auc: 0.8189 - val_loss: 0.6074 - val_masked_acc: 0.7861 - val_masked_auc: 0.8257\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3195 - masked_acc: 0.7882 - masked_auc: 0.8293 - val_loss: 0.6741 - val_masked_acc: 0.7918 - val_masked_auc: 0.8349\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2916 - masked_acc: 0.7941 - masked_auc: 0.8384 - val_loss: 0.7887 - val_masked_acc: 0.7970 - val_masked_auc: 0.8432\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2852 - masked_acc: 0.7989 - masked_auc: 0.8461 - val_loss: 0.8589 - val_masked_acc: 0.8023 - val_masked_auc: 0.8509\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2600 - masked_acc: 0.8042 - masked_auc: 0.8537 - val_loss: 1.0088 - val_masked_acc: 0.8077 - val_masked_auc: 0.8584\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2298 - masked_acc: 0.8111 - masked_auc: 0.8635\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7553 - masked_acc: 0.8133 - masked_auc: 0.8665\n",
      "Test:  [0.7552724480628967, 0.8133485317230225, 0.86653071641922]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 11s 194ms/step - loss: 0.6048 - masked_acc: 0.5669 - masked_auc: 0.5053 - val_loss: 0.5202 - val_masked_acc: 0.7155 - val_masked_auc: 0.6326\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4550 - masked_acc: 0.7291 - masked_auc: 0.6755 - val_loss: 0.4871 - val_masked_acc: 0.7486 - val_masked_auc: 0.7324\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.4156 - masked_acc: 0.7540 - masked_auc: 0.7479 - val_loss: 0.4868 - val_masked_acc: 0.7637 - val_masked_auc: 0.7719\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3929 - masked_acc: 0.7671 - masked_auc: 0.7803 - val_loss: 0.5138 - val_masked_acc: 0.7742 - val_masked_auc: 0.7954\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3711 - masked_acc: 0.7770 - masked_auc: 0.8022 - val_loss: 0.5133 - val_masked_acc: 0.7825 - val_masked_auc: 0.8121\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3505 - masked_acc: 0.7848 - masked_auc: 0.8168 - val_loss: 0.5762 - val_masked_acc: 0.7886 - val_masked_auc: 0.8246\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3200 - masked_acc: 0.7913 - masked_auc: 0.8290 - val_loss: 0.5931 - val_masked_acc: 0.7947 - val_masked_auc: 0.8348\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3099 - masked_acc: 0.7968 - masked_auc: 0.8384 - val_loss: 0.6584 - val_masked_acc: 0.8000 - val_masked_auc: 0.8439\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2884 - masked_acc: 0.8020 - masked_auc: 0.8470 - val_loss: 0.7923 - val_masked_acc: 0.8055 - val_masked_auc: 0.8518\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2619 - masked_acc: 0.8075 - masked_auc: 0.8547 - val_loss: 0.7802 - val_masked_acc: 0.8108 - val_masked_auc: 0.8593\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2441 - masked_acc: 0.8127 - masked_auc: 0.8621 - val_loss: 0.8896 - val_masked_acc: 0.8158 - val_masked_auc: 0.8661\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2317 - masked_acc: 0.8176 - masked_auc: 0.8686 - val_loss: 0.8610 - val_masked_acc: 0.8210 - val_masked_auc: 0.8726\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2269 - masked_acc: 0.8225 - masked_auc: 0.8746 - val_loss: 0.9242 - val_masked_acc: 0.8252 - val_masked_auc: 0.8780\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2070 - masked_acc: 0.8280 - masked_auc: 0.8817\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7952 - masked_acc: 0.8296 - masked_auc: 0.8836\n",
      "Test:  [0.7952123880386353, 0.8295570611953735, 0.8836263418197632]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 195ms/step - loss: 0.5883 - masked_acc: 0.6859 - masked_auc: 0.5259 - val_loss: 0.4858 - val_masked_acc: 0.7339 - val_masked_auc: 0.6579\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4557 - masked_acc: 0.7412 - masked_auc: 0.6937 - val_loss: 0.4654 - val_masked_acc: 0.7534 - val_masked_auc: 0.7423\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4076 - masked_acc: 0.7585 - masked_auc: 0.7582 - val_loss: 0.4724 - val_masked_acc: 0.7654 - val_masked_auc: 0.7790\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3872 - masked_acc: 0.7691 - masked_auc: 0.7877 - val_loss: 0.4856 - val_masked_acc: 0.7741 - val_masked_auc: 0.7998\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3781 - masked_acc: 0.7767 - masked_auc: 0.8058 - val_loss: 0.5103 - val_masked_acc: 0.7814 - val_masked_auc: 0.8149\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3536 - masked_acc: 0.7839 - masked_auc: 0.8196 - val_loss: 0.5371 - val_masked_acc: 0.7877 - val_masked_auc: 0.8263\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3426 - masked_acc: 0.7897 - masked_auc: 0.8297 - val_loss: 0.6073 - val_masked_acc: 0.7930 - val_masked_auc: 0.8354\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3172 - masked_acc: 0.7950 - masked_auc: 0.8386 - val_loss: 0.6041 - val_masked_acc: 0.7982 - val_masked_auc: 0.8439\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3047 - masked_acc: 0.8002 - masked_auc: 0.8469 - val_loss: 0.7387 - val_masked_acc: 0.8035 - val_masked_auc: 0.8511\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2789 - masked_acc: 0.8056 - masked_auc: 0.8539 - val_loss: 0.7529 - val_masked_acc: 0.8086 - val_masked_auc: 0.8581\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2622 - masked_acc: 0.8104 - masked_auc: 0.8607 - val_loss: 0.7901 - val_masked_acc: 0.8133 - val_masked_auc: 0.8648\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2437 - masked_acc: 0.8151 - masked_auc: 0.8673 - val_loss: 0.8161 - val_masked_acc: 0.8178 - val_masked_auc: 0.8710\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2310 - masked_acc: 0.8209 - masked_auc: 0.8752\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7991 - masked_acc: 0.8228 - masked_auc: 0.8772\n",
      "Test:  [0.799075722694397, 0.822755753993988, 0.8772174119949341]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 200ms/step - loss: 0.5873 - masked_acc: 0.7349 - masked_auc: 0.5386 - val_loss: 0.4884 - val_masked_acc: 0.7438 - val_masked_auc: 0.6409\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4711 - masked_acc: 0.7479 - masked_auc: 0.6805 - val_loss: 0.4576 - val_masked_acc: 0.7594 - val_masked_auc: 0.7331\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4037 - masked_acc: 0.7639 - masked_auc: 0.7501 - val_loss: 0.4654 - val_masked_acc: 0.7700 - val_masked_auc: 0.7721\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3990 - masked_acc: 0.7725 - masked_auc: 0.7806 - val_loss: 0.4581 - val_masked_acc: 0.7774 - val_masked_auc: 0.7941\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3798 - masked_acc: 0.7796 - masked_auc: 0.7999 - val_loss: 0.5004 - val_masked_acc: 0.7835 - val_masked_auc: 0.8096\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3637 - masked_acc: 0.7853 - masked_auc: 0.8142 - val_loss: 0.5003 - val_masked_acc: 0.7886 - val_masked_auc: 0.8217\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3549 - masked_acc: 0.7900 - masked_auc: 0.8252 - val_loss: 0.5766 - val_masked_acc: 0.7937 - val_masked_auc: 0.8321\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3160 - masked_acc: 0.7957 - masked_auc: 0.8358 - val_loss: 0.5793 - val_masked_acc: 0.7990 - val_masked_auc: 0.8415\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2938 - masked_acc: 0.8009 - masked_auc: 0.8447 - val_loss: 0.7003 - val_masked_acc: 0.8038 - val_masked_auc: 0.8496\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2706 - masked_acc: 0.8057 - masked_auc: 0.8527 - val_loss: 0.7478 - val_masked_acc: 0.8090 - val_masked_auc: 0.8574\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2475 - masked_acc: 0.8109 - masked_auc: 0.8603 - val_loss: 0.8091 - val_masked_acc: 0.8144 - val_masked_auc: 0.8648\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2313 - masked_acc: 0.8163 - masked_auc: 0.8674 - val_loss: 0.8873 - val_masked_acc: 0.8193 - val_masked_auc: 0.8715\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2179 - masked_acc: 0.8226 - masked_auc: 0.8758\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9605 - masked_acc: 0.8245 - masked_auc: 0.8777\n",
      "Test:  [0.9605389833450317, 0.8245448470115662, 0.877733588218689]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 191ms/step - loss: 0.5813 - masked_acc: 0.6541 - masked_auc: 0.5577 - val_loss: 0.5061 - val_masked_acc: 0.7363 - val_masked_auc: 0.6811\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4454 - masked_acc: 0.7437 - masked_auc: 0.7120 - val_loss: 0.4682 - val_masked_acc: 0.7579 - val_masked_auc: 0.7558\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4079 - masked_acc: 0.7620 - masked_auc: 0.7678 - val_loss: 0.4858 - val_masked_acc: 0.7699 - val_masked_auc: 0.7877\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3870 - masked_acc: 0.7732 - masked_auc: 0.7949 - val_loss: 0.5033 - val_masked_acc: 0.7778 - val_masked_auc: 0.8062\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3692 - masked_acc: 0.7805 - masked_auc: 0.8117 - val_loss: 0.5221 - val_masked_acc: 0.7843 - val_masked_auc: 0.8188\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3557 - masked_acc: 0.7864 - masked_auc: 0.8229 - val_loss: 0.5638 - val_masked_acc: 0.7904 - val_masked_auc: 0.8299\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3214 - masked_acc: 0.7927 - masked_auc: 0.8335 - val_loss: 0.6404 - val_masked_acc: 0.7955 - val_masked_auc: 0.8392\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3031 - masked_acc: 0.7978 - masked_auc: 0.8427 - val_loss: 0.6496 - val_masked_acc: 0.8008 - val_masked_auc: 0.8478\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2951 - masked_acc: 0.8026 - masked_auc: 0.8507 - val_loss: 0.8126 - val_masked_acc: 0.8059 - val_masked_auc: 0.8553\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2728 - masked_acc: 0.8076 - masked_auc: 0.8582 - val_loss: 0.7956 - val_masked_acc: 0.8106 - val_masked_auc: 0.8620\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2561 - masked_acc: 0.8122 - masked_auc: 0.8645 - val_loss: 0.8520 - val_masked_acc: 0.8148 - val_masked_auc: 0.8679\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2429 - masked_acc: 0.8165 - masked_auc: 0.8702 - val_loss: 0.8668 - val_masked_acc: 0.8188 - val_masked_auc: 0.8733\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2282 - masked_acc: 0.8217 - masked_auc: 0.8772\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7958 - masked_acc: 0.8235 - masked_auc: 0.8793\n",
      "Test:  [0.7957891821861267, 0.8235058188438416, 0.8793309926986694]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr gru layers\n",
    "    gru_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    gru_sub_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    gru_ques = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    gru_shif = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "    gru_features = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    gru_output = tf.concat([gru_chap, gru_sub_chap, gru_ques, gru_shif, gru_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 5*EMBEDDING_DIM), activation='relu')(gru_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='gru_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:19:39.404332Z",
     "iopub.status.busy": "2021-08-12T21:19:39.403621Z",
     "iopub.status.idle": "2021-08-12T21:19:39.414051Z",
     "shell.execute_reply": "2021-08-12T21:19:39.414751Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.783012Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.459389,
     "end_time": "2021-08-12T21:19:39.415064",
     "exception": false,
     "start_time": "2021-08-12T21:19:38.955675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.8211777448654175 +/- 0.07151551047333851\n",
      "test avg acc:  0.8227424025535583 +/- 0.005263386178168837\n",
      "test avg auc:  0.8768878102302551 +/- 0.005647482952543486\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:19:40.230053Z",
     "iopub.status.busy": "2021-08-12T21:19:40.229391Z",
     "iopub.status.idle": "2021-08-12T21:19:40.237544Z",
     "shell.execute_reply": "2021-08-12T21:19:40.237039Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.794728Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.411712,
     "end_time": "2021-08-12T21:19:40.237676",
     "exception": false,
     "start_time": "2021-08-12T21:19:39.825964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.2227993667125702 +/- 0.009155421382447657\n",
      "train avg acc:  0.8208601236343384 +/- 0.005463149339598424\n",
      "train avg auc:  0.8746770620346069 +/- 0.0060465408926871096\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 508.097041,
   "end_time": "2021-08-12T21:19:43.787448",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:11:15.690407",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
