{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:10:56.977715Z",
     "iopub.status.busy": "2021-08-12T21:10:56.977026Z",
     "iopub.status.idle": "2021-08-12T21:11:03.466851Z",
     "shell.execute_reply": "2021-08-12T21:11:03.466162Z",
     "shell.execute_reply.started": "2021-07-31T12:06:59.141322Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.532622,
     "end_time": "2021-08-12T21:11:03.467012",
     "exception": false,
     "start_time": "2021-08-12T21:10:56.934390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:17:24.551897Z",
     "iopub.status.busy": "2021-08-12T21:17:24.551098Z",
     "iopub.status.idle": "2021-08-12T21:17:24.554506Z",
     "shell.execute_reply": "2021-08-12T21:17:24.553955Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.831612Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.372696,
     "end_time": "2021-08-12T21:17:24.554657",
     "exception": false,
     "start_time": "2021-08-12T21:17:24.181961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SETTINGS -> can be modified at any time\n",
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "GRU_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:17:25.289285Z",
     "iopub.status.busy": "2021-08-12T21:17:25.288497Z",
     "iopub.status.idle": "2021-08-12T21:17:25.290647Z",
     "shell.execute_reply": "2021-08-12T21:17:25.290027Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.84337Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.370925,
     "end_time": "2021-08-12T21:17:25.290785",
     "exception": false,
     "start_time": "2021-08-12T21:17:24.919860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xc90-aLzxat",
    "papermill": {
     "duration": 0.360511,
     "end_time": "2021-08-12T21:17:29.393124",
     "exception": false,
     "start_time": "2021-08-12T21:17:29.032613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## KFOLD - GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:17:30.167865Z",
     "iopub.status.busy": "2021-08-12T21:17:30.140991Z",
     "iopub.status.idle": "2021-08-12T21:18:54.384640Z",
     "shell.execute_reply": "2021-08-12T21:18:54.384107Z",
     "shell.execute_reply.started": "2021-07-31T12:07:33.257302Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 84.626982,
     "end_time": "2021-08-12T21:18:54.384790",
     "exception": false,
     "start_time": "2021-08-12T21:17:29.757808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 195ms/step - loss: 0.5918 - masked_acc: 0.6583 - masked_auc: 0.5436 - val_loss: 0.5041 - val_masked_acc: 0.7348 - val_masked_auc: 0.6638\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4464 - masked_acc: 0.7438 - masked_auc: 0.7035 - val_loss: 0.4844 - val_masked_acc: 0.7575 - val_masked_auc: 0.7480\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4060 - masked_acc: 0.7625 - masked_auc: 0.7624 - val_loss: 0.4974 - val_masked_acc: 0.7696 - val_masked_auc: 0.7807\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4026 - masked_acc: 0.7721 - masked_auc: 0.7867 - val_loss: 0.5387 - val_masked_acc: 0.7774 - val_masked_auc: 0.7989\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3706 - masked_acc: 0.7801 - masked_auc: 0.8045 - val_loss: 0.5570 - val_masked_acc: 0.7838 - val_masked_auc: 0.8116\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3492 - masked_acc: 0.7861 - masked_auc: 0.8160 - val_loss: 0.5910 - val_masked_acc: 0.7894 - val_masked_auc: 0.8226\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3432 - masked_acc: 0.7913 - masked_auc: 0.8259 - val_loss: 0.6789 - val_masked_acc: 0.7950 - val_masked_auc: 0.8319\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3164 - masked_acc: 0.7969 - masked_auc: 0.8352 - val_loss: 0.6821 - val_masked_acc: 0.7998 - val_masked_auc: 0.8404\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2964 - masked_acc: 0.8017 - masked_auc: 0.8435 - val_loss: 0.6865 - val_masked_acc: 0.8042 - val_masked_auc: 0.8477\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2949 - masked_acc: 0.8058 - masked_auc: 0.8502 - val_loss: 0.7801 - val_masked_acc: 0.8079 - val_masked_auc: 0.8535\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2721 - masked_acc: 0.8095 - masked_auc: 0.8559 - val_loss: 0.9184 - val_masked_acc: 0.8117 - val_masked_auc: 0.8590\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2595 - masked_acc: 0.8131 - masked_auc: 0.8611 - val_loss: 1.0179 - val_masked_acc: 0.8154 - val_masked_auc: 0.8643\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2396 - masked_acc: 0.8177 - masked_auc: 0.8680\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8021 - masked_acc: 0.8194 - masked_auc: 0.8703\n",
      "Test:  [0.8021363019943237, 0.8193919658660889, 0.8703486919403076]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 166ms/step - loss: 0.5923 - masked_acc: 0.6977 - masked_auc: 0.5579 - val_loss: 0.4919 - val_masked_acc: 0.7337 - val_masked_auc: 0.6621\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4525 - masked_acc: 0.7376 - masked_auc: 0.6956 - val_loss: 0.4641 - val_masked_acc: 0.7489 - val_masked_auc: 0.7431\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4219 - masked_acc: 0.7531 - masked_auc: 0.7562 - val_loss: 0.4635 - val_masked_acc: 0.7617 - val_masked_auc: 0.7767\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3878 - masked_acc: 0.7656 - masked_auc: 0.7851 - val_loss: 0.4932 - val_masked_acc: 0.7708 - val_masked_auc: 0.7967\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3714 - masked_acc: 0.7740 - masked_auc: 0.8024 - val_loss: 0.5233 - val_masked_acc: 0.7785 - val_masked_auc: 0.8115\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3519 - masked_acc: 0.7813 - masked_auc: 0.8161 - val_loss: 0.5352 - val_masked_acc: 0.7853 - val_masked_auc: 0.8230\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3447 - masked_acc: 0.7870 - masked_auc: 0.8265 - val_loss: 0.6028 - val_masked_acc: 0.7903 - val_masked_auc: 0.8321\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3229 - masked_acc: 0.7922 - masked_auc: 0.8357 - val_loss: 0.6089 - val_masked_acc: 0.7952 - val_masked_auc: 0.8407\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3044 - masked_acc: 0.7971 - masked_auc: 0.8437 - val_loss: 0.6493 - val_masked_acc: 0.8001 - val_masked_auc: 0.8482\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2998 - masked_acc: 0.8017 - masked_auc: 0.8507 - val_loss: 0.7289 - val_masked_acc: 0.8044 - val_masked_auc: 0.8548\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2806 - masked_acc: 0.8060 - masked_auc: 0.8571 - val_loss: 0.7667 - val_masked_acc: 0.8087 - val_masked_auc: 0.8610\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2580 - masked_acc: 0.8103 - masked_auc: 0.8631 - val_loss: 0.8999 - val_masked_acc: 0.8130 - val_masked_auc: 0.8669\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2420 - masked_acc: 0.8146 - masked_auc: 0.8689 - val_loss: 0.9939 - val_masked_acc: 0.8172 - val_masked_auc: 0.8722\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2272 - masked_acc: 0.8197 - masked_auc: 0.8757\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8569 - masked_acc: 0.8212 - masked_auc: 0.8777\n",
      "Test:  [0.8568554520606995, 0.8212296366691589, 0.8777050971984863]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 220ms/step - loss: 0.5985 - masked_acc: 0.7185 - masked_auc: 0.5221 - val_loss: 0.5170 - val_masked_acc: 0.7378 - val_masked_auc: 0.6449\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4542 - masked_acc: 0.7434 - masked_auc: 0.6865 - val_loss: 0.4850 - val_masked_acc: 0.7565 - val_masked_auc: 0.7377\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4105 - masked_acc: 0.7615 - masked_auc: 0.7526 - val_loss: 0.4992 - val_masked_acc: 0.7681 - val_masked_auc: 0.7737\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3902 - masked_acc: 0.7713 - masked_auc: 0.7821 - val_loss: 0.5027 - val_masked_acc: 0.7761 - val_masked_auc: 0.7942\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3789 - masked_acc: 0.7783 - masked_auc: 0.7998 - val_loss: 0.5637 - val_masked_acc: 0.7821 - val_masked_auc: 0.8081\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3614 - masked_acc: 0.7844 - masked_auc: 0.8127 - val_loss: 0.5991 - val_masked_acc: 0.7881 - val_masked_auc: 0.8198\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3381 - masked_acc: 0.7903 - masked_auc: 0.8240 - val_loss: 0.6072 - val_masked_acc: 0.7935 - val_masked_auc: 0.8299\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3286 - masked_acc: 0.7953 - masked_auc: 0.8330 - val_loss: 0.7158 - val_masked_acc: 0.7983 - val_masked_auc: 0.8378\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3176 - masked_acc: 0.7999 - masked_auc: 0.8405 - val_loss: 0.7437 - val_masked_acc: 0.8031 - val_masked_auc: 0.8449\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2791 - masked_acc: 0.8051 - masked_auc: 0.8478 - val_loss: 0.8217 - val_masked_acc: 0.8076 - val_masked_auc: 0.8515\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2647 - masked_acc: 0.8094 - masked_auc: 0.8542 - val_loss: 0.8434 - val_masked_acc: 0.8119 - val_masked_auc: 0.8576\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2528 - masked_acc: 0.8134 - masked_auc: 0.8601 - val_loss: 1.0220 - val_masked_acc: 0.8159 - val_masked_auc: 0.8632\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2290 - masked_acc: 0.8189 - masked_auc: 0.8675\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8227 - masked_acc: 0.8205 - masked_auc: 0.8697\n",
      "Test:  [0.8226642608642578, 0.8204973936080933, 0.8696919083595276]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 170ms/step - loss: 0.6045 - masked_acc: 0.6535 - masked_auc: 0.5113 - val_loss: 0.5063 - val_masked_acc: 0.7275 - val_masked_auc: 0.6590\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4518 - masked_acc: 0.7399 - masked_auc: 0.6962 - val_loss: 0.4577 - val_masked_acc: 0.7543 - val_masked_auc: 0.7454\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4231 - masked_acc: 0.7586 - masked_auc: 0.7585 - val_loss: 0.4759 - val_masked_acc: 0.7679 - val_masked_auc: 0.7812\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3931 - masked_acc: 0.7710 - masked_auc: 0.7893 - val_loss: 0.4854 - val_masked_acc: 0.7761 - val_masked_auc: 0.8008\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3776 - masked_acc: 0.7788 - masked_auc: 0.8066 - val_loss: 0.4924 - val_masked_acc: 0.7833 - val_masked_auc: 0.8151\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3478 - masked_acc: 0.7860 - masked_auc: 0.8199 - val_loss: 0.5498 - val_masked_acc: 0.7897 - val_masked_auc: 0.8264\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3442 - masked_acc: 0.7914 - masked_auc: 0.8302 - val_loss: 0.5481 - val_masked_acc: 0.7953 - val_masked_auc: 0.8364\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3170 - masked_acc: 0.7972 - masked_auc: 0.8396 - val_loss: 0.6319 - val_masked_acc: 0.8004 - val_masked_auc: 0.8448\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2857 - masked_acc: 0.8024 - masked_auc: 0.8480 - val_loss: 0.6349 - val_masked_acc: 0.8054 - val_masked_auc: 0.8528\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2804 - masked_acc: 0.8070 - masked_auc: 0.8554 - val_loss: 0.7679 - val_masked_acc: 0.8100 - val_masked_auc: 0.8597\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2576 - masked_acc: 0.8118 - masked_auc: 0.8622 - val_loss: 0.7618 - val_masked_acc: 0.8145 - val_masked_auc: 0.8657\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2527 - masked_acc: 0.8160 - masked_auc: 0.8679 - val_loss: 0.8561 - val_masked_acc: 0.8187 - val_masked_auc: 0.8713\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2278 - masked_acc: 0.8216 - masked_auc: 0.8753\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8445 - masked_acc: 0.8232 - masked_auc: 0.8771\n",
      "Test:  [0.8445090055465698, 0.8231579065322876, 0.8770846128463745]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 164ms/step - loss: 0.5927 - masked_acc: 0.7002 - masked_auc: 0.5483 - val_loss: 0.4973 - val_masked_acc: 0.7414 - val_masked_auc: 0.6733\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4406 - masked_acc: 0.7503 - masked_auc: 0.7103 - val_loss: 0.4894 - val_masked_acc: 0.7606 - val_masked_auc: 0.7545\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3955 - masked_acc: 0.7668 - masked_auc: 0.7678 - val_loss: 0.4895 - val_masked_acc: 0.7718 - val_masked_auc: 0.7861\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3892 - masked_acc: 0.7751 - masked_auc: 0.7936 - val_loss: 0.5111 - val_masked_acc: 0.7801 - val_masked_auc: 0.8050\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3639 - masked_acc: 0.7825 - masked_auc: 0.8106 - val_loss: 0.5519 - val_masked_acc: 0.7865 - val_masked_auc: 0.8192\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3343 - masked_acc: 0.7891 - masked_auc: 0.8243 - val_loss: 0.5549 - val_masked_acc: 0.7919 - val_masked_auc: 0.8306\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3312 - masked_acc: 0.7940 - masked_auc: 0.8343 - val_loss: 0.6274 - val_masked_acc: 0.7970 - val_masked_auc: 0.8396\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3113 - masked_acc: 0.7989 - masked_auc: 0.8429 - val_loss: 0.6233 - val_masked_acc: 0.8016 - val_masked_auc: 0.8477\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2997 - masked_acc: 0.8034 - masked_auc: 0.8504 - val_loss: 0.7267 - val_masked_acc: 0.8059 - val_masked_auc: 0.8549\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2670 - masked_acc: 0.8077 - masked_auc: 0.8578 - val_loss: 0.7837 - val_masked_acc: 0.8104 - val_masked_auc: 0.8616\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2551 - masked_acc: 0.8122 - masked_auc: 0.8641 - val_loss: 0.8628 - val_masked_acc: 0.8148 - val_masked_auc: 0.8678\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2454 - masked_acc: 0.8163 - masked_auc: 0.8701 - val_loss: 0.9655 - val_masked_acc: 0.8188 - val_masked_auc: 0.8733\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2264 - masked_acc: 0.8218 - masked_auc: 0.8771\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9378 - masked_acc: 0.8237 - masked_auc: 0.8792\n",
      "Test:  [0.9377544522285461, 0.8236839175224304, 0.8792130947113037]\n"
     ]
    }
   ],
   "source": [
    "# 5 fold cross validation with GRU-based model\n",
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_shifted_t.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_shifted_t.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_shifted_t.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "\n",
    "    # definr GRU layers\n",
    "    GRU_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    GRU_sub_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    GRU_ques = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    GRU_shif = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "\n",
    "    GRU_output = tf.concat([GRU_chap, GRU_sub_chap, GRU_ques, GRU_shif], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(GRU_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted],\n",
    "        outputs=pred,\n",
    "        name='GRU_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:18:55.457082Z",
     "iopub.status.busy": "2021-08-12T21:18:55.456260Z",
     "iopub.status.idle": "2021-08-12T21:18:55.461400Z",
     "shell.execute_reply": "2021-08-12T21:18:55.460868Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.783012Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.547083,
     "end_time": "2021-08-12T21:18:55.461545",
     "exception": false,
     "start_time": "2021-08-12T21:18:54.914462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.8527838945388794 +/- 0.04642718601387392\n",
      "test avg acc:  0.8215921640396118 +/- 0.001612315265764289\n",
      "test avg auc:  0.8748086810111999 +/- 0.003975948122684162\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:18:56.522719Z",
     "iopub.status.busy": "2021-08-12T21:18:56.521997Z",
     "iopub.status.idle": "2021-08-12T21:18:56.526735Z",
     "shell.execute_reply": "2021-08-12T21:18:56.526061Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.794728Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.537763,
     "end_time": "2021-08-12T21:18:56.526889",
     "exception": false,
     "start_time": "2021-08-12T21:18:55.989126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.22999011278152465 +/- 0.004861213805550328\n",
      "train avg acc:  0.8199353098869324 +/- 0.0015601551279484835\n",
      "train avg auc:  0.8727330684661865 +/- 0.004114734491075528\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 491.108522,
   "end_time": "2021-08-12T21:18:59.960866",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:10:48.852344",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
