{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:12:09.261171Z",
     "iopub.status.busy": "2021-08-12T21:12:09.250961Z",
     "iopub.status.idle": "2021-08-12T21:12:16.303884Z",
     "shell.execute_reply": "2021-08-12T21:12:16.303029Z",
     "shell.execute_reply.started": "2021-07-31T12:06:59.141322Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.087156,
     "end_time": "2021-08-12T21:12:16.304058",
     "exception": false,
     "start_time": "2021-08-12T21:12:09.216902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:19:01.511496Z",
     "iopub.status.busy": "2021-08-12T21:19:01.510732Z",
     "iopub.status.idle": "2021-08-12T21:19:01.515714Z",
     "shell.execute_reply": "2021-08-12T21:19:01.515027Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.831612Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.369394,
     "end_time": "2021-08-12T21:19:01.515860",
     "exception": false,
     "start_time": "2021-08-12T21:19:01.146466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "GRU_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:19:02.256351Z",
     "iopub.status.busy": "2021-08-12T21:19:02.255598Z",
     "iopub.status.idle": "2021-08-12T21:19:02.258936Z",
     "shell.execute_reply": "2021-08-12T21:19:02.258313Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.84337Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.376711,
     "end_time": "2021-08-12T21:19:02.259078",
     "exception": false,
     "start_time": "2021-08-12T21:19:01.882367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 37\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:19:07.141644Z",
     "iopub.status.busy": "2021-08-12T21:19:07.140847Z",
     "iopub.status.idle": "2021-08-12T21:20:32.874075Z",
     "shell.execute_reply": "2021-08-12T21:20:32.873536Z",
     "shell.execute_reply.started": "2021-07-31T12:07:33.257302Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 86.112262,
     "end_time": "2021-08-12T21:20:32.874226",
     "exception": false,
     "start_time": "2021-08-12T21:19:06.761964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 203ms/step - loss: 0.5873 - masked_acc: 0.7169 - masked_auc: 0.5273 - val_loss: 0.5851 - val_masked_acc: 0.7366 - val_masked_auc: 0.6315\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4832 - masked_acc: 0.7393 - masked_auc: 0.6663 - val_loss: 0.5556 - val_masked_acc: 0.7495 - val_masked_auc: 0.7158\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4176 - masked_acc: 0.7542 - masked_auc: 0.7328 - val_loss: 0.5537 - val_masked_acc: 0.7593 - val_masked_auc: 0.7547\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3992 - masked_acc: 0.7625 - masked_auc: 0.7634 - val_loss: 0.6027 - val_masked_acc: 0.7663 - val_masked_auc: 0.7764\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3821 - masked_acc: 0.7687 - masked_auc: 0.7827 - val_loss: 0.6172 - val_masked_acc: 0.7720 - val_masked_auc: 0.7924\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3643 - masked_acc: 0.7746 - masked_auc: 0.7976 - val_loss: 0.6739 - val_masked_acc: 0.7786 - val_masked_auc: 0.8058\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3199 - masked_acc: 0.7817 - masked_auc: 0.8109 - val_loss: 0.7117 - val_masked_acc: 0.7850 - val_masked_auc: 0.8179\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2981 - masked_acc: 0.7878 - masked_auc: 0.8224 - val_loss: 0.7754 - val_masked_acc: 0.7918 - val_masked_auc: 0.8290\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2829 - masked_acc: 0.7942 - masked_auc: 0.8331 - val_loss: 0.9235 - val_masked_acc: 0.7982 - val_masked_auc: 0.8386\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2645 - masked_acc: 0.8004 - masked_auc: 0.8421 - val_loss: 0.9793 - val_masked_acc: 0.8040 - val_masked_auc: 0.8473\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2462 - masked_acc: 0.8062 - masked_auc: 0.8506 - val_loss: 1.0399 - val_masked_acc: 0.8098 - val_masked_auc: 0.8551\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2268 - masked_acc: 0.8118 - masked_auc: 0.8580 - val_loss: 1.1691 - val_masked_acc: 0.8151 - val_masked_auc: 0.8626\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.1991 - masked_acc: 0.8172 - masked_auc: 0.8655 - val_loss: 1.3550 - val_masked_acc: 0.8204 - val_masked_auc: 0.8693\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1685 - masked_acc: 0.8239 - masked_auc: 0.8742\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9232 - masked_acc: 0.8264 - masked_auc: 0.8773\n",
      "Test:  [0.9231982827186584, 0.8264354467391968, 0.8773190379142761]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 171ms/step - loss: 0.5984 - masked_acc: 0.6778 - masked_auc: 0.5139 - val_loss: 0.5071 - val_masked_acc: 0.7332 - val_masked_auc: 0.6434\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4669 - masked_acc: 0.7396 - masked_auc: 0.6803 - val_loss: 0.4942 - val_masked_acc: 0.7498 - val_masked_auc: 0.7241\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.4381 - masked_acc: 0.7532 - masked_auc: 0.7379 - val_loss: 0.5014 - val_masked_acc: 0.7604 - val_masked_auc: 0.7601\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4016 - masked_acc: 0.7634 - masked_auc: 0.7689 - val_loss: 0.5387 - val_masked_acc: 0.7673 - val_masked_auc: 0.7813\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3801 - masked_acc: 0.7700 - masked_auc: 0.7873 - val_loss: 0.5518 - val_masked_acc: 0.7737 - val_masked_auc: 0.7970\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3630 - masked_acc: 0.7758 - masked_auc: 0.8021 - val_loss: 0.6068 - val_masked_acc: 0.7795 - val_masked_auc: 0.8096\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3393 - masked_acc: 0.7821 - masked_auc: 0.8139 - val_loss: 0.6742 - val_masked_acc: 0.7858 - val_masked_auc: 0.8203\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3225 - masked_acc: 0.7881 - masked_auc: 0.8243 - val_loss: 0.7325 - val_masked_acc: 0.7916 - val_masked_auc: 0.8300\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3109 - masked_acc: 0.7937 - masked_auc: 0.8333 - val_loss: 0.7018 - val_masked_acc: 0.7972 - val_masked_auc: 0.8386\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2905 - masked_acc: 0.7993 - masked_auc: 0.8416 - val_loss: 0.7914 - val_masked_acc: 0.8021 - val_masked_auc: 0.8460\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2627 - masked_acc: 0.8043 - masked_auc: 0.8489 - val_loss: 0.9931 - val_masked_acc: 0.8075 - val_masked_auc: 0.8529\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2495 - masked_acc: 0.8093 - masked_auc: 0.8555 - val_loss: 0.9752 - val_masked_acc: 0.8124 - val_masked_auc: 0.8595\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2177 - masked_acc: 0.8160 - masked_auc: 0.8645\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8289 - masked_acc: 0.8181 - masked_auc: 0.8672\n",
      "Test:  [0.8288722038269043, 0.818148136138916, 0.8672152161598206]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 172ms/step - loss: 0.5978 - masked_acc: 0.7148 - masked_auc: 0.5012 - val_loss: 0.5068 - val_masked_acc: 0.7382 - val_masked_auc: 0.6356\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4710 - masked_acc: 0.7396 - masked_auc: 0.6763 - val_loss: 0.4932 - val_masked_acc: 0.7459 - val_masked_auc: 0.7245\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4331 - masked_acc: 0.7503 - masked_auc: 0.7394 - val_loss: 0.4966 - val_masked_acc: 0.7582 - val_masked_auc: 0.7627\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3934 - masked_acc: 0.7624 - masked_auc: 0.7730 - val_loss: 0.5211 - val_masked_acc: 0.7673 - val_masked_auc: 0.7853\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3784 - masked_acc: 0.7702 - masked_auc: 0.7922 - val_loss: 0.5142 - val_masked_acc: 0.7742 - val_masked_auc: 0.8017\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3671 - masked_acc: 0.7767 - masked_auc: 0.8067 - val_loss: 0.5679 - val_masked_acc: 0.7810 - val_masked_auc: 0.8147\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3443 - masked_acc: 0.7831 - masked_auc: 0.8191 - val_loss: 0.5974 - val_masked_acc: 0.7866 - val_masked_auc: 0.8250\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3214 - masked_acc: 0.7887 - masked_auc: 0.8288 - val_loss: 0.6142 - val_masked_acc: 0.7920 - val_masked_auc: 0.8346\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3001 - masked_acc: 0.7941 - masked_auc: 0.8383 - val_loss: 0.6723 - val_masked_acc: 0.7974 - val_masked_auc: 0.8436\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2800 - masked_acc: 0.7996 - masked_auc: 0.8469 - val_loss: 0.7751 - val_masked_acc: 0.8030 - val_masked_auc: 0.8518\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2581 - masked_acc: 0.8050 - masked_auc: 0.8548 - val_loss: 0.8185 - val_masked_acc: 0.8082 - val_masked_auc: 0.8594\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2378 - masked_acc: 0.8102 - masked_auc: 0.8621 - val_loss: 1.0408 - val_masked_acc: 0.8133 - val_masked_auc: 0.8659\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2217 - masked_acc: 0.8163 - masked_auc: 0.8703\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0731 - masked_acc: 0.8181 - masked_auc: 0.8724\n",
      "Test:  [1.073132038116455, 0.8181465864181519, 0.872438907623291]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 249ms/step - loss: 0.5952 - masked_acc: 0.6949 - masked_auc: 0.5380 - val_loss: 0.5207 - val_masked_acc: 0.7349 - val_masked_auc: 0.6263\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4637 - masked_acc: 0.7428 - masked_auc: 0.6690 - val_loss: 0.4785 - val_masked_acc: 0.7480 - val_masked_auc: 0.7195\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4330 - masked_acc: 0.7515 - masked_auc: 0.7339 - val_loss: 0.5042 - val_masked_acc: 0.7566 - val_masked_auc: 0.7555\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3999 - masked_acc: 0.7602 - masked_auc: 0.7657 - val_loss: 0.4937 - val_masked_acc: 0.7644 - val_masked_auc: 0.7785\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3886 - masked_acc: 0.7670 - masked_auc: 0.7855 - val_loss: 0.5188 - val_masked_acc: 0.7713 - val_masked_auc: 0.7952\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3702 - masked_acc: 0.7738 - masked_auc: 0.8004 - val_loss: 0.5671 - val_masked_acc: 0.7779 - val_masked_auc: 0.8080\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3406 - masked_acc: 0.7804 - masked_auc: 0.8125 - val_loss: 0.5704 - val_masked_acc: 0.7838 - val_masked_auc: 0.8193\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3362 - masked_acc: 0.7860 - masked_auc: 0.8230 - val_loss: 0.5816 - val_masked_acc: 0.7894 - val_masked_auc: 0.8288\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3203 - masked_acc: 0.7912 - masked_auc: 0.8320 - val_loss: 0.6668 - val_masked_acc: 0.7941 - val_masked_auc: 0.8367\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2968 - masked_acc: 0.7959 - masked_auc: 0.8398 - val_loss: 0.7433 - val_masked_acc: 0.7993 - val_masked_auc: 0.8448\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2716 - masked_acc: 0.8011 - masked_auc: 0.8476 - val_loss: 0.7927 - val_masked_acc: 0.8039 - val_masked_auc: 0.8520\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2623 - masked_acc: 0.8056 - masked_auc: 0.8545 - val_loss: 0.8233 - val_masked_acc: 0.8086 - val_masked_auc: 0.8587\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2274 - masked_acc: 0.8119 - masked_auc: 0.8634\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8212 - masked_acc: 0.8140 - masked_auc: 0.8661\n",
      "Test:  [0.8211652040481567, 0.814003586769104, 0.8660722374916077]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 173ms/step - loss: 0.5994 - masked_acc: 0.6295 - masked_auc: 0.5081 - val_loss: 0.5090 - val_masked_acc: 0.7224 - val_masked_auc: 0.6235\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4772 - masked_acc: 0.7265 - masked_auc: 0.6632 - val_loss: 0.5151 - val_masked_acc: 0.7388 - val_masked_auc: 0.7131\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4317 - masked_acc: 0.7441 - masked_auc: 0.7292 - val_loss: 0.5099 - val_masked_acc: 0.7523 - val_masked_auc: 0.7518\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4089 - masked_acc: 0.7559 - masked_auc: 0.7603 - val_loss: 0.5480 - val_masked_acc: 0.7612 - val_masked_auc: 0.7743\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3898 - masked_acc: 0.7643 - masked_auc: 0.7807 - val_loss: 0.5787 - val_masked_acc: 0.7690 - val_masked_auc: 0.7910\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3739 - masked_acc: 0.7713 - masked_auc: 0.7963 - val_loss: 0.6007 - val_masked_acc: 0.7757 - val_masked_auc: 0.8053\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3354 - masked_acc: 0.7784 - masked_auc: 0.8104 - val_loss: 0.7483 - val_masked_acc: 0.7823 - val_masked_auc: 0.8171\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3164 - masked_acc: 0.7848 - masked_auc: 0.8216 - val_loss: 0.7114 - val_masked_acc: 0.7886 - val_masked_auc: 0.8277\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2937 - masked_acc: 0.7909 - masked_auc: 0.8317 - val_loss: 0.8385 - val_masked_acc: 0.7942 - val_masked_auc: 0.8367\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2773 - masked_acc: 0.7964 - masked_auc: 0.8403 - val_loss: 1.0212 - val_masked_acc: 0.8001 - val_masked_auc: 0.8452\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2602 - masked_acc: 0.8021 - masked_auc: 0.8483 - val_loss: 1.1087 - val_masked_acc: 0.8055 - val_masked_auc: 0.8529\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2336 - masked_acc: 0.8091 - masked_auc: 0.8582\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8187 - masked_acc: 0.8114 - masked_auc: 0.8614\n",
      "Test:  [0.818691611289978, 0.8114451766014099, 0.8613764047622681]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    #train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr GRU layers\n",
    "    GRU_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    GRU_sub_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    GRU_ques = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    GRU_features = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    GRU_output = tf.concat([GRU_chap, GRU_sub_chap, GRU_ques, GRU_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(GRU_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='GRU_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:20:33.942773Z",
     "iopub.status.busy": "2021-08-12T21:20:33.941762Z",
     "iopub.status.idle": "2021-08-12T21:20:33.945883Z",
     "shell.execute_reply": "2021-08-12T21:20:33.945232Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.783012Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.538498,
     "end_time": "2021-08-12T21:20:33.946025",
     "exception": false,
     "start_time": "2021-08-12T21:20:33.407527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.8930118680000305 +/- 0.09813647182881369\n",
      "test avg acc:  0.8176357865333557 +/- 0.005088692657958909\n",
      "test avg auc:  0.8688843607902527 +/- 0.005492578016505915\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:20:35.019388Z",
     "iopub.status.busy": "2021-08-12T21:20:35.018489Z",
     "iopub.status.idle": "2021-08-12T21:20:35.025379Z",
     "shell.execute_reply": "2021-08-12T21:20:35.024611Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.794728Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.547783,
     "end_time": "2021-08-12T21:20:35.025577",
     "exception": false,
     "start_time": "2021-08-12T21:20:34.477794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.21376554071903228 +/- 0.02327360673723974\n",
      "train avg acc:  0.8154297351837159 +/- 0.005018433616764767\n",
      "train avg auc:  0.8661211013793946 +/- 0.005572036553053783\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 517.112419,
   "end_time": "2021-08-12T21:20:38.166617",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:12:01.054198",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
