{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:12:26.337606Z",
     "iopub.status.busy": "2021-08-12T21:12:26.336450Z",
     "iopub.status.idle": "2021-08-12T21:12:33.049526Z",
     "shell.execute_reply": "2021-08-12T21:12:33.048693Z",
     "shell.execute_reply.started": "2021-07-31T12:06:59.141322Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.746017,
     "end_time": "2021-08-12T21:12:33.049709",
     "exception": false,
     "start_time": "2021-08-12T21:12:26.303692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:20:38.988283Z",
     "iopub.status.busy": "2021-08-12T21:20:38.987640Z",
     "iopub.status.idle": "2021-08-12T21:20:38.991571Z",
     "shell.execute_reply": "2021-08-12T21:20:38.992140Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.831612Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.365723,
     "end_time": "2021-08-12T21:20:38.992318",
     "exception": false,
     "start_time": "2021-08-12T21:20:38.626595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "GRU_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:20:39.710112Z",
     "iopub.status.busy": "2021-08-12T21:20:39.709461Z",
     "iopub.status.idle": "2021-08-12T21:20:39.713454Z",
     "shell.execute_reply": "2021-08-12T21:20:39.714032Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.84337Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.364124,
     "end_time": "2021-08-12T21:20:39.714191",
     "exception": false,
     "start_time": "2021-08-12T21:20:39.350067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 39\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:20:44.534352Z",
     "iopub.status.busy": "2021-08-12T21:20:44.501703Z",
     "iopub.status.idle": "2021-08-12T21:22:17.679496Z",
     "shell.execute_reply": "2021-08-12T21:22:17.678965Z",
     "shell.execute_reply.started": "2021-07-31T12:07:33.257302Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 93.547096,
     "end_time": "2021-08-12T21:22:17.679645",
     "exception": false,
     "start_time": "2021-08-12T21:20:44.132549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 230ms/step - loss: 0.6170 - masked_acc: 0.5423 - masked_auc: 0.5340 - val_loss: 0.5160 - val_masked_acc: 0.7043 - val_masked_auc: 0.6320\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4775 - masked_acc: 0.7130 - masked_auc: 0.6699 - val_loss: 0.5065 - val_masked_acc: 0.7309 - val_masked_auc: 0.7160\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4383 - masked_acc: 0.7355 - masked_auc: 0.7311 - val_loss: 0.5048 - val_masked_acc: 0.7448 - val_masked_auc: 0.7542\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4248 - masked_acc: 0.7477 - masked_auc: 0.7621 - val_loss: 0.5054 - val_masked_acc: 0.7554 - val_masked_auc: 0.7767\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3982 - masked_acc: 0.7584 - masked_auc: 0.7825 - val_loss: 0.5287 - val_masked_acc: 0.7641 - val_masked_auc: 0.7929\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3693 - masked_acc: 0.7669 - masked_auc: 0.7984 - val_loss: 0.5579 - val_masked_acc: 0.7710 - val_masked_auc: 0.8064\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3510 - masked_acc: 0.7735 - masked_auc: 0.8108 - val_loss: 0.6137 - val_masked_acc: 0.7779 - val_masked_auc: 0.8179\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3234 - masked_acc: 0.7803 - masked_auc: 0.8218 - val_loss: 0.6329 - val_masked_acc: 0.7841 - val_masked_auc: 0.8278\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3049 - masked_acc: 0.7865 - masked_auc: 0.8314 - val_loss: 0.6757 - val_masked_acc: 0.7903 - val_masked_auc: 0.8368\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2958 - masked_acc: 0.7922 - masked_auc: 0.8399 - val_loss: 0.7811 - val_masked_acc: 0.7957 - val_masked_auc: 0.8444\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2748 - masked_acc: 0.7978 - masked_auc: 0.8473 - val_loss: 0.8501 - val_masked_acc: 0.8012 - val_masked_auc: 0.8514\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2688 - masked_acc: 0.8028 - masked_auc: 0.8538 - val_loss: 0.8164 - val_masked_acc: 0.8057 - val_masked_auc: 0.8579\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2367 - masked_acc: 0.8077 - masked_auc: 0.8603 - val_loss: 0.8634 - val_masked_acc: 0.8103 - val_masked_auc: 0.8640\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2222 - masked_acc: 0.8135 - masked_auc: 0.8682\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8484 - masked_acc: 0.8159 - masked_auc: 0.8707\n",
      "Test:  [0.8484349846839905, 0.8158729672431946, 0.8707329034805298]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 11s 187ms/step - loss: 0.5830 - masked_acc: 0.7206 - masked_auc: 0.5510 - val_loss: 0.5450 - val_masked_acc: 0.7407 - val_masked_auc: 0.6533\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.4654 - masked_acc: 0.7421 - masked_auc: 0.6894 - val_loss: 0.5259 - val_masked_acc: 0.7514 - val_masked_auc: 0.7338\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4282 - masked_acc: 0.7564 - masked_auc: 0.7481 - val_loss: 0.5231 - val_masked_acc: 0.7633 - val_masked_auc: 0.7671\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3985 - masked_acc: 0.7667 - masked_auc: 0.7752 - val_loss: 0.5727 - val_masked_acc: 0.7720 - val_masked_auc: 0.7876\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3672 - masked_acc: 0.7751 - masked_auc: 0.7942 - val_loss: 0.5756 - val_masked_acc: 0.7790 - val_masked_auc: 0.8037\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3530 - masked_acc: 0.7815 - masked_auc: 0.8088 - val_loss: 0.6296 - val_masked_acc: 0.7853 - val_masked_auc: 0.8164\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3257 - masked_acc: 0.7877 - masked_auc: 0.8209 - val_loss: 0.6767 - val_masked_acc: 0.7911 - val_masked_auc: 0.8272\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3070 - masked_acc: 0.7934 - masked_auc: 0.8311 - val_loss: 0.7272 - val_masked_acc: 0.7967 - val_masked_auc: 0.8364\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2891 - masked_acc: 0.7987 - masked_auc: 0.8397 - val_loss: 0.8177 - val_masked_acc: 0.8018 - val_masked_auc: 0.8449\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2585 - masked_acc: 0.8039 - masked_auc: 0.8482 - val_loss: 0.8918 - val_masked_acc: 0.8073 - val_masked_auc: 0.8528\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2562 - masked_acc: 0.8090 - masked_auc: 0.8554 - val_loss: 1.0493 - val_masked_acc: 0.8120 - val_masked_auc: 0.8594\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2237 - masked_acc: 0.8139 - masked_auc: 0.8621 - val_loss: 1.0134 - val_masked_acc: 0.8169 - val_masked_auc: 0.8658\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2187 - masked_acc: 0.8186 - masked_auc: 0.8683 - val_loss: 1.2346 - val_masked_acc: 0.8214 - val_masked_auc: 0.8716\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1867 - masked_acc: 0.8244 - masked_auc: 0.8759\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1117 - masked_acc: 0.8265 - masked_auc: 0.8784\n",
      "Test:  [1.1116570234298706, 0.8264896273612976, 0.8783721327781677]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 11s 182ms/step - loss: 0.6038 - masked_acc: 0.5537 - masked_auc: 0.5076 - val_loss: 0.4920 - val_masked_acc: 0.7134 - val_masked_auc: 0.6259\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4651 - masked_acc: 0.7209 - masked_auc: 0.6697 - val_loss: 0.4799 - val_masked_acc: 0.7362 - val_masked_auc: 0.7190\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4290 - masked_acc: 0.7426 - masked_auc: 0.7349 - val_loss: 0.5062 - val_masked_acc: 0.7522 - val_masked_auc: 0.7567\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.4077 - masked_acc: 0.7556 - masked_auc: 0.7662 - val_loss: 0.5209 - val_masked_acc: 0.7615 - val_masked_auc: 0.7788\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3817 - masked_acc: 0.7643 - masked_auc: 0.7856 - val_loss: 0.5567 - val_masked_acc: 0.7693 - val_masked_auc: 0.7950\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3599 - masked_acc: 0.7722 - masked_auc: 0.8002 - val_loss: 0.6110 - val_masked_acc: 0.7769 - val_masked_auc: 0.8080\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3415 - masked_acc: 0.7792 - masked_auc: 0.8126 - val_loss: 0.6839 - val_masked_acc: 0.7837 - val_masked_auc: 0.8195\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3210 - masked_acc: 0.7859 - masked_auc: 0.8236 - val_loss: 0.7098 - val_masked_acc: 0.7900 - val_masked_auc: 0.8300\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2969 - masked_acc: 0.7923 - masked_auc: 0.8336 - val_loss: 0.8302 - val_masked_acc: 0.7960 - val_masked_auc: 0.8391\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2755 - masked_acc: 0.7983 - masked_auc: 0.8424 - val_loss: 0.8670 - val_masked_acc: 0.8016 - val_masked_auc: 0.8472\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2681 - masked_acc: 0.8034 - masked_auc: 0.8500 - val_loss: 0.9431 - val_masked_acc: 0.8067 - val_masked_auc: 0.8544\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2447 - masked_acc: 0.8085 - masked_auc: 0.8570 - val_loss: 0.9729 - val_masked_acc: 0.8119 - val_masked_auc: 0.8612\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2252 - masked_acc: 0.8150 - masked_auc: 0.8656\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7845 - masked_acc: 0.8169 - masked_auc: 0.8683\n",
      "Test:  [0.7844630479812622, 0.8169370889663696, 0.8682729601860046]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 11s 270ms/step - loss: 0.6038 - masked_acc: 0.7015 - masked_auc: 0.5257 - val_loss: 0.5054 - val_masked_acc: 0.7353 - val_masked_auc: 0.6129\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4698 - masked_acc: 0.7366 - masked_auc: 0.6585 - val_loss: 0.4855 - val_masked_acc: 0.7432 - val_masked_auc: 0.7110\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4453 - masked_acc: 0.7478 - masked_auc: 0.7273 - val_loss: 0.4978 - val_masked_acc: 0.7561 - val_masked_auc: 0.7513\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4259 - masked_acc: 0.7589 - masked_auc: 0.7594 - val_loss: 0.5159 - val_masked_acc: 0.7636 - val_masked_auc: 0.7727\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.3955 - masked_acc: 0.7662 - masked_auc: 0.7794 - val_loss: 0.5229 - val_masked_acc: 0.7705 - val_masked_auc: 0.7887\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3771 - masked_acc: 0.7729 - masked_auc: 0.7939 - val_loss: 0.5389 - val_masked_acc: 0.7764 - val_masked_auc: 0.8015\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3550 - masked_acc: 0.7788 - masked_auc: 0.8060 - val_loss: 0.5814 - val_masked_acc: 0.7825 - val_masked_auc: 0.8135\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3201 - masked_acc: 0.7850 - masked_auc: 0.8180 - val_loss: 0.6265 - val_masked_acc: 0.7883 - val_masked_auc: 0.8247\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3105 - masked_acc: 0.7905 - masked_auc: 0.8284 - val_loss: 0.7095 - val_masked_acc: 0.7943 - val_masked_auc: 0.8344\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2857 - masked_acc: 0.7964 - masked_auc: 0.8378 - val_loss: 0.7954 - val_masked_acc: 0.7998 - val_masked_auc: 0.8431\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2669 - masked_acc: 0.8018 - masked_auc: 0.8460 - val_loss: 0.8916 - val_masked_acc: 0.8048 - val_masked_auc: 0.8506\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.2434 - masked_acc: 0.8067 - masked_auc: 0.8535 - val_loss: 0.9511 - val_masked_acc: 0.8097 - val_masked_auc: 0.8576\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2365 - masked_acc: 0.8129 - masked_auc: 0.8623\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7153 - masked_acc: 0.8148 - masked_auc: 0.8650\n",
      "Test:  [0.7152585983276367, 0.8148298859596252, 0.8649500608444214]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 179ms/step - loss: 0.6166 - masked_acc: 0.5411 - masked_auc: 0.5216 - val_loss: 0.5110 - val_masked_acc: 0.7111 - val_masked_auc: 0.6158\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4822 - masked_acc: 0.7212 - masked_auc: 0.6535 - val_loss: 0.4970 - val_masked_acc: 0.7384 - val_masked_auc: 0.7090\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4236 - masked_acc: 0.7451 - masked_auc: 0.7268 - val_loss: 0.5032 - val_masked_acc: 0.7541 - val_masked_auc: 0.7492\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4096 - masked_acc: 0.7585 - masked_auc: 0.7585 - val_loss: 0.5176 - val_masked_acc: 0.7646 - val_masked_auc: 0.7729\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3737 - masked_acc: 0.7678 - masked_auc: 0.7807 - val_loss: 0.5213 - val_masked_acc: 0.7733 - val_masked_auc: 0.7913\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3668 - masked_acc: 0.7760 - masked_auc: 0.7970 - val_loss: 0.5528 - val_masked_acc: 0.7805 - val_masked_auc: 0.8052\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3513 - masked_acc: 0.7826 - masked_auc: 0.8098 - val_loss: 0.6132 - val_masked_acc: 0.7869 - val_masked_auc: 0.8170\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3293 - masked_acc: 0.7889 - masked_auc: 0.8210 - val_loss: 0.6176 - val_masked_acc: 0.7930 - val_masked_auc: 0.8276\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3008 - masked_acc: 0.7952 - masked_auc: 0.8313 - val_loss: 0.6992 - val_masked_acc: 0.7989 - val_masked_auc: 0.8368\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.2856 - masked_acc: 0.8010 - masked_auc: 0.8403 - val_loss: 0.7263 - val_masked_acc: 0.8044 - val_masked_auc: 0.8452\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2641 - masked_acc: 0.8064 - masked_auc: 0.8482 - val_loss: 0.8156 - val_masked_acc: 0.8096 - val_masked_auc: 0.8527\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2548 - masked_acc: 0.8113 - masked_auc: 0.8554 - val_loss: 0.8813 - val_masked_acc: 0.8147 - val_masked_auc: 0.8599\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2152 - masked_acc: 0.8180 - masked_auc: 0.8649\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8560 - masked_acc: 0.8198 - masked_auc: 0.8677\n",
      "Test:  [0.8559582829475403, 0.8198078870773315, 0.8676577806472778]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr GRU layers\n",
    "    GRU_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    GRU_sub_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    GRU_ques = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    GRU_features = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    GRU_output = tf.concat([GRU_chap, GRU_sub_chap, GRU_ques, GRU_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(GRU_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='GRU_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:22:18.804888Z",
     "iopub.status.busy": "2021-08-12T21:22:18.804204Z",
     "iopub.status.idle": "2021-08-12T21:22:18.814310Z",
     "shell.execute_reply": "2021-08-12T21:22:18.813671Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.783012Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.596543,
     "end_time": "2021-08-12T21:22:18.814464",
     "exception": false,
     "start_time": "2021-08-12T21:22:18.217921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.86315438747406 +/- 0.13422927860511885\n",
      "test avg acc:  0.8187874913215637 +/- 0.004193928629657451\n",
      "test avg auc:  0.8699971675872803 +/- 0.004573844294347403\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:22:19.898685Z",
     "iopub.status.busy": "2021-08-12T21:22:19.898007Z",
     "iopub.status.idle": "2021-08-12T21:22:19.902476Z",
     "shell.execute_reply": "2021-08-12T21:22:19.901956Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.794728Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.548481,
     "end_time": "2021-08-12T21:22:19.902617",
     "exception": false,
     "start_time": "2021-08-12T21:22:19.354136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.21717242598533631 +/- 0.016682616674257765\n",
      "train avg acc:  0.8167566061019897 +/- 0.004228333542593592\n",
      "train avg auc:  0.8673945784568786 +/- 0.004678308226685535\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 605.171636,
   "end_time": "2021-08-12T21:22:23.421062",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:12:18.249426",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
