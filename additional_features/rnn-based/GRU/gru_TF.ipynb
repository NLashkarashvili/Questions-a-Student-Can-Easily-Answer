{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:12:43.432022Z",
     "iopub.status.busy": "2021-08-12T21:12:43.431443Z",
     "iopub.status.idle": "2021-08-12T21:12:49.377692Z",
     "shell.execute_reply": "2021-08-12T21:12:49.376730Z",
     "shell.execute_reply.started": "2021-07-31T12:06:59.141322Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 5.979611,
     "end_time": "2021-08-12T21:12:49.377851",
     "exception": false,
     "start_time": "2021-08-12T21:12:43.398240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, GRU, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:18:35.298627Z",
     "iopub.status.busy": "2021-08-12T21:18:35.297739Z",
     "iopub.status.idle": "2021-08-12T21:18:35.300423Z",
     "shell.execute_reply": "2021-08-12T21:18:35.299979Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.831612Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.278742,
     "end_time": "2021-08-12T21:18:35.300562",
     "exception": false,
     "start_time": "2021-08-12T21:18:35.021820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "GRU_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:18:35.848542Z",
     "iopub.status.busy": "2021-08-12T21:18:35.847912Z",
     "iopub.status.idle": "2021-08-12T21:18:35.850541Z",
     "shell.execute_reply": "2021-08-12T21:18:35.850085Z",
     "shell.execute_reply.started": "2021-07-31T12:07:32.84337Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.278442,
     "end_time": "2021-08-12T21:18:35.850669",
     "exception": false,
     "start_time": "2021-08-12T21:18:35.572227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 2\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:18:39.583695Z",
     "iopub.status.busy": "2021-08-12T21:18:39.582716Z",
     "iopub.status.idle": "2021-08-12T21:19:53.226520Z",
     "shell.execute_reply": "2021-08-12T21:19:53.226016Z",
     "shell.execute_reply.started": "2021-07-31T12:07:33.257302Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 73.919178,
     "end_time": "2021-08-12T21:19:53.226677",
     "exception": false,
     "start_time": "2021-08-12T21:18:39.307499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 180ms/step - loss: 0.5983 - masked_acc: 0.6428 - masked_auc: 0.5331 - val_loss: 0.5135 - val_masked_acc: 0.7318 - val_masked_auc: 0.6572\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4588 - masked_acc: 0.7377 - masked_auc: 0.6917 - val_loss: 0.5148 - val_masked_acc: 0.7471 - val_masked_auc: 0.7308\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4354 - masked_acc: 0.7514 - masked_auc: 0.7437 - val_loss: 0.5185 - val_masked_acc: 0.7582 - val_masked_auc: 0.7613\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4083 - masked_acc: 0.7607 - masked_auc: 0.7692 - val_loss: 0.5536 - val_masked_acc: 0.7652 - val_masked_auc: 0.7800\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3865 - masked_acc: 0.7679 - masked_auc: 0.7858 - val_loss: 0.5774 - val_masked_acc: 0.7721 - val_masked_auc: 0.7947\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3654 - masked_acc: 0.7744 - masked_auc: 0.7999 - val_loss: 0.6409 - val_masked_acc: 0.7779 - val_masked_auc: 0.8066\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3498 - masked_acc: 0.7796 - masked_auc: 0.8105 - val_loss: 0.7462 - val_masked_acc: 0.7825 - val_masked_auc: 0.8164\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3334 - masked_acc: 0.7845 - masked_auc: 0.8201 - val_loss: 0.7668 - val_masked_acc: 0.7882 - val_masked_auc: 0.8255\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3003 - masked_acc: 0.7903 - masked_auc: 0.8294 - val_loss: 0.7767 - val_masked_acc: 0.7929 - val_masked_auc: 0.8341\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2942 - masked_acc: 0.7946 - masked_auc: 0.8370 - val_loss: 0.9290 - val_masked_acc: 0.7974 - val_masked_auc: 0.8417\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2756 - masked_acc: 0.7991 - masked_auc: 0.8444 - val_loss: 1.0092 - val_masked_acc: 0.8020 - val_masked_auc: 0.8486\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2487 - masked_acc: 0.8048 - masked_auc: 0.8534\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8480 - masked_acc: 0.8068 - masked_auc: 0.8563\n",
      "Test:  [0.8479955792427063, 0.8068020343780518, 0.8562646508216858]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 161ms/step - loss: 0.5966 - masked_acc: 0.6410 - masked_auc: 0.5222 - val_loss: 0.5278 - val_masked_acc: 0.7247 - val_masked_auc: 0.6560\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4621 - masked_acc: 0.7343 - masked_auc: 0.6911 - val_loss: 0.5315 - val_masked_acc: 0.7449 - val_masked_auc: 0.7298\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4371 - masked_acc: 0.7494 - masked_auc: 0.7431 - val_loss: 0.5419 - val_masked_acc: 0.7567 - val_masked_auc: 0.7610\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4046 - masked_acc: 0.7608 - masked_auc: 0.7693 - val_loss: 0.5439 - val_masked_acc: 0.7655 - val_masked_auc: 0.7798\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4081 - masked_acc: 0.7673 - masked_auc: 0.7850 - val_loss: 0.6172 - val_masked_acc: 0.7718 - val_masked_auc: 0.7929\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3573 - masked_acc: 0.7747 - masked_auc: 0.7981 - val_loss: 0.5783 - val_masked_acc: 0.7774 - val_masked_auc: 0.8043\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3561 - masked_acc: 0.7796 - masked_auc: 0.8081 - val_loss: 0.6961 - val_masked_acc: 0.7829 - val_masked_auc: 0.8141\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3366 - masked_acc: 0.7851 - masked_auc: 0.8175 - val_loss: 0.7991 - val_masked_acc: 0.7883 - val_masked_auc: 0.8227\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3109 - masked_acc: 0.7903 - masked_auc: 0.8263 - val_loss: 0.8380 - val_masked_acc: 0.7932 - val_masked_auc: 0.8308\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3058 - masked_acc: 0.7949 - masked_auc: 0.8338 - val_loss: 0.7903 - val_masked_acc: 0.7980 - val_masked_auc: 0.8384\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2830 - masked_acc: 0.7996 - masked_auc: 0.8411 - val_loss: 1.0021 - val_masked_acc: 0.8021 - val_masked_auc: 0.8450\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2511 - masked_acc: 0.8052 - masked_auc: 0.8499\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7752 - masked_acc: 0.8072 - masked_auc: 0.8530\n",
      "Test:  [0.7752434015274048, 0.8072453737258911, 0.8530369997024536]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 151ms/step - loss: 0.6075 - masked_acc: 0.5437 - masked_auc: 0.5075 - val_loss: 0.5026 - val_masked_acc: 0.7080 - val_masked_auc: 0.6341\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4649 - masked_acc: 0.7187 - masked_auc: 0.6739 - val_loss: 0.4884 - val_masked_acc: 0.7340 - val_masked_auc: 0.7212\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4449 - masked_acc: 0.7396 - masked_auc: 0.7365 - val_loss: 0.5007 - val_masked_acc: 0.7499 - val_masked_auc: 0.7562\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4175 - masked_acc: 0.7534 - masked_auc: 0.7646 - val_loss: 0.5213 - val_masked_acc: 0.7583 - val_masked_auc: 0.7757\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4039 - masked_acc: 0.7611 - masked_auc: 0.7815 - val_loss: 0.5380 - val_masked_acc: 0.7656 - val_masked_auc: 0.7900\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3877 - masked_acc: 0.7676 - masked_auc: 0.7947 - val_loss: 0.6116 - val_masked_acc: 0.7719 - val_masked_auc: 0.8015\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3678 - masked_acc: 0.7740 - masked_auc: 0.8056 - val_loss: 0.6015 - val_masked_acc: 0.7778 - val_masked_auc: 0.8113\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3409 - masked_acc: 0.7798 - masked_auc: 0.8151 - val_loss: 0.6128 - val_masked_acc: 0.7827 - val_masked_auc: 0.8203\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3396 - masked_acc: 0.7844 - masked_auc: 0.8233 - val_loss: 0.7667 - val_masked_acc: 0.7873 - val_masked_auc: 0.8279\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3126 - masked_acc: 0.7891 - masked_auc: 0.8307 - val_loss: 0.8772 - val_masked_acc: 0.7919 - val_masked_auc: 0.8348\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3008 - masked_acc: 0.7934 - masked_auc: 0.8374 - val_loss: 0.9632 - val_masked_acc: 0.7962 - val_masked_auc: 0.8414\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2854 - masked_acc: 0.7978 - masked_auc: 0.8437 - val_loss: 1.0133 - val_masked_acc: 0.8004 - val_masked_auc: 0.8473\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2582 - masked_acc: 0.8032 - masked_auc: 0.8517\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6421 - masked_acc: 0.8052 - masked_auc: 0.8546\n",
      "Test:  [0.6420685648918152, 0.8051552176475525, 0.8545793294906616]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 209ms/step - loss: 0.6062 - masked_acc: 0.5471 - masked_auc: 0.5107 - val_loss: 0.5319 - val_masked_acc: 0.7116 - val_masked_auc: 0.6331\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4712 - masked_acc: 0.7201 - masked_auc: 0.6703 - val_loss: 0.5157 - val_masked_acc: 0.7365 - val_masked_auc: 0.7167\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4330 - masked_acc: 0.7424 - masked_auc: 0.7316 - val_loss: 0.5207 - val_masked_acc: 0.7510 - val_masked_auc: 0.7533\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4126 - masked_acc: 0.7552 - masked_auc: 0.7618 - val_loss: 0.5377 - val_masked_acc: 0.7604 - val_masked_auc: 0.7739\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3987 - masked_acc: 0.7631 - masked_auc: 0.7805 - val_loss: 0.5944 - val_masked_acc: 0.7677 - val_masked_auc: 0.7893\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3656 - masked_acc: 0.7704 - masked_auc: 0.7944 - val_loss: 0.5750 - val_masked_acc: 0.7743 - val_masked_auc: 0.8022\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3489 - masked_acc: 0.7767 - masked_auc: 0.8066 - val_loss: 0.6966 - val_masked_acc: 0.7801 - val_masked_auc: 0.8127\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.3319 - masked_acc: 0.7825 - masked_auc: 0.8166 - val_loss: 0.6784 - val_masked_acc: 0.7856 - val_masked_auc: 0.8224\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2977 - masked_acc: 0.7880 - masked_auc: 0.8263 - val_loss: 0.7175 - val_masked_acc: 0.7910 - val_masked_auc: 0.8316\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2952 - masked_acc: 0.7929 - masked_auc: 0.8347 - val_loss: 0.8223 - val_masked_acc: 0.7956 - val_masked_auc: 0.8393\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2693 - masked_acc: 0.7976 - masked_auc: 0.8424 - val_loss: 0.8874 - val_masked_acc: 0.8006 - val_masked_auc: 0.8468\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2684 - masked_acc: 0.8020 - masked_auc: 0.8492 - val_loss: 1.0521 - val_masked_acc: 0.8046 - val_masked_auc: 0.8529\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2386 - masked_acc: 0.8076 - masked_auc: 0.8575\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8017 - masked_acc: 0.8094 - masked_auc: 0.8601\n",
      "Test:  [0.8016908764839172, 0.8094049692153931, 0.8600828647613525]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 8s 155ms/step - loss: 0.6007 - masked_acc: 0.7168 - masked_auc: 0.5320 - val_loss: 0.4853 - val_masked_acc: 0.7393 - val_masked_auc: 0.6563\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4811 - masked_acc: 0.7423 - masked_auc: 0.6905 - val_loss: 0.4726 - val_masked_acc: 0.7527 - val_masked_auc: 0.7336\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4398 - masked_acc: 0.7555 - masked_auc: 0.7466 - val_loss: 0.4810 - val_masked_acc: 0.7621 - val_masked_auc: 0.7654\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4182 - masked_acc: 0.7652 - masked_auc: 0.7728 - val_loss: 0.4849 - val_masked_acc: 0.7702 - val_masked_auc: 0.7841\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3885 - masked_acc: 0.7726 - masked_auc: 0.7898 - val_loss: 0.5169 - val_masked_acc: 0.7765 - val_masked_auc: 0.7991\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3702 - masked_acc: 0.7787 - masked_auc: 0.8042 - val_loss: 0.5542 - val_masked_acc: 0.7824 - val_masked_auc: 0.8118\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3525 - masked_acc: 0.7842 - masked_auc: 0.8155 - val_loss: 0.5892 - val_masked_acc: 0.7873 - val_masked_auc: 0.8220\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3346 - masked_acc: 0.7889 - masked_auc: 0.8254 - val_loss: 0.6728 - val_masked_acc: 0.7923 - val_masked_auc: 0.8312\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.3039 - masked_acc: 0.7943 - masked_auc: 0.8346 - val_loss: 0.6564 - val_masked_acc: 0.7971 - val_masked_auc: 0.8392\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2977 - masked_acc: 0.7990 - masked_auc: 0.8422 - val_loss: 0.7396 - val_masked_acc: 0.8021 - val_masked_auc: 0.8468\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2839 - masked_acc: 0.8037 - masked_auc: 0.8494 - val_loss: 0.7834 - val_masked_acc: 0.8064 - val_masked_auc: 0.8535\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.2586 - masked_acc: 0.8080 - masked_auc: 0.8560 - val_loss: 0.8288 - val_masked_acc: 0.8103 - val_masked_auc: 0.8595\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2561 - masked_acc: 0.8127 - masked_auc: 0.8633\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9142 - masked_acc: 0.8140 - masked_auc: 0.8653\n",
      "Test:  [0.9141573309898376, 0.814002275466919, 0.8653103709220886]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr GRU layers\n",
    "    GRU_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    GRU_sub_chap = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    GRU_ques = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    GRU_features = GRU(GRU_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    GRU_output = tf.concat([GRU_chap, GRU_sub_chap, GRU_ques, GRU_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(GRU_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='GRU_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:19:53.993846Z",
     "iopub.status.busy": "2021-08-12T21:19:53.993272Z",
     "iopub.status.idle": "2021-08-12T21:19:53.997216Z",
     "shell.execute_reply": "2021-08-12T21:19:53.996767Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.783012Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.387862,
     "end_time": "2021-08-12T21:19:53.997355",
     "exception": false,
     "start_time": "2021-08-12T21:19:53.609493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.7962311506271362 +/- 0.09035766391860464\n",
      "test avg acc:  0.8085219740867615 +/- 0.0030573299991485696\n",
      "test avg auc:  0.8578548431396484 +/- 0.004404958377093841\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:19:54.840068Z",
     "iopub.status.busy": "2021-08-12T21:19:54.839453Z",
     "iopub.status.idle": "2021-08-12T21:19:54.843938Z",
     "shell.execute_reply": "2021-08-12T21:19:54.844377Z",
     "shell.execute_reply.started": "2021-07-31T12:12:25.794728Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.422631,
     "end_time": "2021-08-12T21:19:54.844546",
     "exception": false,
     "start_time": "2021-08-12T21:19:54.421915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.2505187064409256 +/- 0.006878712132433383\n",
      "train avg acc:  0.8067040205001831 +/- 0.0033236236216702274\n",
      "train avg auc:  0.8551699757575989 +/- 0.004782690777774537\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 442.119199,
   "end_time": "2021-08-12T21:19:58.534990",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:12:36.415791",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
