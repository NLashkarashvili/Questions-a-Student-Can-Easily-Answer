{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:54:04.958313Z",
     "iopub.status.busy": "2021-08-12T21:54:04.957043Z",
     "iopub.status.idle": "2021-08-12T21:54:12.429464Z",
     "shell.execute_reply": "2021-08-12T21:54:12.428588Z",
     "shell.execute_reply.started": "2021-08-06T20:58:20.355062Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.509308,
     "end_time": "2021-08-12T21:54:12.429681",
     "exception": false,
     "start_time": "2021-08-12T21:54:04.920373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:16.005901Z",
     "iopub.status.busy": "2021-08-12T22:01:16.005168Z",
     "iopub.status.idle": "2021-08-12T22:01:16.007136Z",
     "shell.execute_reply": "2021-08-12T22:01:16.007820Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.155466Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.382588,
     "end_time": "2021-08-12T22:01:16.008044",
     "exception": false,
     "start_time": "2021-08-12T22:01:15.625456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "LSTM_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:16.758139Z",
     "iopub.status.busy": "2021-08-12T22:01:16.757493Z",
     "iopub.status.idle": "2021-08-12T22:01:16.761108Z",
     "shell.execute_reply": "2021-08-12T22:01:16.760508Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.168321Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.380101,
     "end_time": "2021-08-12T22:01:16.761259",
     "exception": false,
     "start_time": "2021-08-12T22:01:16.381158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 2\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:21.850708Z",
     "iopub.status.busy": "2021-08-12T22:01:21.849575Z",
     "iopub.status.idle": "2021-08-12T22:03:09.721034Z",
     "shell.execute_reply": "2021-08-12T22:03:09.720504Z",
     "shell.execute_reply.started": "2021-08-06T21:05:49.358265Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 108.24682,
     "end_time": "2021-08-12T22:03:09.721188",
     "exception": false,
     "start_time": "2021-08-12T22:01:21.474368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 244ms/step - loss: 0.6027 - masked_acc: 0.6938 - masked_auc: 0.5299 - val_loss: 0.4844 - val_masked_acc: 0.7373 - val_masked_auc: 0.6480\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4607 - masked_acc: 0.7423 - masked_auc: 0.6862 - val_loss: 0.4708 - val_masked_acc: 0.7542 - val_masked_auc: 0.7312\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4197 - masked_acc: 0.7591 - masked_auc: 0.7466 - val_loss: 0.4658 - val_masked_acc: 0.7669 - val_masked_auc: 0.7709\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3876 - masked_acc: 0.7706 - masked_auc: 0.7799 - val_loss: 0.4964 - val_masked_acc: 0.7757 - val_masked_auc: 0.7941\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3683 - masked_acc: 0.7784 - masked_auc: 0.8007 - val_loss: 0.5185 - val_masked_acc: 0.7824 - val_masked_auc: 0.8105\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3552 - masked_acc: 0.7847 - masked_auc: 0.8152 - val_loss: 0.5574 - val_masked_acc: 0.7884 - val_masked_auc: 0.8224\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3382 - masked_acc: 0.7907 - masked_auc: 0.8262 - val_loss: 0.5590 - val_masked_acc: 0.7942 - val_masked_auc: 0.8324\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3195 - masked_acc: 0.7962 - masked_auc: 0.8359 - val_loss: 0.5914 - val_masked_acc: 0.7987 - val_masked_auc: 0.8407\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2986 - masked_acc: 0.8005 - masked_auc: 0.8437 - val_loss: 0.7173 - val_masked_acc: 0.8031 - val_masked_auc: 0.8483\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2816 - masked_acc: 0.8049 - masked_auc: 0.8512 - val_loss: 0.7725 - val_masked_acc: 0.8077 - val_masked_auc: 0.8552\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2644 - masked_acc: 0.8095 - masked_auc: 0.8580 - val_loss: 0.7602 - val_masked_acc: 0.8123 - val_masked_auc: 0.8619\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2526 - masked_acc: 0.8138 - masked_auc: 0.8643 - val_loss: 0.8790 - val_masked_acc: 0.8164 - val_masked_auc: 0.8681\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2290 - masked_acc: 0.8181 - masked_auc: 0.8704 - val_loss: 0.9828 - val_masked_acc: 0.8207 - val_masked_auc: 0.8737\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1998 - masked_acc: 0.8237 - masked_auc: 0.8778\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7580 - masked_acc: 0.8255 - masked_auc: 0.8804\n",
      "Test:  [0.7580108046531677, 0.825534999370575, 0.8803642988204956]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 228ms/step - loss: 0.6031 - masked_acc: 0.6546 - masked_auc: 0.5346 - val_loss: 0.5315 - val_masked_acc: 0.7295 - val_masked_auc: 0.6369\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4826 - masked_acc: 0.7337 - masked_auc: 0.6690 - val_loss: 0.5062 - val_masked_acc: 0.7450 - val_masked_auc: 0.7162\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4400 - masked_acc: 0.7490 - masked_auc: 0.7328 - val_loss: 0.4861 - val_masked_acc: 0.7579 - val_masked_auc: 0.7561\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4013 - masked_acc: 0.7613 - masked_auc: 0.7652 - val_loss: 0.4936 - val_masked_acc: 0.7677 - val_masked_auc: 0.7812\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3898 - masked_acc: 0.7700 - masked_auc: 0.7873 - val_loss: 0.5022 - val_masked_acc: 0.7755 - val_masked_auc: 0.7987\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3695 - masked_acc: 0.7779 - masked_auc: 0.8038 - val_loss: 0.5335 - val_masked_acc: 0.7828 - val_masked_auc: 0.8128\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3452 - masked_acc: 0.7849 - masked_auc: 0.8167 - val_loss: 0.5845 - val_masked_acc: 0.7884 - val_masked_auc: 0.8240\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3172 - masked_acc: 0.7907 - masked_auc: 0.8279 - val_loss: 0.6272 - val_masked_acc: 0.7941 - val_masked_auc: 0.8340\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2998 - masked_acc: 0.7960 - masked_auc: 0.8372 - val_loss: 0.6981 - val_masked_acc: 0.7994 - val_masked_auc: 0.8430\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2859 - masked_acc: 0.8011 - masked_auc: 0.8459 - val_loss: 0.6753 - val_masked_acc: 0.8042 - val_masked_auc: 0.8508\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2592 - masked_acc: 0.8062 - masked_auc: 0.8535 - val_loss: 0.8086 - val_masked_acc: 0.8091 - val_masked_auc: 0.8576\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2491 - masked_acc: 0.8106 - masked_auc: 0.8600 - val_loss: 0.8141 - val_masked_acc: 0.8135 - val_masked_auc: 0.8642\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2348 - masked_acc: 0.8151 - masked_auc: 0.8665 - val_loss: 0.9663 - val_masked_acc: 0.8178 - val_masked_auc: 0.8702\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2156 - masked_acc: 0.8204 - masked_auc: 0.8740\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8878 - masked_acc: 0.8223 - masked_auc: 0.8762\n",
      "Test:  [0.8878164291381836, 0.8223206996917725, 0.876235842704773]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 231ms/step - loss: 0.6202 - masked_acc: 0.5644 - masked_auc: 0.5033 - val_loss: 0.5423 - val_masked_acc: 0.7123 - val_masked_auc: 0.5943\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4824 - masked_acc: 0.7205 - masked_auc: 0.6347 - val_loss: 0.5054 - val_masked_acc: 0.7372 - val_masked_auc: 0.7018\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.4180 - masked_acc: 0.7433 - masked_auc: 0.7210 - val_loss: 0.5011 - val_masked_acc: 0.7530 - val_masked_auc: 0.7518\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4035 - masked_acc: 0.7567 - masked_auc: 0.7618 - val_loss: 0.5549 - val_masked_acc: 0.7635 - val_masked_auc: 0.7793\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3744 - masked_acc: 0.7667 - masked_auc: 0.7867 - val_loss: 0.5763 - val_masked_acc: 0.7716 - val_masked_auc: 0.7977\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3615 - masked_acc: 0.7744 - masked_auc: 0.8033 - val_loss: 0.5825 - val_masked_acc: 0.7787 - val_masked_auc: 0.8115\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3439 - masked_acc: 0.7810 - masked_auc: 0.8161 - val_loss: 0.6431 - val_masked_acc: 0.7844 - val_masked_auc: 0.8223\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3284 - masked_acc: 0.7866 - masked_auc: 0.8262 - val_loss: 0.6902 - val_masked_acc: 0.7900 - val_masked_auc: 0.8316\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.3124 - masked_acc: 0.7919 - masked_auc: 0.8350 - val_loss: 0.7255 - val_masked_acc: 0.7952 - val_masked_auc: 0.8402\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.2920 - masked_acc: 0.7970 - masked_auc: 0.8432 - val_loss: 0.8080 - val_masked_acc: 0.8001 - val_masked_auc: 0.8477\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2718 - masked_acc: 0.8021 - masked_auc: 0.8505 - val_loss: 0.9388 - val_masked_acc: 0.8049 - val_masked_auc: 0.8543\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2503 - masked_acc: 0.8068 - masked_auc: 0.8570 - val_loss: 0.9715 - val_masked_acc: 0.8095 - val_masked_auc: 0.8607\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2204 - masked_acc: 0.8115 - masked_auc: 0.8634 - val_loss: 1.0617 - val_masked_acc: 0.8140 - val_masked_auc: 0.8665\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2200 - masked_acc: 0.8169 - masked_auc: 0.8706\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8601 - masked_acc: 0.8188 - masked_auc: 0.8731\n",
      "Test:  [0.8601126670837402, 0.8187984228134155, 0.8730530738830566]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 233ms/step - loss: 0.6053 - masked_acc: 0.6308 - masked_auc: 0.5518 - val_loss: 0.5019 - val_masked_acc: 0.7282 - val_masked_auc: 0.6276\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4660 - masked_acc: 0.7343 - masked_auc: 0.6652 - val_loss: 0.4719 - val_masked_acc: 0.7463 - val_masked_auc: 0.7175\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4227 - masked_acc: 0.7520 - masked_auc: 0.7367 - val_loss: 0.4981 - val_masked_acc: 0.7604 - val_masked_auc: 0.7626\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3911 - masked_acc: 0.7647 - masked_auc: 0.7727 - val_loss: 0.5204 - val_masked_acc: 0.7721 - val_masked_auc: 0.7893\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3589 - masked_acc: 0.7758 - masked_auc: 0.7965 - val_loss: 0.5350 - val_masked_acc: 0.7805 - val_masked_auc: 0.8069\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3547 - masked_acc: 0.7828 - masked_auc: 0.8120 - val_loss: 0.5860 - val_masked_acc: 0.7869 - val_masked_auc: 0.8197\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3282 - masked_acc: 0.7896 - masked_auc: 0.8242 - val_loss: 0.6249 - val_masked_acc: 0.7934 - val_masked_auc: 0.8303\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3189 - masked_acc: 0.7955 - masked_auc: 0.8338 - val_loss: 0.6758 - val_masked_acc: 0.7990 - val_masked_auc: 0.8392\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3058 - masked_acc: 0.8008 - masked_auc: 0.8421 - val_loss: 0.7192 - val_masked_acc: 0.8044 - val_masked_auc: 0.8474\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2831 - masked_acc: 0.8061 - masked_auc: 0.8501 - val_loss: 0.8713 - val_masked_acc: 0.8092 - val_masked_auc: 0.8544\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2520 - masked_acc: 0.8111 - masked_auc: 0.8572 - val_loss: 0.8823 - val_masked_acc: 0.8144 - val_masked_auc: 0.8614\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2294 - masked_acc: 0.8163 - masked_auc: 0.8641 - val_loss: 1.0261 - val_masked_acc: 0.8192 - val_masked_auc: 0.8677\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2112 - masked_acc: 0.8223 - masked_auc: 0.8721\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7332 - masked_acc: 0.8245 - masked_auc: 0.8750\n",
      "Test:  [0.7331920862197876, 0.824493944644928, 0.875029444694519]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 219ms/step - loss: 0.5949 - masked_acc: 0.7157 - masked_auc: 0.5010 - val_loss: 0.5222 - val_masked_acc: 0.7351 - val_masked_auc: 0.6419\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.4728 - masked_acc: 0.7382 - masked_auc: 0.6785 - val_loss: 0.4936 - val_masked_acc: 0.7501 - val_masked_auc: 0.7271\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4188 - masked_acc: 0.7549 - masked_auc: 0.7438 - val_loss: 0.4711 - val_masked_acc: 0.7627 - val_masked_auc: 0.7674\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4067 - masked_acc: 0.7655 - masked_auc: 0.7756 - val_loss: 0.5161 - val_masked_acc: 0.7716 - val_masked_auc: 0.7908\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3800 - masked_acc: 0.7741 - masked_auc: 0.7970 - val_loss: 0.5050 - val_masked_acc: 0.7787 - val_masked_auc: 0.8068\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3559 - masked_acc: 0.7811 - masked_auc: 0.8115 - val_loss: 0.5245 - val_masked_acc: 0.7847 - val_masked_auc: 0.8196\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3358 - masked_acc: 0.7868 - masked_auc: 0.8238 - val_loss: 0.5677 - val_masked_acc: 0.7901 - val_masked_auc: 0.8300\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3307 - masked_acc: 0.7920 - masked_auc: 0.8331 - val_loss: 0.5792 - val_masked_acc: 0.7954 - val_masked_auc: 0.8389\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2989 - masked_acc: 0.7975 - masked_auc: 0.8422 - val_loss: 0.6235 - val_masked_acc: 0.8007 - val_masked_auc: 0.8471\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2916 - masked_acc: 0.8025 - masked_auc: 0.8498 - val_loss: 0.7347 - val_masked_acc: 0.8057 - val_masked_auc: 0.8545\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.2592 - masked_acc: 0.8076 - masked_auc: 0.8573 - val_loss: 0.8333 - val_masked_acc: 0.8108 - val_masked_auc: 0.8614\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2392 - masked_acc: 0.8127 - masked_auc: 0.8639 - val_loss: 0.9105 - val_masked_acc: 0.8154 - val_masked_auc: 0.8676\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2248 - masked_acc: 0.8171 - masked_auc: 0.8698 - val_loss: 1.0441 - val_masked_acc: 0.8204 - val_masked_auc: 0.8737\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1953 - masked_acc: 0.8234 - masked_auc: 0.8779\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8682 - masked_acc: 0.8254 - masked_auc: 0.8803\n",
      "Test:  [0.868166446685791, 0.8254296779632568, 0.88031005859375]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr LSTM layers\n",
    "    LSTM_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    LSTM_sub_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    LSTM_ques = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    LSTM_shif = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "    LSTM_features = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    LSTM_output = tf.concat([LSTM_chap, LSTM_sub_chap, LSTM_ques,LSTM_shif, LSTM_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 5*EMBEDDING_DIM), activation='relu')(LSTM_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='LSTM_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:03:10.888521Z",
     "iopub.status.busy": "2021-08-12T22:03:10.887783Z",
     "iopub.status.idle": "2021-08-12T22:03:10.898565Z",
     "shell.execute_reply": "2021-08-12T22:03:10.897779Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.922753Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.566144,
     "end_time": "2021-08-12T22:03:10.898756",
     "exception": false,
     "start_time": "2021-08-12T22:03:10.332612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.821459686756134 +/- 0.06308045896385149\n",
      "test avg acc:  0.8233155488967896 +/- 0.002536859146595249\n",
      "test avg auc:  0.8769985437393188 +/- 0.002909303497422981\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:03:12.026833Z",
     "iopub.status.busy": "2021-08-12T22:03:12.026032Z",
     "iopub.status.idle": "2021-08-12T22:03:12.032148Z",
     "shell.execute_reply": "2021-08-12T22:03:12.032641Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.935484Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.572037,
     "end_time": "2021-08-12T22:03:12.032825",
     "exception": false,
     "start_time": "2021-08-12T22:03:11.460788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.20839348137378694 +/- 0.009399259681037902\n",
      "train avg acc:  0.8213457584381103 +/- 0.0024932243333221195\n",
      "train avg auc:  0.8744932770729065 +/- 0.002963173929084734\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 559.368097,
   "end_time": "2021-08-12T22:03:15.319601",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:53:55.951504",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
