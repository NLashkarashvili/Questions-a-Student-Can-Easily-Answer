{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:55:39.205597Z",
     "iopub.status.busy": "2021-08-12T21:55:39.204975Z",
     "iopub.status.idle": "2021-08-12T21:55:45.641663Z",
     "shell.execute_reply": "2021-08-12T21:55:45.640614Z",
     "shell.execute_reply.started": "2021-08-06T20:58:20.355062Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.472457,
     "end_time": "2021-08-12T21:55:45.641874",
     "exception": false,
     "start_time": "2021-08-12T21:55:39.169417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:58.458067Z",
     "iopub.status.busy": "2021-08-12T22:01:58.457232Z",
     "iopub.status.idle": "2021-08-12T22:01:58.460696Z",
     "shell.execute_reply": "2021-08-12T22:01:58.460254Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.155466Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.278215,
     "end_time": "2021-08-12T22:01:58.460861",
     "exception": false,
     "start_time": "2021-08-12T22:01:58.182646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "LSTM_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:59.000333Z",
     "iopub.status.busy": "2021-08-12T22:01:58.999697Z",
     "iopub.status.idle": "2021-08-12T22:01:59.002818Z",
     "shell.execute_reply": "2021-08-12T22:01:59.002333Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.168321Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.275097,
     "end_time": "2021-08-12T22:01:59.002961",
     "exception": false,
     "start_time": "2021-08-12T22:01:58.727864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 39\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:02.885254Z",
     "iopub.status.busy": "2021-08-12T22:02:02.884555Z",
     "iopub.status.idle": "2021-08-12T22:03:22.802967Z",
     "shell.execute_reply": "2021-08-12T22:03:22.802440Z",
     "shell.execute_reply.started": "2021-08-06T21:05:49.358265Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 80.188335,
     "end_time": "2021-08-12T22:03:22.803113",
     "exception": false,
     "start_time": "2021-08-12T22:02:02.614778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 194ms/step - loss: 0.6018 - masked_acc: 0.7167 - masked_auc: 0.5252 - val_loss: 0.5358 - val_masked_acc: 0.7376 - val_masked_auc: 0.5891\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.5033 - masked_acc: 0.7352 - masked_auc: 0.6326 - val_loss: 0.5112 - val_masked_acc: 0.7429 - val_masked_auc: 0.6881\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4503 - masked_acc: 0.7463 - masked_auc: 0.7064 - val_loss: 0.5006 - val_masked_acc: 0.7534 - val_masked_auc: 0.7351\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.4188 - masked_acc: 0.7563 - masked_auc: 0.7461 - val_loss: 0.5415 - val_masked_acc: 0.7620 - val_masked_auc: 0.7629\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3880 - masked_acc: 0.7648 - masked_auc: 0.7708 - val_loss: 0.5560 - val_masked_acc: 0.7699 - val_masked_auc: 0.7833\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3667 - masked_acc: 0.7723 - masked_auc: 0.7893 - val_loss: 0.5713 - val_masked_acc: 0.7767 - val_masked_auc: 0.7988\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3436 - masked_acc: 0.7791 - masked_auc: 0.8040 - val_loss: 0.6263 - val_masked_acc: 0.7823 - val_masked_auc: 0.8110\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3256 - masked_acc: 0.7845 - masked_auc: 0.8154 - val_loss: 0.6787 - val_masked_acc: 0.7882 - val_masked_auc: 0.8217\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3114 - masked_acc: 0.7901 - masked_auc: 0.8253 - val_loss: 0.7636 - val_masked_acc: 0.7932 - val_masked_auc: 0.8304\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2909 - masked_acc: 0.7951 - masked_auc: 0.8337 - val_loss: 0.8049 - val_masked_acc: 0.7985 - val_masked_auc: 0.8386\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2789 - masked_acc: 0.8003 - masked_auc: 0.8415 - val_loss: 0.9321 - val_masked_acc: 0.8036 - val_masked_auc: 0.8462\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2508 - masked_acc: 0.8055 - masked_auc: 0.8491 - val_loss: 1.0609 - val_masked_acc: 0.8090 - val_masked_auc: 0.8538\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2212 - masked_acc: 0.8109 - masked_auc: 0.8567 - val_loss: 1.1918 - val_masked_acc: 0.8142 - val_masked_auc: 0.8607\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2039 - masked_acc: 0.8175 - masked_auc: 0.8655\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9400 - masked_acc: 0.8196 - masked_auc: 0.8682\n",
      "Test:  [0.9400478005409241, 0.819574773311615, 0.8681962490081787]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 175ms/step - loss: 0.5992 - masked_acc: 0.7182 - masked_auc: 0.5275 - val_loss: 0.5147 - val_masked_acc: 0.7407 - val_masked_auc: 0.6184\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4863 - masked_acc: 0.7432 - masked_auc: 0.6534 - val_loss: 0.4978 - val_masked_acc: 0.7462 - val_masked_auc: 0.7039\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4385 - masked_acc: 0.7510 - masked_auc: 0.7226 - val_loss: 0.5111 - val_masked_acc: 0.7576 - val_masked_auc: 0.7449\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4039 - masked_acc: 0.7614 - masked_auc: 0.7551 - val_loss: 0.5503 - val_masked_acc: 0.7668 - val_masked_auc: 0.7719\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3779 - masked_acc: 0.7702 - masked_auc: 0.7794 - val_loss: 0.5749 - val_masked_acc: 0.7745 - val_masked_auc: 0.7918\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3579 - masked_acc: 0.7771 - masked_auc: 0.7975 - val_loss: 0.6244 - val_masked_acc: 0.7820 - val_masked_auc: 0.8072\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3263 - masked_acc: 0.7850 - masked_auc: 0.8126 - val_loss: 0.6103 - val_masked_acc: 0.7880 - val_masked_auc: 0.8194\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3124 - masked_acc: 0.7903 - masked_auc: 0.8239 - val_loss: 0.6833 - val_masked_acc: 0.7936 - val_masked_auc: 0.8296\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3006 - masked_acc: 0.7957 - masked_auc: 0.8330 - val_loss: 0.8407 - val_masked_acc: 0.7998 - val_masked_auc: 0.8393\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2649 - masked_acc: 0.8020 - masked_auc: 0.8429 - val_loss: 0.8606 - val_masked_acc: 0.8057 - val_masked_auc: 0.8482\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2427 - masked_acc: 0.8078 - masked_auc: 0.8515 - val_loss: 0.9947 - val_masked_acc: 0.8108 - val_masked_auc: 0.8558\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2278 - masked_acc: 0.8127 - masked_auc: 0.8586 - val_loss: 1.2802 - val_masked_acc: 0.8158 - val_masked_auc: 0.8627\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1980 - masked_acc: 0.8194 - masked_auc: 0.8677\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9445 - masked_acc: 0.8215 - masked_auc: 0.8706\n",
      "Test:  [0.9444759488105774, 0.8215447664260864, 0.870620608329773]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 168ms/step - loss: 0.6069 - masked_acc: 0.6762 - masked_auc: 0.5185 - val_loss: 0.5579 - val_masked_acc: 0.7311 - val_masked_auc: 0.5907\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4978 - masked_acc: 0.7359 - masked_auc: 0.6266 - val_loss: 0.5222 - val_masked_acc: 0.7409 - val_masked_auc: 0.6808\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4441 - masked_acc: 0.7460 - masked_auc: 0.6998 - val_loss: 0.5280 - val_masked_acc: 0.7523 - val_masked_auc: 0.7289\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4006 - masked_acc: 0.7567 - masked_auc: 0.7405 - val_loss: 0.5472 - val_masked_acc: 0.7631 - val_masked_auc: 0.7602\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3684 - masked_acc: 0.7671 - masked_auc: 0.7694 - val_loss: 0.5806 - val_masked_acc: 0.7730 - val_masked_auc: 0.7841\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3514 - masked_acc: 0.7760 - masked_auc: 0.7908 - val_loss: 0.6383 - val_masked_acc: 0.7815 - val_masked_auc: 0.8022\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3263 - masked_acc: 0.7841 - masked_auc: 0.8076 - val_loss: 0.6531 - val_masked_acc: 0.7889 - val_masked_auc: 0.8165\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3061 - masked_acc: 0.7912 - masked_auc: 0.8211 - val_loss: 0.6888 - val_masked_acc: 0.7954 - val_masked_auc: 0.8285\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2925 - masked_acc: 0.7976 - masked_auc: 0.8323 - val_loss: 0.7551 - val_masked_acc: 0.8012 - val_masked_auc: 0.8385\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2711 - masked_acc: 0.8033 - masked_auc: 0.8418 - val_loss: 0.8108 - val_masked_acc: 0.8065 - val_masked_auc: 0.8473\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.2493 - masked_acc: 0.8084 - masked_auc: 0.8502 - val_loss: 0.8807 - val_masked_acc: 0.8114 - val_masked_auc: 0.8549\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2386 - masked_acc: 0.8132 - masked_auc: 0.8578 - val_loss: 1.0241 - val_masked_acc: 0.8165 - val_masked_auc: 0.8622\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2050 - masked_acc: 0.8198 - masked_auc: 0.8671\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9757 - masked_acc: 0.8220 - masked_auc: 0.8701\n",
      "Test:  [0.9756593704223633, 0.8220150470733643, 0.8700602650642395]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 168ms/step - loss: 0.6122 - masked_acc: 0.5393 - masked_auc: 0.5140 - val_loss: 0.5418 - val_masked_acc: 0.7094 - val_masked_auc: 0.6039\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.5058 - masked_acc: 0.7139 - masked_auc: 0.6367 - val_loss: 0.5105 - val_masked_acc: 0.7262 - val_masked_auc: 0.6907\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4352 - masked_acc: 0.7326 - masked_auc: 0.7100 - val_loss: 0.4986 - val_masked_acc: 0.7421 - val_masked_auc: 0.7385\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4067 - masked_acc: 0.7467 - masked_auc: 0.7499 - val_loss: 0.5068 - val_masked_acc: 0.7541 - val_masked_auc: 0.7672\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3898 - masked_acc: 0.7576 - masked_auc: 0.7746 - val_loss: 0.5560 - val_masked_acc: 0.7635 - val_masked_auc: 0.7871\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.3621 - masked_acc: 0.7668 - masked_auc: 0.7931 - val_loss: 0.5506 - val_masked_acc: 0.7717 - val_masked_auc: 0.8022\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3575 - masked_acc: 0.7740 - masked_auc: 0.8069 - val_loss: 0.5843 - val_masked_acc: 0.7775 - val_masked_auc: 0.8136\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3393 - masked_acc: 0.7795 - masked_auc: 0.8173 - val_loss: 0.6022 - val_masked_acc: 0.7827 - val_masked_auc: 0.8228\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3247 - masked_acc: 0.7846 - masked_auc: 0.8258 - val_loss: 0.7189 - val_masked_acc: 0.7880 - val_masked_auc: 0.8312\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3039 - masked_acc: 0.7898 - masked_auc: 0.8342 - val_loss: 0.7061 - val_masked_acc: 0.7929 - val_masked_auc: 0.8391\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2856 - masked_acc: 0.7948 - masked_auc: 0.8418 - val_loss: 0.7883 - val_masked_acc: 0.7981 - val_masked_auc: 0.8465\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2584 - masked_acc: 0.8000 - masked_auc: 0.8492 - val_loss: 0.8848 - val_masked_acc: 0.8028 - val_masked_auc: 0.8532\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2421 - masked_acc: 0.8047 - masked_auc: 0.8556 - val_loss: 1.0416 - val_masked_acc: 0.8076 - val_masked_auc: 0.8595\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2139 - masked_acc: 0.8109 - masked_auc: 0.8641\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8279 - masked_acc: 0.8133 - masked_auc: 0.8669\n",
      "Test:  [0.8279054760932922, 0.8133113980293274, 0.8668681979179382]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 170ms/step - loss: 0.5980 - masked_acc: 0.6025 - masked_auc: 0.5055 - val_loss: 0.5453 - val_masked_acc: 0.7176 - val_masked_auc: 0.6237\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4762 - masked_acc: 0.7229 - masked_auc: 0.6618 - val_loss: 0.5640 - val_masked_acc: 0.7346 - val_masked_auc: 0.7088\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4335 - masked_acc: 0.7400 - masked_auc: 0.7262 - val_loss: 0.5406 - val_masked_acc: 0.7485 - val_masked_auc: 0.7492\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4045 - masked_acc: 0.7524 - masked_auc: 0.7590 - val_loss: 0.6055 - val_masked_acc: 0.7584 - val_masked_auc: 0.7740\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3822 - masked_acc: 0.7620 - masked_auc: 0.7810 - val_loss: 0.6277 - val_masked_acc: 0.7673 - val_masked_auc: 0.7917\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3625 - masked_acc: 0.7700 - masked_auc: 0.7973 - val_loss: 0.6776 - val_masked_acc: 0.7749 - val_masked_auc: 0.8058\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3397 - masked_acc: 0.7775 - masked_auc: 0.8105 - val_loss: 0.7617 - val_masked_acc: 0.7814 - val_masked_auc: 0.8168\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3197 - masked_acc: 0.7838 - masked_auc: 0.8210 - val_loss: 0.7904 - val_masked_acc: 0.7873 - val_masked_auc: 0.8264\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3036 - masked_acc: 0.7895 - masked_auc: 0.8299 - val_loss: 0.8947 - val_masked_acc: 0.7931 - val_masked_auc: 0.8349\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2763 - masked_acc: 0.7954 - masked_auc: 0.8382 - val_loss: 0.8858 - val_masked_acc: 0.7983 - val_masked_auc: 0.8427\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2677 - masked_acc: 0.8004 - masked_auc: 0.8457 - val_loss: 1.0496 - val_masked_acc: 0.8033 - val_masked_auc: 0.8497\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2586 - masked_acc: 0.8051 - masked_auc: 0.8522 - val_loss: 1.1236 - val_masked_acc: 0.8082 - val_masked_auc: 0.8557\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2393 - masked_acc: 0.8099 - masked_auc: 0.8580 - val_loss: 1.1939 - val_masked_acc: 0.8126 - val_masked_auc: 0.8614\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2157 - masked_acc: 0.8158 - masked_auc: 0.8659\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8783 - masked_acc: 0.8180 - masked_auc: 0.8685\n",
      "Test:  [0.8783384561538696, 0.8180030584335327, 0.8685490489006042]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr LSTM layers\n",
    "    LSTM_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    LSTM_sub_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    LSTM_ques = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    LSTM_features = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    LSTM_output = tf.concat([LSTM_chap, LSTM_sub_chap, LSTM_ques, LSTM_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(LSTM_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='LSTM_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:03:23.604218Z",
     "iopub.status.busy": "2021-08-12T22:03:23.603568Z",
     "iopub.status.idle": "2021-08-12T22:03:23.611999Z",
     "shell.execute_reply": "2021-08-12T22:03:23.612449Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.922753Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.40781,
     "end_time": "2021-08-12T22:03:23.612612",
     "exception": false,
     "start_time": "2021-08-12T22:03:23.204802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.9132854104042053 +/- 0.05308598476917796\n",
      "test avg acc:  0.8188898086547851 +/- 0.0031365612884996573\n",
      "test avg auc:  0.8688588738441467 +/- 0.0013449834997968921\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:03:24.403268Z",
     "iopub.status.busy": "2021-08-12T22:03:24.402627Z",
     "iopub.status.idle": "2021-08-12T22:03:24.412305Z",
     "shell.execute_reply": "2021-08-12T22:03:24.412951Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.935484Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.405587,
     "end_time": "2021-08-12T22:03:24.413189",
     "exception": false,
     "start_time": "2021-08-12T22:03:24.007602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.20729798674583436 +/- 0.006598071932033646\n",
      "train avg acc:  0.816694700717926 +/- 0.003215078938388891\n",
      "train avg auc:  0.8660627603530884 +/- 0.0012866663753014532\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 476.001901,
   "end_time": "2021-08-12T22:03:28.230610",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:55:32.228709",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
