{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:56:29.306563Z",
     "iopub.status.busy": "2021-08-12T21:56:29.305830Z",
     "iopub.status.idle": "2021-08-12T21:56:36.300630Z",
     "shell.execute_reply": "2021-08-12T21:56:36.299713Z",
     "shell.execute_reply.started": "2021-08-06T20:58:20.355062Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 7.040711,
     "end_time": "2021-08-12T21:56:36.300824",
     "exception": false,
     "start_time": "2021-08-12T21:56:29.260113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:04:46.038972Z",
     "iopub.status.busy": "2021-08-12T22:04:46.037913Z",
     "iopub.status.idle": "2021-08-12T22:04:46.043790Z",
     "shell.execute_reply": "2021-08-12T22:04:46.043106Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.155466Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.380476,
     "end_time": "2021-08-12T22:04:46.043953",
     "exception": false,
     "start_time": "2021-08-12T22:04:45.663477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "LSTM_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:04:46.784168Z",
     "iopub.status.busy": "2021-08-12T22:04:46.783106Z",
     "iopub.status.idle": "2021-08-12T22:04:46.788350Z",
     "shell.execute_reply": "2021-08-12T22:04:46.787726Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.168321Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.375394,
     "end_time": "2021-08-12T22:04:46.788547",
     "exception": false,
     "start_time": "2021-08-12T22:04:46.413153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 39\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:04:51.686572Z",
     "iopub.status.busy": "2021-08-12T22:04:51.658347Z",
     "iopub.status.idle": "2021-08-12T22:06:43.386953Z",
     "shell.execute_reply": "2021-08-12T22:06:43.386185Z",
     "shell.execute_reply.started": "2021-08-06T21:05:49.358265Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 112.115052,
     "end_time": "2021-08-12T22:06:43.387316",
     "exception": false,
     "start_time": "2021-08-12T22:04:51.272264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 256ms/step - loss: 0.5838 - masked_acc: 0.7459 - masked_auc: 0.5180 - val_loss: 0.4831 - val_masked_acc: 0.7397 - val_masked_auc: 0.6584\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4869 - masked_acc: 0.7403 - masked_auc: 0.6868 - val_loss: 0.4537 - val_masked_acc: 0.7503 - val_masked_auc: 0.7343\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4157 - masked_acc: 0.7555 - masked_auc: 0.7506 - val_loss: 0.4439 - val_masked_acc: 0.7632 - val_masked_auc: 0.7737\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.3749 - masked_acc: 0.7678 - masked_auc: 0.7839 - val_loss: 0.4711 - val_masked_acc: 0.7733 - val_masked_auc: 0.7985\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3648 - masked_acc: 0.7764 - masked_auc: 0.8048 - val_loss: 0.5369 - val_masked_acc: 0.7804 - val_masked_auc: 0.8149\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3339 - masked_acc: 0.7835 - masked_auc: 0.8206 - val_loss: 0.5255 - val_masked_acc: 0.7875 - val_masked_auc: 0.8278\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3384 - masked_acc: 0.7895 - masked_auc: 0.8316 - val_loss: 0.5703 - val_masked_acc: 0.7928 - val_masked_auc: 0.8380\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3114 - masked_acc: 0.7950 - masked_auc: 0.8419 - val_loss: 0.6020 - val_masked_acc: 0.7983 - val_masked_auc: 0.8473\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2923 - masked_acc: 0.8003 - masked_auc: 0.8504 - val_loss: 0.7138 - val_masked_acc: 0.8036 - val_masked_auc: 0.8553\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2824 - masked_acc: 0.8052 - masked_auc: 0.8582 - val_loss: 0.7332 - val_masked_acc: 0.8086 - val_masked_auc: 0.8627\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2508 - masked_acc: 0.8105 - masked_auc: 0.8654 - val_loss: 0.7923 - val_masked_acc: 0.8140 - val_masked_auc: 0.8696\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2410 - masked_acc: 0.8158 - masked_auc: 0.8721 - val_loss: 0.7726 - val_masked_acc: 0.8189 - val_masked_auc: 0.8759\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2251 - masked_acc: 0.8207 - masked_auc: 0.8782 - val_loss: 0.8764 - val_masked_acc: 0.8235 - val_masked_auc: 0.8814\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2069 - masked_acc: 0.8264 - masked_auc: 0.8852\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8303 - masked_acc: 0.8282 - masked_auc: 0.8871\n",
      "Test:  [0.8303231000900269, 0.8282145261764526, 0.8870890736579895]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 226ms/step - loss: 0.5962 - masked_acc: 0.6843 - masked_auc: 0.5226 - val_loss: 0.5479 - val_masked_acc: 0.7302 - val_masked_auc: 0.6267\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4792 - masked_acc: 0.7342 - masked_auc: 0.6594 - val_loss: 0.5185 - val_masked_acc: 0.7417 - val_masked_auc: 0.7117\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4335 - masked_acc: 0.7462 - masked_auc: 0.7293 - val_loss: 0.4935 - val_masked_acc: 0.7562 - val_masked_auc: 0.7564\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3904 - masked_acc: 0.7602 - masked_auc: 0.7673 - val_loss: 0.5199 - val_masked_acc: 0.7659 - val_masked_auc: 0.7820\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3771 - masked_acc: 0.7689 - masked_auc: 0.7889 - val_loss: 0.5318 - val_masked_acc: 0.7736 - val_masked_auc: 0.8002\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3633 - masked_acc: 0.7760 - masked_auc: 0.8054 - val_loss: 0.6021 - val_masked_acc: 0.7801 - val_masked_auc: 0.8136\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3284 - masked_acc: 0.7825 - masked_auc: 0.8185 - val_loss: 0.6036 - val_masked_acc: 0.7857 - val_masked_auc: 0.8246\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3217 - masked_acc: 0.7879 - masked_auc: 0.8286 - val_loss: 0.6490 - val_masked_acc: 0.7908 - val_masked_auc: 0.8336\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3040 - masked_acc: 0.7928 - masked_auc: 0.8371 - val_loss: 0.7606 - val_masked_acc: 0.7958 - val_masked_auc: 0.8422\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2920 - masked_acc: 0.7975 - masked_auc: 0.8448 - val_loss: 0.8080 - val_masked_acc: 0.8007 - val_masked_auc: 0.8498\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2688 - masked_acc: 0.8026 - masked_auc: 0.8526 - val_loss: 1.0022 - val_masked_acc: 0.8063 - val_masked_auc: 0.8570\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.2357 - masked_acc: 0.8083 - masked_auc: 0.8597 - val_loss: 0.9653 - val_masked_acc: 0.8111 - val_masked_auc: 0.8634\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.2373 - masked_acc: 0.8127 - masked_auc: 0.8656 - val_loss: 1.2411 - val_masked_acc: 0.8158 - val_masked_auc: 0.8691\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2013 - masked_acc: 0.8189 - masked_auc: 0.8733\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9164 - masked_acc: 0.8212 - masked_auc: 0.8760\n",
      "Test:  [0.9164060950279236, 0.8211742639541626, 0.875987708568573]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 13s 225ms/step - loss: 0.6119 - masked_acc: 0.5344 - masked_auc: 0.5104 - val_loss: 0.4898 - val_masked_acc: 0.7087 - val_masked_auc: 0.6364\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4855 - masked_acc: 0.7182 - masked_auc: 0.6670 - val_loss: 0.4612 - val_masked_acc: 0.7364 - val_masked_auc: 0.7162\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4258 - masked_acc: 0.7430 - masked_auc: 0.7341 - val_loss: 0.4542 - val_masked_acc: 0.7546 - val_masked_auc: 0.7616\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4034 - masked_acc: 0.7585 - masked_auc: 0.7710 - val_loss: 0.4582 - val_masked_acc: 0.7664 - val_masked_auc: 0.7871\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3798 - masked_acc: 0.7698 - masked_auc: 0.7933 - val_loss: 0.4982 - val_masked_acc: 0.7754 - val_masked_auc: 0.8046\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3475 - masked_acc: 0.7785 - masked_auc: 0.8099 - val_loss: 0.5174 - val_masked_acc: 0.7826 - val_masked_auc: 0.8181\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3380 - masked_acc: 0.7851 - masked_auc: 0.8226 - val_loss: 0.5468 - val_masked_acc: 0.7892 - val_masked_auc: 0.8293\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3149 - masked_acc: 0.7916 - masked_auc: 0.8333 - val_loss: 0.5636 - val_masked_acc: 0.7954 - val_masked_auc: 0.8396\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2994 - masked_acc: 0.7976 - masked_auc: 0.8429 - val_loss: 0.6153 - val_masked_acc: 0.8011 - val_masked_auc: 0.8484\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2724 - masked_acc: 0.8033 - masked_auc: 0.8518 - val_loss: 0.6996 - val_masked_acc: 0.8065 - val_masked_auc: 0.8564\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.2632 - masked_acc: 0.8084 - masked_auc: 0.8591 - val_loss: 0.7917 - val_masked_acc: 0.8120 - val_masked_auc: 0.8640\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.2308 - masked_acc: 0.8141 - masked_auc: 0.8667 - val_loss: 0.7885 - val_masked_acc: 0.8173 - val_masked_auc: 0.8710\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2305 - masked_acc: 0.8190 - masked_auc: 0.8733 - val_loss: 0.8320 - val_masked_acc: 0.8222 - val_masked_auc: 0.8771\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2068 - masked_acc: 0.8251 - masked_auc: 0.8811\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7444 - masked_acc: 0.8271 - masked_auc: 0.8835\n",
      "Test:  [0.744384765625, 0.8270528316497803, 0.8834839463233948]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 226ms/step - loss: 0.6024 - masked_acc: 0.7098 - masked_auc: 0.5152 - val_loss: 0.5104 - val_masked_acc: 0.7396 - val_masked_auc: 0.6141\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.4836 - masked_acc: 0.7415 - masked_auc: 0.6516 - val_loss: 0.4993 - val_masked_acc: 0.7515 - val_masked_auc: 0.7046\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4271 - masked_acc: 0.7549 - masked_auc: 0.7230 - val_loss: 0.4821 - val_masked_acc: 0.7634 - val_masked_auc: 0.7518\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.4121 - masked_acc: 0.7655 - masked_auc: 0.7617 - val_loss: 0.5093 - val_masked_acc: 0.7719 - val_masked_auc: 0.7798\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3767 - masked_acc: 0.7742 - masked_auc: 0.7870 - val_loss: 0.5470 - val_masked_acc: 0.7798 - val_masked_auc: 0.7995\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3511 - masked_acc: 0.7822 - masked_auc: 0.8052 - val_loss: 0.5528 - val_masked_acc: 0.7867 - val_masked_auc: 0.8141\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3419 - masked_acc: 0.7885 - masked_auc: 0.8184 - val_loss: 0.5888 - val_masked_acc: 0.7919 - val_masked_auc: 0.8253\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3169 - masked_acc: 0.7938 - masked_auc: 0.8289 - val_loss: 0.6934 - val_masked_acc: 0.7971 - val_masked_auc: 0.8352\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3051 - masked_acc: 0.7991 - masked_auc: 0.8383 - val_loss: 0.8948 - val_masked_acc: 0.8025 - val_masked_auc: 0.8435\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2745 - masked_acc: 0.8044 - masked_auc: 0.8463 - val_loss: 0.9131 - val_masked_acc: 0.8078 - val_masked_auc: 0.8512\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2488 - masked_acc: 0.8095 - masked_auc: 0.8540 - val_loss: 0.9721 - val_masked_acc: 0.8126 - val_masked_auc: 0.8586\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2395 - masked_acc: 0.8142 - masked_auc: 0.8611 - val_loss: 1.1345 - val_masked_acc: 0.8170 - val_masked_auc: 0.8651\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2111 - masked_acc: 0.8187 - masked_auc: 0.8675 - val_loss: 1.2434 - val_masked_acc: 0.8216 - val_masked_auc: 0.8715\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1844 - masked_acc: 0.8248 - masked_auc: 0.8758\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8725 - masked_acc: 0.8268 - masked_auc: 0.8787\n",
      "Test:  [0.8724877238273621, 0.8268194198608398, 0.8786629438400269]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 242ms/step - loss: 0.6138 - masked_acc: 0.5392 - masked_auc: 0.5007 - val_loss: 0.5531 - val_masked_acc: 0.7067 - val_masked_auc: 0.5948\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.4761 - masked_acc: 0.7156 - masked_auc: 0.6366 - val_loss: 0.5433 - val_masked_acc: 0.7237 - val_masked_auc: 0.6921\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4295 - masked_acc: 0.7267 - masked_auc: 0.7119 - val_loss: 0.5303 - val_masked_acc: 0.7322 - val_masked_auc: 0.7414\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.3953 - masked_acc: 0.7383 - masked_auc: 0.7530 - val_loss: 0.5418 - val_masked_acc: 0.7475 - val_masked_auc: 0.7716\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.3691 - masked_acc: 0.7516 - masked_auc: 0.7798 - val_loss: 0.6144 - val_masked_acc: 0.7587 - val_masked_auc: 0.7926\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.3448 - masked_acc: 0.7624 - masked_auc: 0.7993 - val_loss: 0.6109 - val_masked_acc: 0.7679 - val_masked_auc: 0.8080\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.3311 - masked_acc: 0.7710 - masked_auc: 0.8130 - val_loss: 0.7045 - val_masked_acc: 0.7755 - val_masked_auc: 0.8199\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3215 - masked_acc: 0.7782 - masked_auc: 0.8240 - val_loss: 0.7296 - val_masked_acc: 0.7827 - val_masked_auc: 0.8301\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.2943 - masked_acc: 0.7850 - masked_auc: 0.8336 - val_loss: 0.7918 - val_masked_acc: 0.7886 - val_masked_auc: 0.8389\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.2846 - masked_acc: 0.7910 - masked_auc: 0.8421 - val_loss: 0.8390 - val_masked_acc: 0.7944 - val_masked_auc: 0.8468\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.2700 - masked_acc: 0.7964 - masked_auc: 0.8497 - val_loss: 0.9625 - val_masked_acc: 0.7996 - val_masked_auc: 0.8537\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2501 - masked_acc: 0.8016 - masked_auc: 0.8563 - val_loss: 1.1774 - val_masked_acc: 0.8049 - val_masked_auc: 0.8601\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2264 - masked_acc: 0.8067 - masked_auc: 0.8626 - val_loss: 1.1403 - val_masked_acc: 0.8099 - val_masked_auc: 0.8663\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2108 - masked_acc: 0.8131 - masked_auc: 0.8705\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9066 - masked_acc: 0.8153 - masked_auc: 0.8730\n",
      "Test:  [0.9066401124000549, 0.8152819871902466, 0.8730027079582214]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr LSTM layers\n",
    "    LSTM_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    LSTM_sub_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    LSTM_ques = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    LSTM_shif = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "    LSTM_features = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    LSTM_output = tf.concat([LSTM_chap, LSTM_sub_chap, LSTM_ques,LSTM_shif, LSTM_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 5*EMBEDDING_DIM), activation='relu')(LSTM_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='LSTM_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:06:44.601773Z",
     "iopub.status.busy": "2021-08-12T22:06:44.601003Z",
     "iopub.status.idle": "2021-08-12T22:06:44.607128Z",
     "shell.execute_reply": "2021-08-12T22:06:44.606510Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.922753Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.571531,
     "end_time": "2021-08-12T22:06:44.607282",
     "exception": false,
     "start_time": "2021-08-12T22:06:44.035751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.8540483593940735 +/- 0.06258335492080869\n",
      "test avg acc:  0.8237086057662963 +/- 0.004870218041940088\n",
      "test avg auc:  0.8796452760696412 +/- 0.005071725536785536\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:06:45.729094Z",
     "iopub.status.busy": "2021-08-12T22:06:45.727997Z",
     "iopub.status.idle": "2021-08-12T22:06:45.733284Z",
     "shell.execute_reply": "2021-08-12T22:06:45.732707Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.935484Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.567783,
     "end_time": "2021-08-12T22:06:45.733483",
     "exception": false,
     "start_time": "2021-08-12T22:06:45.165700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.20203068256378173 +/- 0.009328008351445717\n",
      "train avg acc:  0.8216705203056336 +/- 0.005009241711265909\n",
      "train avg auc:  0.8772027492523193 +/- 0.005311352213840935\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 628.233348,
   "end_time": "2021-08-12T22:06:49.150148",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:56:20.916800",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
