{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:54:44.302737Z",
     "iopub.status.busy": "2021-08-12T21:54:44.302123Z",
     "iopub.status.idle": "2021-08-12T21:54:51.198558Z",
     "shell.execute_reply": "2021-08-12T21:54:51.197802Z",
     "shell.execute_reply.started": "2021-08-06T20:58:20.355062Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.932553,
     "end_time": "2021-08-12T21:54:51.198719",
     "exception": false,
     "start_time": "2021-08-12T21:54:44.266166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:40.168849Z",
     "iopub.status.busy": "2021-08-12T22:02:40.168194Z",
     "iopub.status.idle": "2021-08-12T22:02:40.171358Z",
     "shell.execute_reply": "2021-08-12T22:02:40.170732Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.155466Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.282713,
     "end_time": "2021-08-12T22:02:40.171509",
     "exception": false,
     "start_time": "2021-08-12T22:02:39.888796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "LSTM_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:40.724506Z",
     "iopub.status.busy": "2021-08-12T22:02:40.723708Z",
     "iopub.status.idle": "2021-08-12T22:02:40.727257Z",
     "shell.execute_reply": "2021-08-12T22:02:40.726665Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.168321Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.279788,
     "end_time": "2021-08-12T22:02:40.727422",
     "exception": false,
     "start_time": "2021-08-12T22:02:40.447634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 37\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:44.626116Z",
     "iopub.status.busy": "2021-08-12T22:02:44.625412Z",
     "iopub.status.idle": "2021-08-12T22:04:07.390430Z",
     "shell.execute_reply": "2021-08-12T22:04:07.389818Z",
     "shell.execute_reply.started": "2021-08-06T21:05:49.358265Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 83.039198,
     "end_time": "2021-08-12T22:04:07.390567",
     "exception": false,
     "start_time": "2021-08-12T22:02:44.351369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 202ms/step - loss: 0.6075 - masked_acc: 0.5636 - masked_auc: 0.4815 - val_loss: 0.5517 - val_masked_acc: 0.7088 - val_masked_auc: 0.5955\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4769 - masked_acc: 0.7177 - masked_auc: 0.6364 - val_loss: 0.5412 - val_masked_acc: 0.7271 - val_masked_auc: 0.6915\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4378 - masked_acc: 0.7319 - masked_auc: 0.7110 - val_loss: 0.5185 - val_masked_acc: 0.7403 - val_masked_auc: 0.7363\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4086 - masked_acc: 0.7454 - masked_auc: 0.7477 - val_loss: 0.5655 - val_masked_acc: 0.7521 - val_masked_auc: 0.7641\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3746 - masked_acc: 0.7562 - masked_auc: 0.7730 - val_loss: 0.5432 - val_masked_acc: 0.7616 - val_masked_auc: 0.7842\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3676 - masked_acc: 0.7645 - masked_auc: 0.7905 - val_loss: 0.5906 - val_masked_acc: 0.7697 - val_masked_auc: 0.7997\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3545 - masked_acc: 0.7720 - masked_auc: 0.8045 - val_loss: 0.7064 - val_masked_acc: 0.7761 - val_masked_auc: 0.8114\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3224 - masked_acc: 0.7787 - masked_auc: 0.8156 - val_loss: 0.7208 - val_masked_acc: 0.7822 - val_masked_auc: 0.8214\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3154 - masked_acc: 0.7846 - masked_auc: 0.8251 - val_loss: 0.7076 - val_masked_acc: 0.7880 - val_masked_auc: 0.8301\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2975 - masked_acc: 0.7900 - masked_auc: 0.8333 - val_loss: 0.8666 - val_masked_acc: 0.7935 - val_masked_auc: 0.8379\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2723 - masked_acc: 0.7955 - masked_auc: 0.8410 - val_loss: 0.8113 - val_masked_acc: 0.7985 - val_masked_auc: 0.8454\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2732 - masked_acc: 0.8002 - masked_auc: 0.8480 - val_loss: 1.0316 - val_masked_acc: 0.8035 - val_masked_auc: 0.8518\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.2376 - masked_acc: 0.8052 - masked_auc: 0.8545 - val_loss: 1.0570 - val_masked_acc: 0.8084 - val_masked_auc: 0.8584\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2138 - masked_acc: 0.8116 - masked_auc: 0.8631\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8423 - masked_acc: 0.8137 - masked_auc: 0.8658\n",
      "Test:  [0.8422578573226929, 0.8136740326881409, 0.8657982349395752]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 175ms/step - loss: 0.6055 - masked_acc: 0.6338 - masked_auc: 0.4907 - val_loss: 0.5506 - val_masked_acc: 0.7214 - val_masked_auc: 0.5999\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.4953 - masked_acc: 0.7238 - masked_auc: 0.6386 - val_loss: 0.5663 - val_masked_acc: 0.7311 - val_masked_auc: 0.6885\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4356 - masked_acc: 0.7354 - masked_auc: 0.7097 - val_loss: 0.5678 - val_masked_acc: 0.7439 - val_masked_auc: 0.7350\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4104 - masked_acc: 0.7473 - masked_auc: 0.7455 - val_loss: 0.5920 - val_masked_acc: 0.7545 - val_masked_auc: 0.7637\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3873 - masked_acc: 0.7580 - masked_auc: 0.7717 - val_loss: 0.5899 - val_masked_acc: 0.7640 - val_masked_auc: 0.7841\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3524 - masked_acc: 0.7675 - masked_auc: 0.7913 - val_loss: 0.6159 - val_masked_acc: 0.7720 - val_masked_auc: 0.7994\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3408 - masked_acc: 0.7748 - masked_auc: 0.8046 - val_loss: 0.6759 - val_masked_acc: 0.7790 - val_masked_auc: 0.8122\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3115 - masked_acc: 0.7820 - masked_auc: 0.8168 - val_loss: 0.7326 - val_masked_acc: 0.7858 - val_masked_auc: 0.8235\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2933 - masked_acc: 0.7883 - masked_auc: 0.8279 - val_loss: 0.7691 - val_masked_acc: 0.7921 - val_masked_auc: 0.8336\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2893 - masked_acc: 0.7943 - masked_auc: 0.8369 - val_loss: 0.9475 - val_masked_acc: 0.7978 - val_masked_auc: 0.8418\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2615 - masked_acc: 0.7997 - masked_auc: 0.8449 - val_loss: 0.9518 - val_masked_acc: 0.8026 - val_masked_auc: 0.8492\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2390 - masked_acc: 0.8061 - masked_auc: 0.8545\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8320 - masked_acc: 0.8083 - masked_auc: 0.8575\n",
      "Test:  [0.8320481181144714, 0.8083062171936035, 0.85752272605896]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 173ms/step - loss: 0.6077 - masked_acc: 0.5568 - masked_auc: 0.5042 - val_loss: 0.5443 - val_masked_acc: 0.7141 - val_masked_auc: 0.6023\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4947 - masked_acc: 0.7221 - masked_auc: 0.6335 - val_loss: 0.5031 - val_masked_acc: 0.7302 - val_masked_auc: 0.6893\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4481 - masked_acc: 0.7357 - masked_auc: 0.7079 - val_loss: 0.4862 - val_masked_acc: 0.7455 - val_masked_auc: 0.7362\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4038 - masked_acc: 0.7497 - masked_auc: 0.7479 - val_loss: 0.5034 - val_masked_acc: 0.7569 - val_masked_auc: 0.7663\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3851 - masked_acc: 0.7602 - masked_auc: 0.7741 - val_loss: 0.5081 - val_masked_acc: 0.7659 - val_masked_auc: 0.7875\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3599 - masked_acc: 0.7691 - masked_auc: 0.7932 - val_loss: 0.5290 - val_masked_acc: 0.7737 - val_masked_auc: 0.8031\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3418 - masked_acc: 0.7764 - masked_auc: 0.8078 - val_loss: 0.5622 - val_masked_acc: 0.7808 - val_masked_auc: 0.8157\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3395 - masked_acc: 0.7831 - masked_auc: 0.8193 - val_loss: 0.6592 - val_masked_acc: 0.7866 - val_masked_auc: 0.8252\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3166 - masked_acc: 0.7886 - masked_auc: 0.8284 - val_loss: 0.6850 - val_masked_acc: 0.7921 - val_masked_auc: 0.8342\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2881 - masked_acc: 0.7939 - masked_auc: 0.8374 - val_loss: 0.7108 - val_masked_acc: 0.7971 - val_masked_auc: 0.8425\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2752 - masked_acc: 0.7990 - masked_auc: 0.8453 - val_loss: 0.8069 - val_masked_acc: 0.8025 - val_masked_auc: 0.8500\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2542 - masked_acc: 0.8043 - masked_auc: 0.8527 - val_loss: 0.8255 - val_masked_acc: 0.8073 - val_masked_auc: 0.8570\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2346 - masked_acc: 0.8091 - masked_auc: 0.8595 - val_loss: 0.9903 - val_masked_acc: 0.8123 - val_masked_auc: 0.8634\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.2035 - masked_acc: 0.8153 - masked_auc: 0.8679\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0050 - masked_acc: 0.8174 - masked_auc: 0.8705\n",
      "Test:  [1.0049736499786377, 0.8174117803573608, 0.8704856038093567]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 175ms/step - loss: 0.5936 - masked_acc: 0.6691 - masked_auc: 0.5255 - val_loss: 0.5164 - val_masked_acc: 0.7290 - val_masked_auc: 0.6201\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4933 - masked_acc: 0.7294 - masked_auc: 0.6588 - val_loss: 0.5098 - val_masked_acc: 0.7379 - val_masked_auc: 0.7053\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4501 - masked_acc: 0.7428 - masked_auc: 0.7211 - val_loss: 0.5009 - val_masked_acc: 0.7506 - val_masked_auc: 0.7457\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.4200 - masked_acc: 0.7543 - masked_auc: 0.7563 - val_loss: 0.5289 - val_masked_acc: 0.7606 - val_masked_auc: 0.7716\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3777 - masked_acc: 0.7646 - masked_auc: 0.7801 - val_loss: 0.5226 - val_masked_acc: 0.7692 - val_masked_auc: 0.7904\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3648 - masked_acc: 0.7720 - masked_auc: 0.7960 - val_loss: 0.5959 - val_masked_acc: 0.7758 - val_masked_auc: 0.8038\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3466 - masked_acc: 0.7784 - masked_auc: 0.8084 - val_loss: 0.6006 - val_masked_acc: 0.7817 - val_masked_auc: 0.8151\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3301 - masked_acc: 0.7839 - masked_auc: 0.8192 - val_loss: 0.6274 - val_masked_acc: 0.7872 - val_masked_auc: 0.8253\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3163 - masked_acc: 0.7892 - masked_auc: 0.8288 - val_loss: 0.6765 - val_masked_acc: 0.7924 - val_masked_auc: 0.8341\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2921 - masked_acc: 0.7946 - masked_auc: 0.8375 - val_loss: 0.7202 - val_masked_acc: 0.7975 - val_masked_auc: 0.8423\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2881 - masked_acc: 0.7991 - masked_auc: 0.8450 - val_loss: 0.8855 - val_masked_acc: 0.8020 - val_masked_auc: 0.8491\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2640 - masked_acc: 0.8037 - masked_auc: 0.8517 - val_loss: 0.9501 - val_masked_acc: 0.8067 - val_masked_auc: 0.8556\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.2340 - masked_acc: 0.8085 - masked_auc: 0.8582 - val_loss: 1.0877 - val_masked_acc: 0.8115 - val_masked_auc: 0.8619\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2040 - masked_acc: 0.8148 - masked_auc: 0.8665\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8438 - masked_acc: 0.8168 - masked_auc: 0.8692\n",
      "Test:  [0.843773603439331, 0.8167709708213806, 0.8692050576210022]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 178ms/step - loss: 0.5956 - masked_acc: 0.7035 - masked_auc: 0.5435 - val_loss: 0.5176 - val_masked_acc: 0.7335 - val_masked_auc: 0.6275\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4775 - masked_acc: 0.7376 - masked_auc: 0.6652 - val_loss: 0.5006 - val_masked_acc: 0.7467 - val_masked_auc: 0.7109\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.4334 - masked_acc: 0.7523 - masked_auc: 0.7267 - val_loss: 0.5166 - val_masked_acc: 0.7580 - val_masked_auc: 0.7492\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 31ms/step - loss: 0.4275 - masked_acc: 0.7606 - masked_auc: 0.7576 - val_loss: 0.5692 - val_masked_acc: 0.7660 - val_masked_auc: 0.7730\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3819 - masked_acc: 0.7688 - masked_auc: 0.7803 - val_loss: 0.5610 - val_masked_acc: 0.7731 - val_masked_auc: 0.7914\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.3746 - masked_acc: 0.7753 - masked_auc: 0.7964 - val_loss: 0.6339 - val_masked_acc: 0.7803 - val_masked_auc: 0.8057\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3394 - masked_acc: 0.7829 - masked_auc: 0.8105 - val_loss: 0.6480 - val_masked_acc: 0.7861 - val_masked_auc: 0.8172\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3265 - masked_acc: 0.7882 - masked_auc: 0.8214 - val_loss: 0.7232 - val_masked_acc: 0.7914 - val_masked_auc: 0.8269\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3055 - masked_acc: 0.7935 - masked_auc: 0.8306 - val_loss: 0.7676 - val_masked_acc: 0.7964 - val_masked_auc: 0.8354\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3078 - masked_acc: 0.7979 - masked_auc: 0.8385 - val_loss: 0.8229 - val_masked_acc: 0.8012 - val_masked_auc: 0.8429\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2769 - masked_acc: 0.8030 - masked_auc: 0.8458 - val_loss: 0.9487 - val_masked_acc: 0.8059 - val_masked_auc: 0.8503\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 32ms/step - loss: 0.2514 - masked_acc: 0.8076 - masked_auc: 0.8532 - val_loss: 1.0287 - val_masked_acc: 0.8106 - val_masked_auc: 0.8574\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2203 - masked_acc: 0.8140 - masked_auc: 0.8625\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7314 - masked_acc: 0.8162 - masked_auc: 0.8656\n",
      "Test:  [0.7313655614852905, 0.8162198662757874, 0.8655723333358765]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr LSTM layers\n",
    "    LSTM_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    LSTM_sub_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    LSTM_ques = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    LSTM_features = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    LSTM_output = tf.concat([LSTM_chap, LSTM_sub_chap, LSTM_ques, LSTM_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(LSTM_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='LSTM_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:04:08.226043Z",
     "iopub.status.busy": "2021-08-12T22:04:08.225395Z",
     "iopub.status.idle": "2021-08-12T22:04:08.229791Z",
     "shell.execute_reply": "2021-08-12T22:04:08.229264Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.922753Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.424623,
     "end_time": "2021-08-12T22:04:08.229949",
     "exception": false,
     "start_time": "2021-08-12T22:04:07.805326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.8508837580680847 +/- 0.08775880115223274\n",
      "test avg acc:  0.8144765734672547 +/- 0.003335749893758685\n",
      "test avg auc:  0.8657167911529541 +/- 0.004518401952458003\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:04:09.034106Z",
     "iopub.status.busy": "2021-08-12T22:04:09.033267Z",
     "iopub.status.idle": "2021-08-12T22:04:09.038819Z",
     "shell.execute_reply": "2021-08-12T22:04:09.038298Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.935484Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.410141,
     "end_time": "2021-08-12T22:04:09.038974",
     "exception": false,
     "start_time": "2021-08-12T22:04:08.628833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.216133975982666 +/- 0.01306908435951156\n",
      "train avg acc:  0.812351405620575 +/- 0.0033898337998455705\n",
      "train avg auc:  0.8629042506217957 +/- 0.004658940618688999\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 576.027891,
   "end_time": "2021-08-12T22:04:12.876383",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:54:36.848492",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
