{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:54:23.640134Z",
     "iopub.status.busy": "2021-08-12T21:54:23.638942Z",
     "iopub.status.idle": "2021-08-12T21:54:29.893989Z",
     "shell.execute_reply": "2021-08-12T21:54:29.893309Z",
     "shell.execute_reply.started": "2021-08-06T20:58:20.355062Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.290421,
     "end_time": "2021-08-12T21:54:29.894200",
     "exception": false,
     "start_time": "2021-08-12T21:54:23.603779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:05.588393Z",
     "iopub.status.busy": "2021-08-12T22:01:05.587352Z",
     "iopub.status.idle": "2021-08-12T22:01:05.591620Z",
     "shell.execute_reply": "2021-08-12T22:01:05.592145Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.155466Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.368571,
     "end_time": "2021-08-12T22:01:05.592325",
     "exception": false,
     "start_time": "2021-08-12T22:01:05.223754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "LSTM_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:06.318610Z",
     "iopub.status.busy": "2021-08-12T22:01:06.317611Z",
     "iopub.status.idle": "2021-08-12T22:01:06.321709Z",
     "shell.execute_reply": "2021-08-12T22:01:06.322178Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.168321Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.371123,
     "end_time": "2021-08-12T22:01:06.322375",
     "exception": false,
     "start_time": "2021-08-12T22:01:05.951252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 37\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:01:11.161598Z",
     "iopub.status.busy": "2021-08-12T22:01:11.160110Z",
     "iopub.status.idle": "2021-08-12T22:02:54.073414Z",
     "shell.execute_reply": "2021-08-12T22:02:54.073952Z",
     "shell.execute_reply.started": "2021-08-06T21:05:49.358265Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 103.281414,
     "end_time": "2021-08-12T22:02:54.074170",
     "exception": false,
     "start_time": "2021-08-12T22:01:10.792756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 248ms/step - loss: 0.5889 - masked_acc: 0.7186 - masked_auc: 0.5260 - val_loss: 0.5219 - val_masked_acc: 0.7340 - val_masked_auc: 0.6480\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4768 - masked_acc: 0.7374 - masked_auc: 0.6806 - val_loss: 0.4793 - val_masked_acc: 0.7475 - val_masked_auc: 0.7265\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4230 - masked_acc: 0.7530 - masked_auc: 0.7430 - val_loss: 0.4736 - val_masked_acc: 0.7620 - val_masked_auc: 0.7678\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3992 - masked_acc: 0.7652 - masked_auc: 0.7765 - val_loss: 0.5164 - val_masked_acc: 0.7710 - val_masked_auc: 0.7917\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.3700 - masked_acc: 0.7738 - masked_auc: 0.7983 - val_loss: 0.5167 - val_masked_acc: 0.7784 - val_masked_auc: 0.8086\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3603 - masked_acc: 0.7806 - masked_auc: 0.8136 - val_loss: 0.5582 - val_masked_acc: 0.7846 - val_masked_auc: 0.8214\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3400 - masked_acc: 0.7865 - masked_auc: 0.8255 - val_loss: 0.6236 - val_masked_acc: 0.7902 - val_masked_auc: 0.8319\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3135 - masked_acc: 0.7922 - masked_auc: 0.8356 - val_loss: 0.6713 - val_masked_acc: 0.7956 - val_masked_auc: 0.8414\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3011 - masked_acc: 0.7975 - masked_auc: 0.8446 - val_loss: 0.7431 - val_masked_acc: 0.8005 - val_masked_auc: 0.8496\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2793 - masked_acc: 0.8024 - masked_auc: 0.8525 - val_loss: 0.8025 - val_masked_acc: 0.8057 - val_masked_auc: 0.8573\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2559 - masked_acc: 0.8076 - masked_auc: 0.8601 - val_loss: 0.9256 - val_masked_acc: 0.8105 - val_masked_auc: 0.8640\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2452 - masked_acc: 0.8123 - masked_auc: 0.8665 - val_loss: 0.9623 - val_masked_acc: 0.8151 - val_masked_auc: 0.8700\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2260 - masked_acc: 0.8168 - masked_auc: 0.8724 - val_loss: 1.0312 - val_masked_acc: 0.8196 - val_masked_auc: 0.8759\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2104 - masked_acc: 0.8227 - masked_auc: 0.8798\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9940 - masked_acc: 0.8247 - masked_auc: 0.8820\n",
      "Test:  [0.9940410852432251, 0.8247172236442566, 0.882030189037323]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 227ms/step - loss: 0.5850 - masked_acc: 0.6613 - masked_auc: 0.5377 - val_loss: 0.5160 - val_masked_acc: 0.7304 - val_masked_auc: 0.6551\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.4827 - masked_acc: 0.7303 - masked_auc: 0.6827 - val_loss: 0.5139 - val_masked_acc: 0.7378 - val_masked_auc: 0.7281\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4258 - masked_acc: 0.7421 - masked_auc: 0.7433 - val_loss: 0.4771 - val_masked_acc: 0.7513 - val_masked_auc: 0.7664\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3977 - masked_acc: 0.7557 - masked_auc: 0.7755 - val_loss: 0.4973 - val_masked_acc: 0.7629 - val_masked_auc: 0.7898\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3675 - masked_acc: 0.7664 - masked_auc: 0.7964 - val_loss: 0.5061 - val_masked_acc: 0.7717 - val_masked_auc: 0.8066\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3634 - masked_acc: 0.7739 - masked_auc: 0.8112 - val_loss: 0.5600 - val_masked_acc: 0.7784 - val_masked_auc: 0.8189\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3367 - masked_acc: 0.7809 - masked_auc: 0.8232 - val_loss: 0.5422 - val_masked_acc: 0.7847 - val_masked_auc: 0.8295\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3312 - masked_acc: 0.7866 - masked_auc: 0.8327 - val_loss: 0.6452 - val_masked_acc: 0.7904 - val_masked_auc: 0.8381\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3043 - masked_acc: 0.7925 - masked_auc: 0.8410 - val_loss: 0.6245 - val_masked_acc: 0.7959 - val_masked_auc: 0.8461\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3004 - masked_acc: 0.7975 - masked_auc: 0.8486 - val_loss: 0.7755 - val_masked_acc: 0.8004 - val_masked_auc: 0.8525\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2709 - masked_acc: 0.8021 - masked_auc: 0.8550 - val_loss: 0.7237 - val_masked_acc: 0.8051 - val_masked_auc: 0.8590\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2593 - masked_acc: 0.8067 - masked_auc: 0.8614 - val_loss: 0.8176 - val_masked_acc: 0.8098 - val_masked_auc: 0.8654\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2415 - masked_acc: 0.8114 - masked_auc: 0.8677 - val_loss: 0.8906 - val_masked_acc: 0.8146 - val_masked_auc: 0.8715\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2155 - masked_acc: 0.8176 - masked_auc: 0.8755\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7911 - masked_acc: 0.8195 - masked_auc: 0.8777\n",
      "Test:  [0.7911349534988403, 0.8194781541824341, 0.8776729106903076]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 12s 214ms/step - loss: 0.5990 - masked_acc: 0.6004 - masked_auc: 0.5362 - val_loss: 0.5294 - val_masked_acc: 0.7165 - val_masked_auc: 0.6185\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4896 - masked_acc: 0.7234 - masked_auc: 0.6507 - val_loss: 0.4980 - val_masked_acc: 0.7371 - val_masked_auc: 0.7088\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4373 - masked_acc: 0.7424 - masked_auc: 0.7280 - val_loss: 0.4728 - val_masked_acc: 0.7524 - val_masked_auc: 0.7544\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4080 - masked_acc: 0.7563 - masked_auc: 0.7649 - val_loss: 0.4948 - val_masked_acc: 0.7634 - val_masked_auc: 0.7810\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3805 - masked_acc: 0.7665 - masked_auc: 0.7876 - val_loss: 0.5280 - val_masked_acc: 0.7722 - val_masked_auc: 0.7999\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3679 - masked_acc: 0.7747 - masked_auc: 0.8052 - val_loss: 0.5338 - val_masked_acc: 0.7798 - val_masked_auc: 0.8140\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3448 - masked_acc: 0.7818 - masked_auc: 0.8182 - val_loss: 0.5843 - val_masked_acc: 0.7856 - val_masked_auc: 0.8255\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3293 - masked_acc: 0.7874 - masked_auc: 0.8290 - val_loss: 0.5986 - val_masked_acc: 0.7909 - val_masked_auc: 0.8351\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3066 - masked_acc: 0.7929 - masked_auc: 0.8386 - val_loss: 0.6789 - val_masked_acc: 0.7966 - val_masked_auc: 0.8440\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2861 - masked_acc: 0.7986 - masked_auc: 0.8470 - val_loss: 0.7547 - val_masked_acc: 0.8019 - val_masked_auc: 0.8517\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2741 - masked_acc: 0.8035 - masked_auc: 0.8542 - val_loss: 0.8459 - val_masked_acc: 0.8067 - val_masked_auc: 0.8587\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2542 - masked_acc: 0.8084 - masked_auc: 0.8611 - val_loss: 0.9034 - val_masked_acc: 0.8116 - val_masked_auc: 0.8652\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2300 - masked_acc: 0.8133 - masked_auc: 0.8675 - val_loss: 0.9953 - val_masked_acc: 0.8163 - val_masked_auc: 0.8711\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2012 - masked_acc: 0.8196 - masked_auc: 0.8756\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9005 - masked_acc: 0.8216 - masked_auc: 0.8777\n",
      "Test:  [0.9005358815193176, 0.8215872049331665, 0.8777259588241577]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 11s 206ms/step - loss: 0.5821 - masked_acc: 0.7540 - masked_auc: 0.5121 - val_loss: 0.4971 - val_masked_acc: 0.7427 - val_masked_auc: 0.6575\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4766 - masked_acc: 0.7448 - masked_auc: 0.6849 - val_loss: 0.4674 - val_masked_acc: 0.7557 - val_masked_auc: 0.7331\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4225 - masked_acc: 0.7603 - masked_auc: 0.7478 - val_loss: 0.4676 - val_masked_acc: 0.7678 - val_masked_auc: 0.7718\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3990 - masked_acc: 0.7706 - masked_auc: 0.7806 - val_loss: 0.4864 - val_masked_acc: 0.7767 - val_masked_auc: 0.7950\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3680 - masked_acc: 0.7793 - masked_auc: 0.8015 - val_loss: 0.5014 - val_masked_acc: 0.7842 - val_masked_auc: 0.8114\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.3522 - masked_acc: 0.7865 - masked_auc: 0.8162 - val_loss: 0.5394 - val_masked_acc: 0.7896 - val_masked_auc: 0.8233\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3396 - masked_acc: 0.7916 - masked_auc: 0.8270 - val_loss: 0.5890 - val_masked_acc: 0.7949 - val_masked_auc: 0.8334\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3221 - masked_acc: 0.7969 - masked_auc: 0.8366 - val_loss: 0.6039 - val_masked_acc: 0.8003 - val_masked_auc: 0.8422\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3074 - masked_acc: 0.8020 - masked_auc: 0.8450 - val_loss: 0.6727 - val_masked_acc: 0.8051 - val_masked_auc: 0.8499\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2898 - masked_acc: 0.8067 - masked_auc: 0.8526 - val_loss: 0.7276 - val_masked_acc: 0.8096 - val_masked_auc: 0.8571\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2606 - masked_acc: 0.8114 - masked_auc: 0.8599 - val_loss: 0.7954 - val_masked_acc: 0.8144 - val_masked_auc: 0.8639\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2332 - masked_acc: 0.8163 - masked_auc: 0.8665 - val_loss: 0.9211 - val_masked_acc: 0.8191 - val_masked_auc: 0.8701\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2155 - masked_acc: 0.8223 - masked_auc: 0.8745\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9149 - masked_acc: 0.8243 - masked_auc: 0.8770\n",
      "Test:  [0.9148817658424377, 0.8243410587310791, 0.8770169019699097]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 11s 212ms/step - loss: 0.5924 - masked_acc: 0.5752 - masked_auc: 0.5270 - val_loss: 0.5379 - val_masked_acc: 0.7168 - val_masked_auc: 0.6394\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4930 - masked_acc: 0.7218 - masked_auc: 0.6660 - val_loss: 0.5155 - val_masked_acc: 0.7389 - val_masked_auc: 0.7180\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.4092 - masked_acc: 0.7458 - masked_auc: 0.7368 - val_loss: 0.5088 - val_masked_acc: 0.7556 - val_masked_auc: 0.7607\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.3937 - masked_acc: 0.7597 - masked_auc: 0.7703 - val_loss: 0.5493 - val_masked_acc: 0.7666 - val_masked_auc: 0.7850\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3631 - masked_acc: 0.7703 - masked_auc: 0.7920 - val_loss: 0.5645 - val_masked_acc: 0.7755 - val_masked_auc: 0.8027\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.3532 - masked_acc: 0.7780 - masked_auc: 0.8077 - val_loss: 0.6510 - val_masked_acc: 0.7823 - val_masked_auc: 0.8158\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3406 - masked_acc: 0.7847 - masked_auc: 0.8199 - val_loss: 0.6157 - val_masked_acc: 0.7883 - val_masked_auc: 0.8266\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2999 - masked_acc: 0.7909 - masked_auc: 0.8306 - val_loss: 0.7383 - val_masked_acc: 0.7942 - val_masked_auc: 0.8364\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2875 - masked_acc: 0.7964 - masked_auc: 0.8400 - val_loss: 0.8387 - val_masked_acc: 0.8001 - val_masked_auc: 0.8453\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2732 - masked_acc: 0.8020 - masked_auc: 0.8484 - val_loss: 0.8732 - val_masked_acc: 0.8050 - val_masked_auc: 0.8527\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2683 - masked_acc: 0.8066 - masked_auc: 0.8552 - val_loss: 1.0454 - val_masked_acc: 0.8096 - val_masked_auc: 0.8590\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2365 - masked_acc: 0.8115 - masked_auc: 0.8614 - val_loss: 1.0698 - val_masked_acc: 0.8144 - val_masked_auc: 0.8652\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2150 - masked_acc: 0.8161 - masked_auc: 0.8677 - val_loss: 1.1577 - val_masked_acc: 0.8190 - val_masked_auc: 0.8712\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2040 - masked_acc: 0.8220 - masked_auc: 0.8751\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7691 - masked_acc: 0.8241 - masked_auc: 0.8778\n",
      "Test:  [0.7691434621810913, 0.824124276638031, 0.8777639269828796]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_shifted_t = []\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_shifted_t.append(user[4])\n",
    "        train_labels.append(user[5])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_shifted_t = np.array(train_shifted_t)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_shifted_t = []\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_shifted_t.append(user[4])\n",
    "        val_labels.append(user[5])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_shifted_t = np.array(val_shifted_t)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_shifted_t = []\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_shifted_t.append(user[4])\n",
    "        test_labels.append(user[5])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_shifted_t = np.array(test_shifted_t)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_shifted = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    embedding_shifted = Embedding(input_dim = 3, output_dim = EMBEDDING_DIM)(input_shifted)\n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr LSTM layers\n",
    "    LSTM_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    LSTM_sub_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    LSTM_ques = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    LSTM_shif = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_shifted)\n",
    "    LSTM_features = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    LSTM_output = tf.concat([LSTM_chap, LSTM_sub_chap, LSTM_ques,LSTM_shif, LSTM_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 5*EMBEDDING_DIM), activation='relu')(LSTM_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_shifted, input_features],\n",
    "        outputs=pred,\n",
    "        name='LSTM_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_shifted_t, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_shifted_t, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_shifted_t, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:55.170479Z",
     "iopub.status.busy": "2021-08-12T22:02:55.169764Z",
     "iopub.status.idle": "2021-08-12T22:02:55.178366Z",
     "shell.execute_reply": "2021-08-12T22:02:55.178974Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.922753Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.558871,
     "end_time": "2021-08-12T22:02:55.179182",
     "exception": false,
     "start_time": "2021-08-12T22:02:54.620311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.8739474296569825 +/- 0.08324281298656018\n",
      "test avg acc:  0.8228495836257934 +/- 0.0020148228685841385\n",
      "test avg auc:  0.8784419775009156 +/- 0.0018149380875794447\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:56.275951Z",
     "iopub.status.busy": "2021-08-12T22:02:56.274976Z",
     "iopub.status.idle": "2021-08-12T22:02:56.286057Z",
     "shell.execute_reply": "2021-08-12T22:02:56.285026Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.935484Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.557336,
     "end_time": "2021-08-12T22:02:56.286317",
     "exception": false,
     "start_time": "2021-08-12T22:02:55.728981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.20931620597839357 +/- 0.005869281974950056\n",
      "train avg acc:  0.8208276271820069 +/- 0.001928692370714094\n",
      "train avg auc:  0.8761117696762085 +/- 0.0019019104397995524\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 524.179522,
   "end_time": "2021-08-12T22:02:59.555687",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:54:15.376165",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
