{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T21:56:04.981013Z",
     "iopub.status.busy": "2021-08-12T21:56:04.976265Z",
     "iopub.status.idle": "2021-08-12T21:56:11.544135Z",
     "shell.execute_reply": "2021-08-12T21:56:11.543388Z",
     "shell.execute_reply.started": "2021-08-06T20:58:20.355062Z"
    },
    "id": "farifxiKU1aB",
    "papermill": {
     "duration": 6.607716,
     "end_time": "2021-08-12T21:56:11.544302",
     "exception": false,
     "start_time": "2021-08-12T21:56:04.936586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from random import choice\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Flatten, Activation, Dropout\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "warnings.filterwarnings('ignore')\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:26.463009Z",
     "iopub.status.busy": "2021-08-12T22:02:26.462307Z",
     "iopub.status.idle": "2021-08-12T22:02:26.466513Z",
     "shell.execute_reply": "2021-08-12T22:02:26.467047Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.155466Z"
    },
    "id": "9kZqV9siDyNb",
    "papermill": {
     "duration": 0.364783,
     "end_time": "2021-08-12T22:02:26.467211",
     "exception": false,
     "start_time": "2021-08-12T22:02:26.102428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAXLENGTH = 13\n",
    "EMBEDDING_DIM = 128\n",
    "DENSE_NEURON = 16\n",
    "LSTM_NEURON = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:27.194631Z",
     "iopub.status.busy": "2021-08-12T22:02:27.193961Z",
     "iopub.status.idle": "2021-08-12T22:02:27.197522Z",
     "shell.execute_reply": "2021-08-12T22:02:27.198060Z",
     "shell.execute_reply.started": "2021-08-06T21:05:48.168321Z"
    },
    "id": "1MksD1JizpPn",
    "papermill": {
     "duration": 0.374551,
     "end_time": "2021-08-12T22:02:27.198236",
     "exception": false,
     "start_time": "2021-08-12T22:02:26.823685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_SIZE = 2\n",
    "CHAPTER_SIZE = 38\n",
    "SUB_CHAPTER_SIZE = 223\n",
    "QUESTION_SIZE = 1069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:02:31.863671Z",
     "iopub.status.busy": "2021-08-12T22:02:31.862607Z",
     "iopub.status.idle": "2021-08-12T22:03:55.357080Z",
     "shell.execute_reply": "2021-08-12T22:03:55.356128Z",
     "shell.execute_reply.started": "2021-08-06T21:05:49.358265Z"
    },
    "id": "gzJrljnjzypP",
    "outputId": "87abe488-b493-4f8f-9d71-45cb1d2ddf51",
    "papermill": {
     "duration": 83.88016,
     "end_time": "2021-08-12T22:03:55.357238",
     "exception": false,
     "start_time": "2021-08-12T22:02:31.477078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 209ms/step - loss: 0.6208 - masked_acc: 0.5282 - masked_auc: 0.5191 - val_loss: 0.5379 - val_masked_acc: 0.7043 - val_masked_auc: 0.5896\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.5071 - masked_acc: 0.7098 - masked_auc: 0.6266 - val_loss: 0.4979 - val_masked_acc: 0.7281 - val_masked_auc: 0.6876\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4471 - masked_acc: 0.7342 - masked_auc: 0.7062 - val_loss: 0.4970 - val_masked_acc: 0.7437 - val_masked_auc: 0.7342\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4016 - masked_acc: 0.7486 - masked_auc: 0.7458 - val_loss: 0.5536 - val_masked_acc: 0.7550 - val_masked_auc: 0.7618\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4002 - masked_acc: 0.7579 - masked_auc: 0.7687 - val_loss: 0.5504 - val_masked_acc: 0.7638 - val_masked_auc: 0.7810\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3743 - masked_acc: 0.7670 - masked_auc: 0.7864 - val_loss: 0.5978 - val_masked_acc: 0.7712 - val_masked_auc: 0.7950\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 0.3595 - masked_acc: 0.7734 - masked_auc: 0.7990 - val_loss: 0.6494 - val_masked_acc: 0.7773 - val_masked_auc: 0.8067\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3404 - masked_acc: 0.7795 - masked_auc: 0.8103 - val_loss: 0.6728 - val_masked_acc: 0.7830 - val_masked_auc: 0.8167\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3104 - masked_acc: 0.7853 - masked_auc: 0.8206 - val_loss: 0.7496 - val_masked_acc: 0.7881 - val_masked_auc: 0.8250\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3125 - masked_acc: 0.7897 - masked_auc: 0.8278 - val_loss: 0.8311 - val_masked_acc: 0.7927 - val_masked_auc: 0.8322\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2832 - masked_acc: 0.7945 - masked_auc: 0.8349 - val_loss: 0.7651 - val_masked_acc: 0.7969 - val_masked_auc: 0.8390\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2809 - masked_acc: 0.7985 - masked_auc: 0.8413 - val_loss: 0.8819 - val_masked_acc: 0.8013 - val_masked_auc: 0.8453\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.2587 - masked_acc: 0.8029 - masked_auc: 0.8476 - val_loss: 0.9964 - val_masked_acc: 0.8056 - val_masked_auc: 0.8515\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2289 - masked_acc: 0.8085 - masked_auc: 0.8558\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7636 - masked_acc: 0.8106 - masked_auc: 0.8587\n",
      "Test:  [0.7636094689369202, 0.8105910420417786, 0.8587368130683899]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 178ms/step - loss: 0.6192 - masked_acc: 0.5322 - masked_auc: 0.4933 - val_loss: 0.5166 - val_masked_acc: 0.7084 - val_masked_auc: 0.5987\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4788 - masked_acc: 0.7152 - masked_auc: 0.6436 - val_loss: 0.5176 - val_masked_acc: 0.7285 - val_masked_auc: 0.6948\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.4339 - masked_acc: 0.7357 - masked_auc: 0.7137 - val_loss: 0.5740 - val_masked_acc: 0.7455 - val_masked_auc: 0.7400\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3978 - masked_acc: 0.7505 - masked_auc: 0.7523 - val_loss: 0.5741 - val_masked_acc: 0.7568 - val_masked_auc: 0.7679\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3900 - masked_acc: 0.7597 - masked_auc: 0.7753 - val_loss: 0.6556 - val_masked_acc: 0.7653 - val_masked_auc: 0.7865\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.3551 - masked_acc: 0.7688 - masked_auc: 0.7928 - val_loss: 0.6194 - val_masked_acc: 0.7726 - val_masked_auc: 0.8009\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.3467 - masked_acc: 0.7751 - masked_auc: 0.8054 - val_loss: 0.7034 - val_masked_acc: 0.7785 - val_masked_auc: 0.8121\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3322 - masked_acc: 0.7806 - masked_auc: 0.8161 - val_loss: 0.7962 - val_masked_acc: 0.7840 - val_masked_auc: 0.8217\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3188 - masked_acc: 0.7860 - masked_auc: 0.8254 - val_loss: 0.8426 - val_masked_acc: 0.7893 - val_masked_auc: 0.8305\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2999 - masked_acc: 0.7912 - masked_auc: 0.8337 - val_loss: 0.9391 - val_masked_acc: 0.7941 - val_masked_auc: 0.8381\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2843 - masked_acc: 0.7958 - masked_auc: 0.8408 - val_loss: 1.1534 - val_masked_acc: 0.7992 - val_masked_auc: 0.8451\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2523 - masked_acc: 0.8023 - masked_auc: 0.8501\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7974 - masked_acc: 0.8045 - masked_auc: 0.8532\n",
      "Test:  [0.7973924279212952, 0.8044965267181396, 0.8532406687736511]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 176ms/step - loss: 0.6137 - masked_acc: 0.6700 - masked_auc: 0.4828 - val_loss: 0.5005 - val_masked_acc: 0.7231 - val_masked_auc: 0.5996\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4765 - masked_acc: 0.7293 - masked_auc: 0.6441 - val_loss: 0.4937 - val_masked_acc: 0.7409 - val_masked_auc: 0.7000\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4523 - masked_acc: 0.7454 - masked_auc: 0.7156 - val_loss: 0.4884 - val_masked_acc: 0.7537 - val_masked_auc: 0.7427\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4128 - masked_acc: 0.7577 - masked_auc: 0.7539 - val_loss: 0.5002 - val_masked_acc: 0.7638 - val_masked_auc: 0.7691\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3885 - masked_acc: 0.7668 - masked_auc: 0.7759 - val_loss: 0.5372 - val_masked_acc: 0.7714 - val_masked_auc: 0.7877\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3690 - masked_acc: 0.7741 - masked_auc: 0.7937 - val_loss: 0.5351 - val_masked_acc: 0.7777 - val_masked_auc: 0.8019\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3559 - masked_acc: 0.7799 - masked_auc: 0.8063 - val_loss: 0.5878 - val_masked_acc: 0.7829 - val_masked_auc: 0.8133\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3547 - masked_acc: 0.7843 - masked_auc: 0.8168 - val_loss: 0.6366 - val_masked_acc: 0.7872 - val_masked_auc: 0.8226\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3269 - masked_acc: 0.7890 - masked_auc: 0.8259 - val_loss: 0.6529 - val_masked_acc: 0.7917 - val_masked_auc: 0.8313\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3048 - masked_acc: 0.7934 - masked_auc: 0.8345 - val_loss: 0.8203 - val_masked_acc: 0.7966 - val_masked_auc: 0.8393\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2888 - masked_acc: 0.7983 - masked_auc: 0.8420 - val_loss: 0.8281 - val_masked_acc: 0.8012 - val_masked_auc: 0.8468\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2600 - masked_acc: 0.8028 - masked_auc: 0.8498 - val_loss: 0.9655 - val_masked_acc: 0.8055 - val_masked_auc: 0.8539\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2409 - masked_acc: 0.8071 - masked_auc: 0.8564 - val_loss: 1.2109 - val_masked_acc: 0.8100 - val_masked_auc: 0.8604\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2269 - masked_acc: 0.8128 - masked_auc: 0.8647\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0502 - masked_acc: 0.8145 - masked_auc: 0.8670\n",
      "Test:  [1.0501766204833984, 0.8144766092300415, 0.8670040369033813]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 10s 174ms/step - loss: 0.6082 - masked_acc: 0.6813 - masked_auc: 0.5264 - val_loss: 0.5400 - val_masked_acc: 0.7298 - val_masked_auc: 0.6259\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.4754 - masked_acc: 0.7338 - masked_auc: 0.6619 - val_loss: 0.5232 - val_masked_acc: 0.7378 - val_masked_auc: 0.7079\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.4452 - masked_acc: 0.7412 - masked_auc: 0.7230 - val_loss: 0.5445 - val_masked_acc: 0.7488 - val_masked_auc: 0.7472\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4143 - masked_acc: 0.7527 - masked_auc: 0.7558 - val_loss: 0.5548 - val_masked_acc: 0.7589 - val_masked_auc: 0.7710\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4001 - masked_acc: 0.7617 - masked_auc: 0.7773 - val_loss: 0.5985 - val_masked_acc: 0.7670 - val_masked_auc: 0.7882\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3824 - masked_acc: 0.7694 - masked_auc: 0.7926 - val_loss: 0.6447 - val_masked_acc: 0.7736 - val_masked_auc: 0.8012\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3350 - masked_acc: 0.7765 - masked_auc: 0.8063 - val_loss: 0.6642 - val_masked_acc: 0.7793 - val_masked_auc: 0.8124\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3330 - masked_acc: 0.7814 - masked_auc: 0.8161 - val_loss: 0.7105 - val_masked_acc: 0.7848 - val_masked_auc: 0.8221\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3207 - masked_acc: 0.7869 - masked_auc: 0.8255 - val_loss: 0.7373 - val_masked_acc: 0.7898 - val_masked_auc: 0.8302\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2996 - masked_acc: 0.7918 - masked_auc: 0.8332 - val_loss: 0.7811 - val_masked_acc: 0.7949 - val_masked_auc: 0.8381\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2767 - masked_acc: 0.7969 - masked_auc: 0.8410 - val_loss: 0.8535 - val_masked_acc: 0.7999 - val_masked_auc: 0.8457\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.2611 - masked_acc: 0.8018 - masked_auc: 0.8484 - val_loss: 0.9755 - val_masked_acc: 0.8050 - val_masked_auc: 0.8527\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2351 - masked_acc: 0.8081 - masked_auc: 0.8574\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7706 - masked_acc: 0.8102 - masked_auc: 0.8604\n",
      "Test:  [0.7705996632575989, 0.8102415800094604, 0.8603614568710327]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 9s 178ms/step - loss: 0.6217 - masked_acc: 0.5508 - masked_auc: 0.5200 - val_loss: 0.5577 - val_masked_acc: 0.7167 - val_masked_auc: 0.5869\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.4868 - masked_acc: 0.7206 - masked_auc: 0.6237 - val_loss: 0.5296 - val_masked_acc: 0.7309 - val_masked_auc: 0.6836\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4407 - masked_acc: 0.7329 - masked_auc: 0.7028 - val_loss: 0.5248 - val_masked_acc: 0.7414 - val_masked_auc: 0.7308\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.4148 - masked_acc: 0.7449 - masked_auc: 0.7415 - val_loss: 0.5661 - val_masked_acc: 0.7536 - val_masked_auc: 0.7604\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3765 - masked_acc: 0.7572 - masked_auc: 0.7687 - val_loss: 0.5920 - val_masked_acc: 0.7629 - val_masked_auc: 0.7803\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3738 - masked_acc: 0.7657 - masked_auc: 0.7860 - val_loss: 0.6180 - val_masked_acc: 0.7709 - val_masked_auc: 0.7956\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3542 - masked_acc: 0.7731 - masked_auc: 0.7999 - val_loss: 0.6327 - val_masked_acc: 0.7779 - val_masked_auc: 0.8080\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.3347 - masked_acc: 0.7800 - masked_auc: 0.8114 - val_loss: 0.6878 - val_masked_acc: 0.7839 - val_masked_auc: 0.8180\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3190 - masked_acc: 0.7858 - masked_auc: 0.8212 - val_loss: 0.7783 - val_masked_acc: 0.7895 - val_masked_auc: 0.8269\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.3016 - masked_acc: 0.7913 - masked_auc: 0.8297 - val_loss: 0.9029 - val_masked_acc: 0.7948 - val_masked_auc: 0.8348\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2784 - masked_acc: 0.7965 - masked_auc: 0.8373 - val_loss: 0.9621 - val_masked_acc: 0.7998 - val_masked_auc: 0.8421\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.2614 - masked_acc: 0.8015 - masked_auc: 0.8445 - val_loss: 1.0314 - val_masked_acc: 0.8043 - val_masked_auc: 0.8485\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 36ms/step - loss: 0.2490 - masked_acc: 0.8059 - masked_auc: 0.8508 - val_loss: 1.1476 - val_masked_acc: 0.8085 - val_masked_auc: 0.8544\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2301 - masked_acc: 0.8113 - masked_auc: 0.8585\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9120 - masked_acc: 0.8130 - masked_auc: 0.8610\n",
      "Test:  [0.9119814038276672, 0.8129832744598389, 0.8610113859176636]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = np.array(grouped_data.keys())\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "train_losses = list()\n",
    "train_aucs = list()\n",
    "val_losses = list()\n",
    "val_aucs = list()\n",
    "train_eval = list()\n",
    "test_eval = list()\n",
    "for train, test in kfold.split(X):\n",
    "    users_train, users_test =  X[train], X[test]\n",
    "    n = len(users_test)//2\n",
    "    users_test, users_val = users_test[:n], users_test[n: ]\n",
    "    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n",
    "    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n",
    "    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n",
    "    #construct training input\n",
    "    train_chapter=[]\n",
    "    train_sub_chapter=[]\n",
    "    train_question = []\n",
    "    train_features=[]\n",
    "    train_labels=[]\n",
    "    for i in range(len(users_train)):\n",
    "        user = train_data_space.__getitem__(i)\n",
    "        train_chapter.append(user[0])\n",
    "        train_sub_chapter.append(user[1]) \n",
    "        train_question.append(user[2])\n",
    "        train_features.append(user[3])\n",
    "        train_labels.append(user[4])\n",
    "    train_chapter = np.array(train_chapter)\n",
    "    train_sub_chapter = np.array(train_sub_chapter)\n",
    "    train_question = np.array(train_question)\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels= np.array(train_labels)[..., np.newaxis]\n",
    "\n",
    "    #construct validation input\n",
    "    val_chapter=[]\n",
    "    val_sub_chapter=[]\n",
    "    val_question = []\n",
    "    val_features=[]\n",
    "    val_labels=[]\n",
    "    for i in range(len(users_val)):\n",
    "        user = val_data_space.__getitem__(i)\n",
    "        val_chapter.append(user[0])\n",
    "        val_sub_chapter.append(user[1]) \n",
    "        val_question.append(user[2])\n",
    "        val_features.append(user[3])\n",
    "        val_labels.append(user[4])\n",
    "    val_chapter = np.array(val_chapter)\n",
    "    val_sub_chapter = np.array(val_sub_chapter)\n",
    "    val_features = np.array(val_features)\n",
    "    val_question = np.array(val_question)\n",
    "    val_labels= np.array(val_labels)[..., np.newaxis]\n",
    "\n",
    "    # construct test input\n",
    "    test_chapter=[]\n",
    "    test_sub_chapter=[]\n",
    "    test_features=[]\n",
    "    test_question=[]\n",
    "    test_labels=[]\n",
    "    for i in range(len(users_test)):\n",
    "        user = test_data_space.__getitem__(i)\n",
    "        test_chapter.append(user[0])\n",
    "        test_sub_chapter.append(user[1]) \n",
    "        test_question.append(user[2])\n",
    "        test_features.append(user[3])\n",
    "        test_labels.append(user[4])\n",
    "    test_chapter = np.array(test_chapter)\n",
    "    test_sub_chapter = np.array(test_sub_chapter)\n",
    "    test_features = np.array(test_features)\n",
    "    test_question = np.array(test_question)\n",
    "    test_labels= np.array(test_labels)[..., np.newaxis]\n",
    "\n",
    "    # define loss function and evaluation metrics\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    acc = tf.keras.metrics.Accuracy()\n",
    "    auc = tf.keras.metrics.AUC()\n",
    "\n",
    "    def masked_bce(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_acc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      flat_pred = (flat_pred >= 0.5)\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    def masked_auc(y_true, y_pred):\n",
    "      flat_pred = y_pred\n",
    "      flat_ground_truth = y_true\n",
    "      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n",
    "      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n",
    "\n",
    "    # input layer\n",
    "    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n",
    "    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n",
    "\n",
    "    # embedding layer for categorical features\n",
    "    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n",
    "    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n",
    "    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n",
    "    # dense layer for numeric features\n",
    "    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n",
    "\n",
    "    # definr LSTM layers\n",
    "    LSTM_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n",
    "    LSTM_sub_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n",
    "    LSTM_ques = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n",
    "    LSTM_features = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n",
    "\n",
    "    LSTM_output = tf.concat([LSTM_chap, LSTM_sub_chap, LSTM_ques, LSTM_features], axis = 2)\n",
    "\n",
    "    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(LSTM_output)\n",
    "    dropout1 = Dropout(0.1)(dense1)\n",
    "    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.1)(dense2)\n",
    "    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n",
    "        outputs=pred,\n",
    "        name='LSTM_model'\n",
    "    )\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    opt_adam = Adam(learning_rate = 0.005)\n",
    "    model.compile(\n",
    "        optimizer=opt_adam,\n",
    "        loss= masked_bce,\n",
    "        metrics = [masked_acc, masked_auc]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      [train_chapter, train_sub_chapter, train_question, train_features],\n",
    "      train_labels,\n",
    "      batch_size = 64,\n",
    "      epochs = 100,\n",
    "      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n",
    "      callbacks=[callback]\n",
    "    )\n",
    "    val_losses.append(list(history.history['val_loss']))\n",
    "    train_losses.append(list(history.history['loss']))\n",
    "    val_aucs.append(list(history.history['val_masked_auc']))\n",
    "    train_aucs.append(list(history.history['masked_auc']))\n",
    "    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n",
    "    train_eval.append(train_score)\n",
    "    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n",
    "    test_eval.append(test_score)\n",
    "    print(\"Test: \", test_score)\n",
    "    def reset_weights(model):\n",
    "      for layer in model.layers: \n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "          reset_weights(layer)\n",
    "          continue\n",
    "        for k, initializer in layer.__dict__.items():\n",
    "          if \"initializer\" not in k:\n",
    "            continue\n",
    "          # find the corresponding variable\n",
    "          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n",
    "          var.assign(initializer(var.shape, var.dtype))\n",
    "    reset_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:03:56.462031Z",
     "iopub.status.busy": "2021-08-12T22:03:56.461384Z",
     "iopub.status.idle": "2021-08-12T22:03:56.466811Z",
     "shell.execute_reply": "2021-08-12T22:03:56.466245Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.922753Z"
    },
    "id": "QsVmumHMz3lx",
    "outputId": "4ff1e2fa-6abb-458e-c729-495b456f53e5",
    "papermill": {
     "duration": 0.582837,
     "end_time": "2021-08-12T22:03:56.466947",
     "exception": false,
     "start_time": "2021-08-12T22:03:55.884110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test avg loss:  0.858751916885376 +/- 0.10960354696353948\n",
      "test avg acc:  0.8105578064918518 +/- 0.003408229043058315\n",
      "test avg auc:  0.8600708723068238 +/- 0.004415182236789456\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(test_eval)\n",
    "print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T22:03:57.537681Z",
     "iopub.status.busy": "2021-08-12T22:03:57.536685Z",
     "iopub.status.idle": "2021-08-12T22:03:57.542207Z",
     "shell.execute_reply": "2021-08-12T22:03:57.543010Z",
     "shell.execute_reply.started": "2021-08-06T21:35:33.935484Z"
    },
    "id": "b9MM_CXWz5K6",
    "outputId": "4cf88e1d-3a74-4e7d-f92c-d01522e91757",
    "papermill": {
     "duration": 0.545135,
     "end_time": "2021-08-12T22:03:57.543273",
     "exception": false,
     "start_time": "2021-08-12T22:03:56.998138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train avg loss:  0.2346488893032074 +/- 0.009228668114438806\n",
      "train avg acc:  0.8085930824279786 +/- 0.0035766275826575704\n",
      "train avg auc:  0.8573102712631225 +/- 0.004677878350250182\n"
     ]
    }
   ],
   "source": [
    "t_eval = np.array(train_eval)\n",
    "print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n",
    "print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n",
    "print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 484.151177,
   "end_time": "2021-08-12T22:04:01.008923",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-12T21:55:56.857746",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
